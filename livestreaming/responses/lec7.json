[
    {
        "Conversation History": "\t",
        "GPT Response": "It seems like your comment about the Spanish guitar doesn't directly relate to the lecture content on string manipulation and regular expressions. If you have any questions about the lecture material or need further clarification on those topics, feel free to ask!",
        "Recent Audio": "this thing, these divisions with nothing. Delete them from the string. That's what it'll do. And you can do the exact same thing in pandas with your replace function. Annoyingly, you need to tell it that it's in fact the pattern is a regular expression. Why this function is so common and very few people are comfortable with regular expressions if by default it doesn't assume the pattern is a regular expression. So when you're using this with regular expressions, you should say with regular expression equals true. All right, so an example here again, I'm removing all the HTML tags from my HTML string. So these are my HTML strings, the resulting text without tags. All right, so here's a final list of the important functions for string manipulation. When you eat on the exams, we'll give you the the key piece of notation as a reference. You don't need to memorize all these functions, but you should be familiar with the kinds of things that they do when I show you a list like this. There are a lot of limitations. Regular expressions. They can be, as you've already seen, pretty confusing. They get pretty complicated. But yet they are one of the more powerful ways for working with complex strings, and they're also very efficient for lots of string manipulation. All right, I think that is it. We finished regular expressions by the the driest lecture of the semester. Next lecture is visualizations, one of the more exciting lectures semester. See you all.",
        "Recent Video": "-\nJoey Gonzalez the, him, his !!\n2024-09-17 12:30:02\n\nv\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n",
        "Retrieved Audio": "",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000",
        "Retrieved Video": "v\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n\nv\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n",
        "Question": "love the spanish guitar",
        "Timestamp": 0,
        "TA Response": "super relaxing in the morning! ",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "It seems like the poll might have been part of an interactive element of the lecture, possibly using a platform like Slido, as indicated in the video context. If it disappeared, it could be due to a temporary glitch or it might have been closed by the instructor. You might want to check if there is a way to access it again through the lecture platform or ask the instructor if it was an intended part of the session.",
        "Recent Audio": "We've spent a lot of time in exploratory data analysis. We've seen how we can manipulate the data. How can we do imputation? How can we make sense of whether our data is in the right format or not? We've seen a lot of string functions, right? The last lecture was a lot of a string functions at regular expressions. What we're going to do today is actually make a visualization of our data set after we do. Bit of data cleaning, so we'll make visualization so that we summarize the trends and then we basically try to understand whether our data is ready for the next phase of. The next phase of the data science life cycle, which is going to be the prediction and inference that we're going to go into pretty quickly in a couple of weeks, we're going to see a lot of modelling in Data 100. So the places that we will do visualization in a data science life cycle as you can see is in two places. I also. Kind of bolded the report decision and solution. So either we make visualization in the EDA phase or we make visualization in the part that will make reports, or we're trying to share our insights with stakeholders or outsiders or outsiders of the data science lifecycle. You have also seen visualization before. So it's not going to be entirely new to how we make visualization and different plots. It's just going to be a different programming library that you will learn.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g27ea4c00798_0_0\nNarges Norouzi\n...\nO\nWhere Are We?\nH\nabo\nT\n6321285\nQuestion &\nData\nProblem\nAcquisition\nFormulation\nPrediction and\nExploratory\nInference\nData Analysis\nReports, Decisions,\nand Solutions\n(today)\nData Wrangling\nWorking with Text Data\nPlots and variables\nViz principles\nIntro to EDA\nRegular Expressions\nSeaborn\nKDE\nTransformations\n(Part I: Processing Data)\n(Part II: Visualizing and Reporting Data)\n6\nHY\n2024-09-19 11:12:31\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nC \u00ba docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112e46d2196_1_483\nNarges Norouzi\n...\nO\nVisualizations in Data 8 (and Data 100, so far)\nYou worked with many types of visualizations throughout Data 8.\n6321285\n# The call is\n# The call is\nDistribution of Birth Weight\n# t.plot(x_Label, y_Label)\n# t.scatter(x_Label, y_Label)\nmovies.plot( 'Year', 'Number of Movies')\nactors. scatter ( \"Number of Movies', 'Total Gross')\nMaternal Smoker\n700\n80\nFalse\nTrue\n600\n4500\n60\n500\n4000\n40\nCount\n400\n3500\nTotal Gross\n300\n3000\n20\nNumber of Movies\n200\n250\n0\n1980 1985 1990 1995 2000 2005 2010 2015\n20\n40\n60\n80\n60\n80\n100\n120\n140\n160\nYear\nNumber of Movies\nBirth Weight\nLine plot\nScatter plot\nHistogram from Homework #1\n7\nC\nHY\nSA\n2024-09-19 11:13:05\n",
        "Retrieved Audio": "Good morning everyone. Welcome back. Welcome to another fun Data 100 lecture. This lecture is a disclaimer has been one of the favorite lectures of a student. So in the post kind of survey, we found that a lot of students like to learn about visualization. So that's what we're going to do today and also on Tuesday of next week.\nBit of data cleaning, so we'll make visualization so that we summarize the trends and then we basically try to understand whether our data is ready for the next phase of.\nSo this is today's going to be our lecture Visualization 1.",
        "Retrieved Notes": "oters tell the truth? How can we predict turnout? -- still remain, but the *Gallup Poll* uses several tactics to mitigate them. Within their sampling frame of \"civilian, non-institutionalized population\u00e2\u0080\u009d of adults in telephone households in continental U.S., they use random digit dialing to include both listed/unlisted phone numbers and to avoid selection bias. Additionally, they use a within-household selection process to randomly select households with one or more adults. If no one answers, re-call mul\n**\"No\"**, then the surveyor knows the **individual didn't cheat**. We assume the individual is comfortable revealing this information. \nGenerally, we can assume that the coin lands heads 50% of the time, masking the remaining 50% of the \"No\" answers. We can therefore **double** the proportion of \"No\" answers to estimate the **true** fraction of \"No\" answers.\n**Election Polls**\nToday, the *Gallup Poll* is one of the leading polls for election results. The many sources of biases -- who responds to polls? Do v\nheads or answer truthfully if tails.\n* **Non-response bias** occurs because people don't always respond to survey requests, which can skew responses. \n    * Example: Only 2.4m out of 10m people responded to the *Literary Digest*'s poll.\n    * How to avoid: Keep surveys short, and be persistent.\n \n**Randomized Response**\nSuppose you want to ask someone a sensitive question: \"Have you ever cheated on an exam?\" An individual may be embarrassed or afraid to answer truthfully and might lie or not answer the ques",
        "Retrieved Video": "g Data)\n(Part II: Visualizing and Reporting Data)\n6\n2024-09-19 11:11:43\n\ng Data)\n(Part II: Visualizing and Reporting Data)\n6\nHY\n2024-09-19 11:12:31\n\nv\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n",
        "Question": "A poll just randomly pull up on my screen and disappeared. Is something wrong ?",
        "Timestamp": 156,
        "TA Response": "Don't worry about it. It was accidentally opened and then immediately closed",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "No, you do not have to get the poll right to receive credit. As long as you submit a response to at least one poll question during the live lecture timeslot, you will receive synchronous attendance credit.",
        "Recent Audio": "instance. So making sure that there is literally 1 to one correspondence between your data set and the summaries that the summary of the distribution that you're creating. So let's put it into practice. This is an example of a bar chart. So we're going to see bar chart in a SEC. But let's take a look at this example and see if this bar chart or this chart shows. Distribution to you or not? This is going to be our kind of first attempt in Data 100, kind of to see a plot, see if a plot communicates all the ideas are not noticed that it has a title. The first way that you make sense of a plot is to read the title. And then you have to also take a look at the axis labels and make sure that you're understanding what's plotted on the X axis, what's plotted on the Y axis. And then this slide, whether this is a distribution or not? 275, I'll wait for 400. That's my guess. All right, cool. No, it is not a distribution. So overwhelming majority of you said no. And the reason is that when we were looking at what's plotted here, what's plotted is. What is it the percentage of teens who say that they ever post about their whatever on social media? And you can think about this as being multi select option that teams can post on about multiple things. So it's not that one individual thing is going to be.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API381006836_0\nNarges Norouzi\nC\n:\n:E Active poll\nSynchronous\nab\nT\n407 83\no\nWhile about half of teens post their\naccomplishments on social media, few\nDoes this chart show a\ndiscuss their religious or political beliefs\ndistribution?\n% of U.S. teens who say they ever post about their_ on\nsocial media\nNO O\n54%\nAccomplishments\n49\nFamily\n44\nYes\nEmotions and\nfeelings\n34\n46%\nDating life\n22\nJoin at\nPersonal problems\n13\nslido.com\nReligious beliefs\n11\n#6321 285\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n2024-09-19 11:21:14\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112d83cfbe6_1_215\nNarges Norouzi\nC\n:\nab/\nT\nWhile about half of teens post their\naccomplishments on social media, few\nDoes this chart show a distribution?\n6321285\ndiscuss their religious or political beliefs\n% of U.S. teens who say they ever post about their_ on\nsocial media\nNo.\nAccomplishments\n49\n.\nThe chart does show percents of\nindividuals in different categories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n",
        "Retrieved Audio": "Distribution to you or not?\nAnd then this slide, whether this is a distribution or not?\nAll right, cool. No, it is not a distribution. So overwhelming majority of you said no. And the reason is that when we were looking at what's plotted here, what's plotted is.",
        "Retrieved Notes": "uestions are launched; or (2) asynchronously using a link provided after lecture.\n\n-   Lecture participation is graded using poll responses on a 0/1 basis.\n    -   Synchronous Participation: complete at least one participation poll question during the live lecture timeslot (11:00am-12:30pm, Tuesdays and Thursdays). As long as you submit a response to at least one poll question in this timeframe, you will receive synchronous attendance credit.\n    -   Asynchronous Participation: complete all participation po\n**\"No\"**, then the surveyor knows the **individual didn't cheat**. We assume the individual is comfortable revealing this information. \nGenerally, we can assume that the coin lands heads 50% of the time, masking the remaining 50% of the \"No\" answers. We can therefore **double** the proportion of \"No\" answers to estimate the **true** fraction of \"No\" answers.\n**Election Polls**\nToday, the *Gallup Poll* is one of the leading polls for election results. The many sources of biases -- who responds to polls? Do v\ntion. One solution is to leverage a randomized response:\nFirst, you can ask the individual to secretly flip a fair coin; you (the surveyor) *don't* know the outcome of the coin flip.\nThen, you ask them to **answer \"Yes\"** if the coin landed heads and to **answer truthfully** if the coin landed tails.\n  \nThe surveyor doesn't know if the **\"Yes\"** means that the **person cheated** or if it means that the **coin landed heads**. The individual's sensitive information remains secret. However, if the response is ",
        "Retrieved Video": "ories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n\nfeelings\n34\n46%\nDating life\n22\nJoin at\nPersonal problems\n13\nslido.com\nReligious beliefs\n11\n#6321 285\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n2024-09-19 11:21:14\n\nher words: How is the variable distributed across all of its possible values?\nThis means that percentages should sum to 100% (if using proportions) and counts should\nsum to the total number of datapoints (if using raw counts).\nLet's see some examples.\n11\nCC\nHY\nNC\nSA\n2024-09-19 11:18:55\n",
        "Question": "Do you have to get the poll right to get credit",
        "Timestamp": 671,
        "TA Response": "No",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "No, you do not have to answer all polls to get credit. For synchronous participation, you only need to complete at least one participation poll question during the live lecture timeslot to receive attendance credit.",
        "Recent Audio": "see if a plot communicates all the ideas are not noticed that it has a title. The first way that you make sense of a plot is to read the title. And then you have to also take a look at the axis labels and make sure that you're understanding what's plotted on the X axis, what's plotted on the Y axis. And then this slide, whether this is a distribution or not? 275, I'll wait for 400. That's my guess. All right, cool. No, it is not a distribution. So overwhelming majority of you said no. And the reason is that when we were looking at what's plotted here, what's plotted is. What is it the percentage of teens who say that they ever post about their whatever on social media? And you can think about this as being multi select option that teams can post on about multiple things. So it's not that one individual thing is going to be. Reflected in a single category versus they can be reflected in multiple categories. So it doesn't meet the criteria that we want that we can basically summarize one individual or 1 instance in one category and then basically calculate the frequency of that that category as the total number of individuals who will ever basically post about that specific category on social media. So that's why this is not the distribution. Let's try this one. So this is the. American adults in each one of the income tiers. Is this a distribution or not?",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112d83cfbe6_1_215\nNarges Norouzi\nC\n:\nab/\nT\nWhile about half of teens post their\naccomplishments on social media, few\nDoes this chart show a distribution?\n6321285\ndiscuss their religious or political beliefs\n% of U.S. teens who say they ever post about their_ on\nsocial media\nNo.\nAccomplishments\n49\n.\nThe chart does show percents of\nindividuals in different categories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112d83cfbe6_1_215\nNarges Norouzi\n...\nO\n: Active poll\nSynchronous\n4\nT\n0 8\nDoes this chart show a\ndistribution?\n\u00b7 Yes\nSHARE OF AMERICAN ADULTS\nIN EACH INCOME TIER\n.\nNo\nUpper\n19%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:07\n",
        "Retrieved Audio": "Distribution to you or not?\nAmerican adults in each one of the income tiers. Is this a distribution or not?\nAnd then this slide, whether this is a distribution or not?",
        "Retrieved Notes": "uestions are launched; or (2) asynchronously using a link provided after lecture.\n\n-   Lecture participation is graded using poll responses on a 0/1 basis.\n    -   Synchronous Participation: complete at least one participation poll question during the live lecture timeslot (11:00am-12:30pm, Tuesdays and Thursdays). As long as you submit a response to at least one poll question in this timeframe, you will receive synchronous attendance credit.\n    -   Asynchronous Participation: complete all participation po\n**\"No\"**, then the surveyor knows the **individual didn't cheat**. We assume the individual is comfortable revealing this information. \nGenerally, we can assume that the coin lands heads 50% of the time, masking the remaining 50% of the \"No\" answers. We can therefore **double** the proportion of \"No\" answers to estimate the **true** fraction of \"No\" answers.\n**Election Polls**\nToday, the *Gallup Poll* is one of the leading polls for election results. The many sources of biases -- who responds to polls? Do v\noters tell the truth? How can we predict turnout? -- still remain, but the *Gallup Poll* uses several tactics to mitigate them. Within their sampling frame of \"civilian, non-institutionalized population\u00e2\u0080\u009d of adults in telephone households in continental U.S., they use random digit dialing to include both listed/unlisted phone numbers and to avoid selection bias. Additionally, they use a within-household selection process to randomly select households with one or more adults. If no one answers, re-call mul",
        "Retrieved Video": "feelings\n34\n46%\nDating life\n22\nJoin at\nPersonal problems\n13\nslido.com\nReligious beliefs\n11\n#6321 285\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n2024-09-19 11:21:14\n\nories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n\nories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n",
        "Question": "Do we have to answer all polls to get credit?",
        "Timestamp": 708,
        "TA Response": "No, the polls will be graded on completion. As long as you answer at least one of the polls during lecture, you get credit.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The first poll wasn't considered a distribution because it involved a multi-select option where individuals could be reflected in multiple categories. This means that it didn't meet the criteria for a distribution, which typically requires that each individual or instance is summarized in one category, allowing for the calculation of the frequency of that category as a total number of individuals. In this case, the data couldn't be neatly categorized into distinct, non-overlapping groups, which is essential for a distribution.",
        "Recent Audio": "see if a plot communicates all the ideas are not noticed that it has a title. The first way that you make sense of a plot is to read the title. And then you have to also take a look at the axis labels and make sure that you're understanding what's plotted on the X axis, what's plotted on the Y axis. And then this slide, whether this is a distribution or not? 275, I'll wait for 400. That's my guess. All right, cool. No, it is not a distribution. So overwhelming majority of you said no. And the reason is that when we were looking at what's plotted here, what's plotted is. What is it the percentage of teens who say that they ever post about their whatever on social media? And you can think about this as being multi select option that teams can post on about multiple things. So it's not that one individual thing is going to be. Reflected in a single category versus they can be reflected in multiple categories. So it doesn't meet the criteria that we want that we can basically summarize one individual or 1 instance in one category and then basically calculate the frequency of that that category as the total number of individuals who will ever basically post about that specific category on social media. So that's why this is not the distribution. Let's try this one. So this is the. American adults in each one of the income tiers. Is this a distribution or not?",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112d83cfbe6_1_215\nNarges Norouzi\n...\nO\n: Active poll\nSynchronous\n4\nT\n0 8\nDoes this chart show a\ndistribution?\n\u00b7 Yes\nSHARE OF AMERICAN ADULTS\nIN EACH INCOME TIER\n.\nNo\nUpper\n19%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n",
        "Retrieved Audio": "And then this slide, whether this is a distribution or not?\nDistribution to you or not?\nAll right, cool. No, it is not a distribution. So overwhelming majority of you said no. And the reason is that when we were looking at what's plotted here, what's plotted is.",
        "Retrieved Notes": "y had a dismal response rate (about 24\\%); who knows how the other non-respondents would have polled? The *Digest* folded just 18 months after this disaster.\nAt the same time, George Gallup, a rising statistician, also made predictions about the 1936 elections. Despite having a smaller sample size of \u00e2\u0080\u009conly\u00e2\u0080\u009d 50,000 (this is still more than necessary; more when we cover the Central Limit Theorem), his estimate that 56\\% of voters would choose Roosevelt was much closer to the actual result (61\\%). Gallup\nt* have been so wrong with their polling?\nIt turns out that the *Literary Digest* sample was not representative of the population. Their sampling frame of people found in phone books, lists of magazine subscribers, and lists of country club members were more affluent and tended to vote Republican. As such, their sampling frame was inherently skewed in Landon's favor. The *Literary Digest* completely overlooked the lion's share of voters who were still suffering through the Great Depression. Furthermore, the\nn population sizes.\n![Sampling_Frames](images/samplingframe.png)\n## Bias: A Case Study\nThe following case study is adapted from *Statistics* by Freedman, Pisani, and Purves, W.W. Norton NY, 1978.\nIn 1936, President Franklin D. Roosevelt (Democratic) went up for re-election against Alf Landon (Republican). As is usual, **polls** were conducted in the months leading up to the election to try and predict the outcome. The *Literary Digest* was a magazine that had successfully predicted the outcome of 5 general ",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112d83cfbe6_1_215\nNarges Norouzi\n...\nO\n: Active poll\nSynchronous\n4\nT\n0 8\nDoes this chart show a\ndistribution?\n\u00b7 Yes\nSHARE OF AMERICAN ADULTS\nIN EACH INCOME TIER\n.\nNo\nUpper\n19%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:07\n",
        "Question": "Why wasn\u2019t the first poll a distribution again?",
        "Timestamp": 729,
        "TA Response": "Have repeat(percentage sum not equal to 100%)",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "I'm here to help with lecture-related questions, but I can't play the guitar. If you have any questions about the lecture content, feel free to ask!",
        "Recent Audio": "The template for. Math plotlet is that it basically gets a sequence. What is a sequence? A sequence can be a list, it can be an array, it can be a serious object or what have you. And then it gets a sequence of items that needs to be plotted on the X axis. It gets a sequence of items that need needs to be plotted on the Y axis. And it will go ahead and plot them and using the proper name of the plot that you want to plot, pass the sequences. It will do its own magic. So the 10 foot for invoking any math plotlet function would be first to import math plot lip. So I say import. Flip that pie plot as PLTI try to remember this alias PLT that we're using for Mac blood lip as a short form for plot. So you just remember that this is kind of the core programming library that we're going to be using. And then the way that I'm invoking it as I'll directly say PLT dot whatever name of the plotting function I have, right? So this is the name of the plotting function. Then I go ahead and pass the sequence of values that I want. Again, the sequence. Any sequence, it can be a list, it can be an array, or it can be a serious object. So let's go ahead and take a look at the example that I wanted to go over. Where is my cursor here? Interesting.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualization | - Google Slides - Googl ...\nScreen Sharing Meeting Controls\nNarges Norouzi\n. +\nOH\n01\n\u010d8\n308\nV\nAudio\nVideo\nParticipants\nChat\nshare\nPause\nAnnotate\nShow webinar\nMore\nYou are screen sharing\nStop share\nGenerating Bar Plots: Matplotlib\nIn Data 100, we will mainly use two libraries for generating plots Malcloth and Seabord\nMost Matploch plotting functions follow the same structure. We pass in a sequence (list,\narray, or Series) of values to be placed on the scans, and a second sequence of values to\nbe plotted on the y-m\nImport\n- -\ngiven the allan plt\npit.plotting function(x values y_values)\n4\nTo add labels and a title\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nplt.title[\"Title of the plot\");\nZoom Workplace\nEpic Pen Content Surface: \\\\\\DISPLAY1\n---\nC\nData 100 Lecture - Narges\n19:00 AM-18:00 AM\nPort:\nData 100 Lecture - Narges\n11:00 AM/12:30 PM\nTravel time\n12:30 PM6-1:00 PM\n1:00 P14-1:30 PM\nProf. Norogn's CH\n1.30PM 2:39 PM\nDesktop 1\nNew desktop\n+\n2024-09-19 11:28:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n->\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_308\nNarges Norouzi\nLec 07 - DS100 Fa24- Visualization I\nA\nA\nA\n194\nSlideshow\nShare\nFile\nDue to heavy collaborator use, some tools for this presentation may become unavailable for larger audiences. Publishing can make files more accessible.\nLearn more\nDismiss\n+\nK\nbackground Layout\nV\nRec\n31\n7\n1\n3\n4\nab\nT\n:\n8\n9\n14\nGenerating Bar Plots: Matplotlib\nDoes this chart show a\ndistribution?\nIn Data 100, we will mainly use two libraries for generating plots: Matplotlib and Seaborn.\n6321285\n15\n-\nMost Matplotlib plotting functions follow the same structure: We pass in a sequence (list,\narray, or Series) of values to be plotted on the x-axis, and a second sequence of values to\nbe plotted on the y-axis.\n16\n+\nMatplotlib is typically\nimport matplotlib. pyplot as plt\ngiven the alias plt\nplt.plotting_function(x_values, y_values)\n17\n-\n--\nTo add labels and a title:\n18\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nStillait\n....\n-\nplt. title(\"Title of the plot\");\n19\n19\nCc\n2024-09-19 11:28:17\n",
        "Retrieved Audio": "We will also try to.\nshows.\n.",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000",
        "Retrieved Video": "v\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n\nv\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n\n\nNC\nSA\n2024-09-19 11:18:17\n",
        "Question": "Can you play the guitar in intermission \ud83d\ude4f\ud83d\udc4d",
        "Timestamp": 1058,
        "TA Response": "please it was fye \ud83d\ude03\ud83d\udd25\ud83e\udd79",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The `%matplotlib inline` command is used in Jupyter notebooks to ensure that plots generated by Matplotlib are displayed directly within the notebook. This command makes it convenient to visualize plots immediately after running the code cells that generate them, without needing to open separate windows or files.",
        "Recent Audio": "that I wanted to go over. Where is my cursor here? Interesting. Keith, I'll go here. And one more thing that I forgot to do is hide this. All right, cool. So we're working on this specific example again, the World Bank data set that we're working with. So as you can see, I'm importing. What is it under? OK. Importing all of the functions that I want and then. Sorry, my laptop is not cooperating. I'm not sure what's going on. Let me reload this. All right, cool. So importing all the functions that we bond, and this is the data set that will be loading. So I'm loading the word bank data set. It's also uploaded on your student repo. So if you take a look at the head of this data set, what you're seeing is that. OK, all of those, the development statistics that we saw, we have 47 different columns. And then I'm showing you the head of. This distribution. Or this data frame, what you're seeing is that I have 166 different countries and again, for all of those 47 columns that we have. So what I want to do next is I want to go ahead and actually calculate the distribution of countries that I have in different continents. How do I calculate the distribution? You remember that we had value counts, right? So what I can say is I can say that I have a word bank data frame. I'm going to go ahead and grab the continent.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n->\n\u00ba% data100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel\nTabs Settings Help\nlec07-demo.ipynb\n+\n...\n+\nDownload Code\nv @ git\n\u00b7 Open i\nO\nK\nK\nK\nO\nT\nA\n[4]:\nwb . shape\n[4]: (166, 47)\nBar Plots\nWe often use bar plots to display distributions of a categorical variable.\nIn the examples below, we plot the distribution of the \"Continent\" column. The cell below uses . value_counts () to determine the number of\ncountries corresponding to each continent in the dataset.\n-\n[ ]:\n# Getting the distribution of the Continent column\nIn Data 8, you used the datascience library to generate plots. The code to plot the distribution of the \"Maternal Smoker\" column may have\nlooked like this:\nfrom datascience import Table\nt = Table. from_df(wb[\"Continent\"] . value_counts().reset_index())\nt. barh(\"index\", \"Continent\")\nIn Data 100, we will use the Matplotlib and Seaborn plotting libraries to create visualizations. First, let's generate a bar plot using the Matplotlib\nfunction plt. bar .\n[ ]: # creating continents Series object\nSimple\n0\n1\nPython 3 (ipykernel) | Idle\nMem: 262.76 / 4096.00 MB\nMode: Edit\n(X\nLn 2, Col 1 lec07-demo.i2024-09-19111:30:26\n\nLec 07 - DS100 Fa24- Visualizat >\nlab? - JupyterLab\n\u00d7\n+\n->\n% data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\nlec07-demo.ipynb\n+\nO\n..\n+\nC\nDownload Markdown v\ngit\n0\nOpen\nK\ncountries corresponding to each continent in the dataset.\nT\n[5]:\n# Getting the distribution of the Continent column\nwb[\"Continent\"] . value_counts ()\n[5]: Continent\nAfrica\n47\nEurope\n43\nAsia\n34\nN. America\n18\nOceania\n13\nS. America\n11\nName: count, dtype: int64\nIn Data 8, you used the datascience library to generate plots. The code to plot the distribution of the \"Maternal Smoker\" column may have\nlooked like this:\nfrom datascience import Table\nt = Table. from_df(wb[\"Continent\"] . value_counts(). reset_index())\nt.barh(\"index\", \"Continent\")\nIn Data 100, we will use the Matplotlib and Seaborn plotting libraries to create visualizations. First, let's generate a bar plot using the Matplotlib\nfunction plt.bar .\n[ ]:\n# creating continents Series object\n[ ]:\n# Plotting the continents in a bar plot\n# Setting axis labels and title\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 262.55 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:31:10\n",
        "Retrieved Audio": "And then this slide, whether this is a distribution or not?\nWhich basically what we're going to do is we're going to talk about why we need to do visualization, what kind of visualization do we need to use, and the actual code that will help us to do to make different visualization plots so that you can make your own plots in different cases. And we're learning some Python libraries and the relationship between those libraries as well. So First off, I'm going to start by talking about why do we care about visualization and what is the goal of visualization?\nTwo main programming library that we'll be using for plotting. You might have heard them, you might have seen us.",
        "Retrieved Notes": "{python}\n#| code-fold: true\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#%matplotlib inline\nplt.rcParams['figure.figsize'] = (12, 9)\nsns.set()\nsns.set_context('talk')\nnp.set_printoptions(threshold=20, precision=2, suppress=True)\npd.set_option('display.max_rows', 30)\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 2)\n# This option stops scientific notation for pandas\npd.set_option('display.float_format', '{:.2f}'.format)\n# Silence\n*<1%** of 738 months), any of these approaches would work.\nHowever there is some appeal to **option C, Imputing**:\n* Shows seasonal trends for CO<sub>2</sub>\n* We are plotting all months in our data as a line plot\nLet's replot our original figure with option 3:\n```{python}\n#| code-fold: true\nsns.lineplot(x='DecDate', y='Avg', data=co2_impute)\nplt.title(\"CO2 Average By Month, Imputed\");\n```\nLooks pretty close to what we see on the NOAA [website](https://gml.noaa.gov/ccgg/trends/)!\n### Presenting the Data: A \nth='600'> -->\n```{python}\n#| code-fold: true\n#| vscode: {languageId: python}\n# Residual visualization\nfig, axs = plt.subplots(2, 2, figsize=(10, 10))\nfor i, dataset in enumerate([\"I\", \"II\", \"III\", \"IV\"]):\n    ans = anscombe[dataset]\n    x, y = ans[\"x\"], ans[\"y\"]\n    ahat, bhat = fit_least_squares(x, y)\n    yhat = predict(x, ahat, bhat)\n    axs[i // 2, i % 2].scatter(\n        x, y - yhat, alpha=0.6, color=\"red\"\n    )  # plot the x, y points\n    axs[i // 2, i % 2].plot(\n        x, np.zeros_like(x), color=\"bla",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_308\nNarges Norouz\n0\n:\nGenerating Bar Plots: Matplotlib\nab,\nT\nIn Data 100, we will mainly use two libraries for generating plots: Matplotlib and Seaborn.\n6321285\n19\ncc 030\nNC\nSA\n2024-09-19 11:26:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_308\nNarges Norouz\n0\n:\nGenerating Bar Plots: Matplotlib\nab,\nT\nIn Data 100, we will mainly use two libraries for generating plots: Matplotlib and Seaborn.\n6321285\n19\ncc 030\nNC\nSA\n2024-09-19 11:26:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_0\nNarges Norouzi\n0\nE\n:\nH\nab/\nT\n6321285\nUnderstand the theories behind effective\nvisualizations and start to generate plots\nof our own\n.\nThe necessary \"pre-thinking\" before\nGoals for this\ncreating a plot\nPython libraries for visualizing data\nLecture\nLecture 7, Data 100 Fall 2024\n3\n2024-09-19 11:11:19\n",
        "Question": "what is this doing? %matplotlib inline",
        "Timestamp": 1229,
        "TA Response": "This just allows us to have our plots output after our code. See this link for more details: https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The poll questions at the end of the lectures are likely part of the asynchronous participation component. As per the lecture notes, asynchronous participation requires completing all participation poll questions provided after the lecture. Therefore, you need to fill those polls to receive asynchronous attendance credit if you did not participate synchronously during the live lecture timeslot.",
        "Recent Audio": "continents dot values. Remember that there were two attributes that I had in a series object index and values. Then if I go ahead and plot, what you'll see is this plot exactly as we intended. But you're also seeing is that this is string thing that is also. Kind of printed out here. This is because if you don't put a semi colon at the end of the last line of your plotting function, it will basically try to plot or or print out whatever the last element that you plot it was. So here it's telling me that it created a bar container object and just talks about something about that specific object that we don't necessarily want. So what I can do is I can go ahead and say I'm going to put a semi colon here, run it again. That the string is now gone. So the other thing that I want to do is remember that I said that every time that you're creating a plot, you want to make sure that you're communicating, communicating every information about the plot with a viewer or someone that you're sending this plot to. Right now, I have some information on those on the X axis, but I need to also be clear that those values are different continents on the Y axis. I should say that that's the count of different countries. And then I also need to have a title. So that's why what we're going to do is we're going to.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat >\nlab? - JupyterLab\n\u00d7\n+\nC \u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n...\n(O\n7\nlec07-demo.ipynb\n+\nT\nabo T\nC\nDownload Markdown v 1 git\n\u00b7 Open in ...\nPython 3 (ipykernel)\nO\nIn Data 100, we will use the Matplotlib and Seaborn plotting libraries to create visualizations. First, let's generate a bar plot using the Matplotlib\nfunction plt.bar .\n[6]:\n# creating continents Series object\ncontinents = wb[\"Continent\"] . value_counts()\n:\n[8]:\n# Plotting the continents in a bar plot\nplt. bar(continents.index, continents. values);\n# Setting axis labels and title\n40 -\n30\n20\n10 -\nX\nSimple\n0\n$.\nPython 3 (ipykernel) | Idle\nMem: 265.33 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\ndata 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n...\n<O\nlec07-demo.ipynb\n+\nabo\nT\na +\nC\nDownload\nMarkdown v @ git\nOpen in ...\nPython 3 (ipykernel)\nO\n[8]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis labels and title\n40\n30\n20 -\n10\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\n-\nNote that we concluded our call to plt. bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle\nMem: 268.08 / 4096.00 MB\nMode: Command\n[X\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:17\n",
        "Retrieved Audio": "Good morning everyone. Welcome back. Welcome to another fun Data 100 lecture. This lecture is a disclaimer has been one of the favorite lectures of a student. So in the post kind of survey, we found that a lot of students like to learn about visualization. So that's what we're going to do today and also on Tuesday of next week.\nMake effective decision in terms of how much time do you want to spend it and how much how much care you should put into the details of the plot that you're creating. So in that sense, these two lectures are divided between the lecture one or today's lecture is just generally talking about different kinds of plots, looking into different types of variables, and then figuring out what is the appropriate type of plot that we can use for those visualizations.\nSo this is kind of the data science life cycle that by now you're all familiar with. We've spent a lot of time in exploratory data analysis. We've seen how we can manipulate the data. How can we do imputation? How can we make sense of whether our data is in the right format or not? We've seen a lot of string functions, right? The last lecture was a lot of a string functions at regular expressions. What we're going to do today is actually make a visualization of our data set after we do.",
        "Retrieved Notes": "uestions are launched; or (2) asynchronously using a link provided after lecture.\n\n-   Lecture participation is graded using poll responses on a 0/1 basis.\n    -   Synchronous Participation: complete at least one participation poll question during the live lecture timeslot (11:00am-12:30pm, Tuesdays and Thursdays). As long as you submit a response to at least one poll question in this timeframe, you will receive synchronous attendance credit.\n    -   Asynchronous Participation: complete all participation po\nuals and households. What is asked and how it is asked can affect how the respondent answers or even whether or not they answer in the first place.\nWhile censuses are great, it is often very difficult and expensive to survey everyone in a population. Imagine the amount of resources, money, time, and energy the U.S. spent on the 2020 Census. While this does give us more accurate information about the population, it's often infeasible to execute. Thus, we usually survey a subset of the population instead.\nA *\ng/faqs/fa24/#i-have-added-the-course-later-in-the-semester-can-i-catch-up-can-i-be-excused-for-all-late-work)\n    21.  [I didn\u00e2\u0080\u0099t turn in a Lab/HW/etc in time because I had X (illness, etc.). Can I have an extension?](https://ds100.org/faqs/fa24/#i-didnt-turn-in-a-labhwetc-in-time-because-i-had-x-illness-etc-can-i-have-an-extension)\n    22.  [I would like to make a class-wide announcement about my project/group/initiative/etc.](https://ds100.org/faqs/fa24/#i-would-like-to-make-a-class-wide-announcement-ab",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112d83cfbe6_1_215\nNarges Norouzi\n...\nO\n: Active poll\nSynchronous\n4\nT\n0 8\nDoes this chart show a\ndistribution?\n\u00b7 Yes\nSHARE OF AMERICAN ADULTS\nIN EACH INCOME TIER\n.\nNo\nUpper\n19%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:07\n",
        "Question": "Why does a poll with all the poll questions appear at the end of the lectures? Do we need to fill those as well? (Happened in the last 2 lectures)",
        "Timestamp": 1437,
        "TA Response": "This is the asynchronous poll for those who did not participate synchronously. If you have answered at least one question during lecture, then you are good to go.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "If you plug in two Series as arguments to a plotting function like `plt.plot` or `plt.bar`, their indices and values will act as coordinates. Typically, the indices of the first Series will be used for the x-axis, and the values of the second Series will be used for the y-axis. This is consistent with how the `plt.bar` function was used in the lecture, where `continents.index` was used for the x-axis and `continents.values` for the y-axis.",
        "Recent Audio": "continents dot values. Remember that there were two attributes that I had in a series object index and values. Then if I go ahead and plot, what you'll see is this plot exactly as we intended. But you're also seeing is that this is string thing that is also. Kind of printed out here. This is because if you don't put a semi colon at the end of the last line of your plotting function, it will basically try to plot or or print out whatever the last element that you plot it was. So here it's telling me that it created a bar container object and just talks about something about that specific object that we don't necessarily want. So what I can do is I can go ahead and say I'm going to put a semi colon here, run it again. That the string is now gone. So the other thing that I want to do is remember that I said that every time that you're creating a plot, you want to make sure that you're communicating, communicating every information about the plot with a viewer or someone that you're sending this plot to. Right now, I have some information on those on the X axis, but I need to also be clear that those values are different continents on the Y axis. I should say that that's the count of different countries. And then I also need to have a title. So that's why what we're going to do is we're going to.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat >\nlab? - JupyterLab\n\u00d7\n+\nC \u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n...\n(O\n7\nlec07-demo.ipynb\n+\nT\nabo T\nC\nDownload Markdown v 1 git\n\u00b7 Open in ...\nPython 3 (ipykernel)\nO\nIn Data 100, we will use the Matplotlib and Seaborn plotting libraries to create visualizations. First, let's generate a bar plot using the Matplotlib\nfunction plt.bar .\n[6]:\n# creating continents Series object\ncontinents = wb[\"Continent\"] . value_counts()\n:\n[8]:\n# Plotting the continents in a bar plot\nplt. bar(continents.index, continents. values);\n# Setting axis labels and title\n40 -\n30\n20\n10 -\nX\nSimple\n0\n$.\nPython 3 (ipykernel) | Idle\nMem: 265.33 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\ndata 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n...\n<O\nlec07-demo.ipynb\n+\nabo\nT\na +\nC\nDownload\nMarkdown v @ git\nOpen in ...\nPython 3 (ipykernel)\nO\n[8]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis labels and title\n40\n30\n20 -\n10\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\n-\nNote that we concluded our call to plt. bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle\nMem: 268.08 / 4096.00 MB\nMode: Command\n[X\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:17\n",
        "Retrieved Audio": "At the top here, so in this series object, the X axis that I want to plot is the index. And then the values are actually going to be the values that I want to input in the Y axis, which is going to be basically deciding about the lengths of each one of those bars that I have. So what I'll do is I'll pass those sequences that I have. So what is the sequence on the X axis? The sequence on the X axis is.\nContinents dot index. So that's the index that I want on the X axis. Then I need to have continents dot values. Remember that there were two attributes that I had in a series object index and values. Then if I go ahead and plot, what you'll see is this plot exactly as we intended. But you're also seeing is that this is string thing that is also.\nContinents dot index. So that's the index that I want on the X axis. Then I need to have continents dot values. Remember that there were two attributes that I had in a series object index and values. Then if I go ahead and plot, what you'll see is this plot exactly as we intended. What you're also seeing is that this is string thing that is also.",
        "Retrieved Notes": "zations and their underlying theory. In doing so, we'll motivate their importance in real-world examples with the use of plotting libraries.\n## Visualizations in Data 8 and Data 100 (so far)\nYou've likely encountered several forms of data visualizations in your studies. You may remember two such examples from Data 8: line plots, scatter plots, and histograms. Each of these served a unique purpose. For example, line plots displayed how numerical quantities changed over time, while histograms were useful in u\nth\");\n```\n##### Overplotting \nAlthough the plots above communicate the general relationship between the two plotted variables, they both suffer a major limitation \u00e2\u0080\u0093 **overplotting**. Overplotting occurs when scatter points with similar values are stacked on top of one another, making it difficult to see the number of scatter points actually plotted in the visualization. Notice how in the upper righthand region of the plots, we cannot easily tell just how many points have been plotted. This makes our visu\n\n2. Identify correlated variables ([interpret](https://docs.google.com/presentation/d/1-aDu0ILCkPx3iCcJGB3YXci-L4g90Q6AarXU6wffLB8/edit#slide=id.g62cb86badb_0_1128) rows of $V^{T}$ as linear coefficients) ([Paper 3](https://www.nature.com/articles/s41598-017-05714-1)). Uses [biplots](<https://www.google.com/url?q=https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/Principal-Component-Analysis/principal-components-basics/Interpretation-and-visualization/index.html%23:~:text%3DThe%2520biplot%2520is%2520a%",
        "Retrieved Video": "e plotted on the y-axis.\nMatplotlib is typically\nimport matplotlib.pyplot as plt\ngiven the alias plt\nplt.plotting_function(x_values, y_values)\n19\nHY\nNC\nSA\n2024-09-19 11:27:10\n\ne plotted on the y-axis.\nMatplotlib is typically\nimport matplotlib.pyplot as plt\ngiven the alias plt\nplt.plotting_function(x_values, y_values)\n19\nHY\nNC\nSA\n2024-09-19 11:27:10\n\nplotted on the y-axis.\nMatplotlib is typically\nimport matplotlib.pyplot as plt\ngiven the alias plt\nplt.plotting_function(x_values, y_values)\n19\nNC\nSA\n2024-09-19 11:27:24\n",
        "Question": "if we plugged in two Series as the arguments to the plotting function, would their values or their indices act as coordinates? ",
        "Timestamp": 1452,
        "TA Response": "It would be their values.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The semicolon at the end of a `plt` line of code in Python is used to suppress the output of the last object that is plotted. Without the semicolon, Python will display extraneous text about the object created by the plotting function, which is generally not needed when you're only interested in the visual output. This extraneous text does not affect the plot itself but can clutter the output, especially in Jupyter notebooks. Including the semicolon is a matter of preference for cleaner output.",
        "Recent Audio": "the plot with a viewer or someone that you're sending this plot to. Right now, I have some information on those on the X axis, but I need to also be clear that those values are different continents on the Y axis. I should say that that's the count of different countries. And then I also need to have a title. So that's why what we're going to do is we're going to. Set some values here. So I'm going to say PLT dot X label to be equal to whatever I'm plotting on the X label. X axis which is going to be continents is what I plotted. I can also see PLT dot Y label and then say this is. Count of the countries. And then I can also say that PLT dot title and then here I would say that. The distribution or distribution of countries and different continents. Right and then, but I'll go and do is put a semi colon at the end of the last plotting function. Plug it again, it doesn't like me to misspell stuff. X label, and then you're seeing that now I have the plot with ** axis label, Y axis label, and also the title for the plot. This is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat >\nlab? - JupyterLab\n\u00d7\n+\n>\n\u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n-\n..\n(O\n_ lec07-demo.ipynb\n+\n*\nT\nabo T\na + x 0\n00\nPC Download Markdown v\n@ git\n\u00b7 Open in ...\nPython 3 (ipykernel)\n[10]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis Labels and title\n:\nplt.xlabel(\"Continents\")\nplt.ylabel (\"Count of the countries\")\nplt. title(\"Distribution of countries in different continents\");\nDistribution of countries in different continents\n40\n30\n20\nCount of the countries\n10 -\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\nContinents\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 274.95 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:35:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba% data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\nO\n...\n7\nlec07-demo.ipynb\nX\n+\n*\nT\na +\nC\nDownload\nMarkdown v\n1\ngit\nOpen in ...\nPython 3 (ipykernel)\nO\n[10]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis Labels and title\nplt.xlabel(\"Continents\")\nplt.ylabel (\"Count of the countries\")\nplt. title(\"Distribution of countries in different continents\");\nDistribution of countries in different continents\n40-\n30\n20\nCount of the countries\n10 -\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\nContinents\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 276.40 / 4096.00 MB\nMode: Command\nLn 1, Col 1\nlec07-demo.i2024-09-19111:35:43\n",
        "Retrieved Audio": "Kind of printed out here. This is because if you don't put a semi colon at the end of the last line of your plotting function, it will basically try to plot or or print out whatever the last element that you plot it was. So here it's telling me that it created a bar container object and just talks about something about that specific object that we don't necessarily want. So what I can do is I can go ahead and say I'm going to put a semi colon here, run it again.\nRight and then, but I'll go and do is put a semi colon at the end of the last plotting function.\nRight and then, but I'll go and do is put a semi colon at the end of the last plotting function.",
        "Retrieved Notes": "eparates each statement with a new line. SQL queries are not impacted by whitespace within the query; this means that SQL code is typically written with a new line after each statement to make things more readable. The semicolon (`;`) indicates the end of a query. There are some \"flavors\" of SQL in which a query will not run if no semicolon is present; however, in Data 100, the SQL version we will use works with or without an ending semicolon. Queries in these notes will end with semicolons to build up good\nodes no additional information about the categories themselves. This is not always true; color may signify meaningful detail in other visualizations. We'll explore this more in-depth during the next lecture.\nBy now, you'll have noticed that each of these plotting libraries have a very different syntax. As with `pandas`, we'll teach you the important methods in `matplotlib` and `seaborn`, but you'll learn more through documentation.\n1. [Matplotlib Documentation](https://matplotlib.org/stable/index.html)\n2. [\nth\");\n```\n##### Overplotting \nAlthough the plots above communicate the general relationship between the two plotted variables, they both suffer a major limitation \u00e2\u0080\u0093 **overplotting**. Overplotting occurs when scatter points with similar values are stacked on top of one another, making it difficult to see the number of scatter points actually plotted in the visualization. Notice how in the upper righthand region of the plots, we cannot easily tell just how many points have been plotted. This makes our visu",
        "Retrieved Video": "ded our call to plt. bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle Mem: 268.07 / 4096.00 MB\nMode: Edit\n(X\nLn 5, Col 6\nlec07-demo. i2024-09-19111:34:55\n\nded our call to plt. bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle Mem: 268.07 / 4096.00 MB\nMode: Edit\n(X\nLn 5, Col 6\nlec07-demo. i2024-09-19111:34:55\n\nolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle\nMem: 268.08 / 4096.00 MB\nMode: Command\n[X\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:17\n",
        "Question": "Is there any relevance of the semicolon at the end of a plt line of code? I saw w/o it, it returns an object, but does that hold any significance?",
        "Timestamp": 1519,
        "TA Response": "No that is just how our plot is being represented under the hood. We do not need to see this most of the time, so we use a semi-colon.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the context of the lecture, `continents.index` is used because it refers to the index of the `Series` object returned by `value_counts()`, which contains the unique continent names. The `value_counts()` method returns a `Series` where the index represents the unique values (in this case, continent names) and the values represent their counts. Therefore, `continents.index` correctly provides the names of the continents for the x-axis of the bar plot. Using `Continent.index` would not be appropriate here as it does not refer to the result of `value_counts()`.",
        "Recent Audio": "the plot with a viewer or someone that you're sending this plot to. Right now, I have some information on those on the X axis, but I need to also be clear that those values are different continents on the Y axis. I should say that that's the count of different countries. And then I also need to have a title. So that's why what we're going to do is we're going to. Set some values here. So I'm going to say PLT dot X label to be equal to whatever I'm plotting on the X label. X axis which is going to be continents is what I plotted. I can also see PLT dot Y label and then say this is. Count of the countries. And then I can also say that PLT dot title and then here I would say that. The distribution or distribution of countries and different continents. Right and then, but I'll go and do is put a semi colon at the end of the last plotting function. Plug it again, it doesn't like me to misspell stuff. X label, and then you're seeing that now I have the plot with ** axis label, Y axis label, and also the title for the plot. This is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat >\nlab? - JupyterLab\n\u00d7\n+\n>\n\u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n-\n..\n(O\n_ lec07-demo.ipynb\n+\n*\nT\nabo T\na + x 0\n00\nPC Download Markdown v\n@ git\n\u00b7 Open in ...\nPython 3 (ipykernel)\n[10]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis Labels and title\n:\nplt.xlabel(\"Continents\")\nplt.ylabel (\"Count of the countries\")\nplt. title(\"Distribution of countries in different continents\");\nDistribution of countries in different continents\n40\n30\n20\nCount of the countries\n10 -\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\nContinents\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 274.95 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:35:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba% data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\nO\n...\n7\nlec07-demo.ipynb\nX\n+\n*\nT\na +\nC\nDownload\nMarkdown v\n1\ngit\nOpen in ...\nPython 3 (ipykernel)\nO\n[10]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis Labels and title\nplt.xlabel(\"Continents\")\nplt.ylabel (\"Count of the countries\")\nplt. title(\"Distribution of countries in different continents\");\nDistribution of countries in different continents\n40-\n30\n20\nCount of the countries\n10 -\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\nContinents\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 276.40 / 4096.00 MB\nMode: Command\nLn 1, Col 1\nlec07-demo.i2024-09-19111:35:43\n",
        "Retrieved Audio": "Continents dot index. So that's the index that I want on the X axis. Then I need to have continents dot values. Remember that there were two attributes that I had in a series object index and values. Then if I go ahead and plot, what you'll see is this plot exactly as we intended. But you're also seeing is that this is string thing that is also.\nThe continent column and I would say value counts and we will be able to see the trend, right? So this is exactly the summary that we wanted. So this is summarizing what are those sets of values that I'll have for the continent and what's the frequency with which each one of them is actually coming up. So the next thing that I want to do is I want to actually go ahead and plot this distribution using a bar plot because why bar plot? Because all of those.\nOr this data frame, what you're seeing is that I have 166 different countries and again, for all of those 47 columns that we have. So what I want to do next is I want to go ahead and actually calculate the distribution of countries that I have in different continents. How do I calculate the distribution? You remember that we had value counts, right? So what I can say is I can say that I have a word bank data frame. I'm going to go ahead and grab the continent.",
        "Retrieved Notes": "ex_col=0)\nwb.head()\n```\nWe can visualize the distribution of the `Continent` column using a bar plot. There are a few ways to do this.\n### Plotting in Pandas\n```{python}\nwb['Continent'].value_counts().plot(kind='bar');\n```\nRecall that `.value_counts()` returns a `Series` with the total count of each unique value. We call `.plot(kind='bar')` on this result to visualize these counts as a bar plot.\nPlotting methods in `pandas` are the least preferred and not supported in Data 100, as their functionality is lim\ns to each hemisphere \u00e2\u0080\u0093 a legend should always be included if color is used to encode information in a visualization!\n```{python}\n# Create a new variable to store the hemisphere in which each country is located\nnorth = [\"Asia\", \"Europe\", \"N. America\"]\nsouth = [\"Africa\", \"Oceania\", \"S. America\"]\nwb.loc[wb[\"Continent\"].isin(north), \"Hemisphere\"] = \"Northern\"\nwb.loc[wb[\"Continent\"].isin(south), \"Hemisphere\"] = \"Southern\"\n```\n```{python}\nsns.histplot(data=wb, x=\"Gross national income per capita, Atlas method:\ndimensions in their index, they can often be difficult to use. \nAnother strategy to aggregate across two columns is to create a pivot table. You saw these back in [Data 8](https://inferentialthinking.com/chapters/08/3/Cross-Classifying_by_More_than_One_Variable.html#pivot-tables-rearranging-the-output-of-group). One set of values is used to create the index of the pivot table; another set is used to define the column names. The values contained in each cell of the table correspond to the aggregated data for",
        "Retrieved Video": "value_counts()\n:\n[8]:\n# Plotting the continents in a bar plot\nplt. bar(continents.index, continents. values);\n# Setting axis labels and title\n40 -\n30\n20\n10 -\nX\nSimple\n0\n$.\nPython 3 (ipykernel) | Idle\nMem: 265.33 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:07\n\nvalue_counts()\n:\n[8]:\n# Plotting the continents in a bar plot\nplt. bar(continents.index, continents. values);\n# Setting axis labels and title\n40 -\n30\n20\n10 -\nX\nSimple\n0\n$.\nPython 3 (ipykernel) | Idle\nMem: 265.33 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:34:07\n\nf\ncountries corresponding to each continent in the dataset.\n# Gattina\nthe distribution of the continent column\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle Mem: 262.97 / 4096.00 MB\nMode: Command\nX\nLn 1, Col 1 lec07-demo.i2024-09-19111:30:17\n",
        "Question": "for the x axis why aren't we using Continent.index instead of continents.index if we want the name of continents and not the value count",
        "Timestamp": 1522,
        "TA Response": "When we generate the value counts from the \"Continents\" column, the index of the resulting series will be the continent labels. That's why we use continents.index, and our resulting call is plt.bar(continents.index, continents.values). The actual Continent DataFrame might have a numerical index.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the context of plotting with libraries like Matplotlib in Python, adding a semicolon at the end of a plotting function suppresses any unnecessary output other than the plot itself. Without the semicolon, the plot will still generate, but you might see extraneous text or information about the plot object. This is similar to SQL, where a semicolon is used to indicate the end of a query, although in SQL, it is more about marking the end of a statement rather than suppressing output.",
        "Recent Audio": "the plot with a viewer or someone that you're sending this plot to. Right now, I have some information on those on the X axis, but I need to also be clear that those values are different continents on the Y axis. I should say that that's the count of different countries. And then I also need to have a title. So that's why what we're going to do is we're going to. Set some values here. So I'm going to say PLT dot X label to be equal to whatever I'm plotting on the X label. X axis which is going to be continents is what I plotted. I can also see PLT dot Y label and then say this is. Count of the countries. And then I can also say that PLT dot title and then here I would say that. The distribution or distribution of countries and different continents. Right and then, but I'll go and do is put a semi colon at the end of the last plotting function. Plug it again, it doesn't like me to misspell stuff. X label, and then you're seeing that now I have the plot with ** axis label, Y axis label, and also the title for the plot. This is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba% data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\nO\n...\n7\nlec07-demo.ipynb\nX\n+\n*\nT\na +\nC\nDownload\nMarkdown v\n1\ngit\nOpen in ...\nPython 3 (ipykernel)\nO\n[10]:\n# Plotting the continents in a bar plot\nplt.bar(continents.index, continents. values);\n# Setting axis Labels and title\nplt.xlabel(\"Continents\")\nplt.ylabel (\"Count of the countries\")\nplt. title(\"Distribution of countries in different continents\");\nDistribution of countries in different continents\n40-\n30\n20\nCount of the countries\n10 -\n0\nAfrica\nEurope\nAsia\nN. America Oceania S. America\nContinents\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 276.40 / 4096.00 MB\nMode: Command\nLn 1, Col 1\nlec07-demo.i2024-09-19111:35:43\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\nG\n\u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n...\n0\nlec07-demo.ipynb\nX\n+\nT\nabo T\na +\nC\nDownload Code\nv 1 git\nOpen in ...\nPython 3 (ipykernel)\nContinents\nNote that we concluded our call to plt . bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nWe also remember to set the axis labels and the title for the plot.\npandas native plotting:\n-\n[ ]:\n# pandas native plotting\nEquivalently, we could use the countplot method of the Seaborn library to create our bar plot.\n[ ] :\n# Seaborn countplot\nAbove, we said that bar plots should only be used to visualize the distribution of a qualitative (categorical) variable. Why is that? Consider what\nhappens when we try to use sns. countplot to visualize a quantitative variable, gross national income per capita.\n[ ]:\nwb ['Gross national income per capita, Atlas method: $: 2016' ]\n[ ]:\nsns. countplot(data=wb, x='Gross national income per capita, Atlas method: $: 2016')\nplt.title(\"GNI distribution for different countries\");\nWhat happened? A bar plot (either plt. bar or sns. countplot ) will create a separate bar for each unique value of a variable. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nSimple\n0\n1 0\nPython 3 (ipykernel) | Idle\nMem: 276.28 / 4096.00 MB\nMode: Edit\nLn 2, Col 1 lec07-demo.i2024-09-19111:36:07\n",
        "Retrieved Audio": "Kind of printed out here. This is because if you don't put a semi colon at the end of the last line of your plotting function, it will basically try to plot or or print out whatever the last element that you plot it was. So here it's telling me that it created a bar container object and just talks about something about that specific object that we don't necessarily want. So what I can do is I can go ahead and say I'm going to put a semi colon here, run it again.\nRight and then, but I'll go and do is put a semi colon at the end of the last plotting function.\nRight and then, but I'll go and do is put a semi colon at the end of the last plotting function.",
        "Retrieved Notes": "eparates each statement with a new line. SQL queries are not impacted by whitespace within the query; this means that SQL code is typically written with a new line after each statement to make things more readable. The semicolon (`;`) indicates the end of a query. There are some \"flavors\" of SQL in which a query will not run if no semicolon is present; however, in Data 100, the SQL version we will use works with or without an ending semicolon. Queries in these notes will end with semicolons to build up good\nle tables, we'll use the (creatively named) `JOIN` keyword. We'll make things easier for now by first considering the simpler `cats` dataset, which consists of the tables `s` and `t`.\n<div style=\"text-align: center;\">\n<img src=\"images/cats.png\" alt='cats' width='500'>\n</div> \nTo perform a join, we amend the `FROM` clause. You can think of this as saying, \"`SELECT` my data `FROM` tables that have  been `JOIN`ed together.\" \nRemember: SQL does not consider newlines or whitespace when interpreting queries. The \n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0012\u0000c\u0000a\u0000s\u0000e\u0000_\u0000s\u0000t\u0000u\u0000d\u0000y\u0000_\u0000c\u0000l\u0000i\u0000m\u0000a\u0000t\u0000eIlocblob\u0000\u0000\u0000\u0010\u0000\u0000\u0000A\u0000\u0000\u0000.\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u0000\u0000\u0000\u0000\u0000\u000e\u0000c\u0000a\u0000s\u0000e\u0000_\u0000s\u0000t\u0000u\u0000d\u0000y\u0000_\u0000H\u0000C\u0000EIlocblob\u0000\u0000\u0000\u0010\u0000\u0000\u0000\u00af\u0000\u0000\u0000.\u00ff\u00ff\u00ff\u00ff\u00ff\u00ff\u0000\u0000\u0000\u0000\u0000\n\u0000c\u0000l\u0000u\u0000s\u0000t\u0000e\u0000r\u0000i\u0000n\u0000gIlo",
        "Retrieved Video": "ded our call to plt. bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle Mem: 268.07 / 4096.00 MB\nMode: Edit\n(X\nLn 5, Col 6\nlec07-demo. i2024-09-19111:34:55\n\nded our call to plt. bar with a semicolon ( ; ). This suppresses any unnecessary output other than the plot. If we do not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle Mem: 268.07 / 4096.00 MB\nMode: Edit\n(X\nLn 5, Col 6\nlec07-demo. i2024-09-19111:34:55\n\not include\na semicolon, the plot will still generate, however, we will see extraneous text as well:\nWe also remember to set the axis labels and the title for the plot.\nSimple\n0\nS.\nPython 3 (ipykernel) | Idle\nMem: 265.46 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:33:34\n",
        "Question": "can you explain what the semicolon does again",
        "Timestamp": 1525,
        "TA Response": "The semicolon is used to prevent output from a code line.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "Yes, you can rotate the labels on the x-axis to be horizontal by using the `plt.xticks()` function with the `rotation` parameter set to 0. For example, after your `.plot()` call, you can add `plt.xticks(rotation=0)` to ensure the labels are displayed horizontally. This will make the x-axis labels easier to read if they are currently displayed vertically.",
        "Recent Audio": "is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward. The other way that I want to show you that we can actually do exactly the same thing is using native pandas plotting. So I could directly go ahead and say that instead of like creating that serious object and getting the index and getting the values, I could directly go ahead and say that. OK, go ahead and grab the continent column and calculate value counts that you actually did. And then I would say that plot a function for me. And then in the plot function, I would say that the kind of plot that you're going to be plotting is a bar plot and simple as that. With pandas native native plotting, we can actually invoke. A map flood lip, the math plotlet framework to do the plotting for us so we did not need to make a separate call for it. Obviously I want to actually go ahead and. Label them properly so that it is automatically labeled. For the X axis, I can go ahead and label it. For the Y axis. I could say that PLT dot Y label be equal to. Counts. Counts and then I would say PLT that title. I would just simply say distribution of countries. Different continents. Auntie Lanes.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n\u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel\nTabs Settings Help\nCO\nK\n..\nlec07-demo.ipynb\n+\nT\nB +% > > + Download Code\nv 1 git\nOpen in ...\n# Python 3 (ipykernel) O\nO\n\u00b7 [11] :\n# pandas native plotting\nwb[\"Continent\"] . value_counts() . plot(kind = \"bar\")\nplt.ylabel (\"counts\")\nplt.title\n[11]: < Axes: xlabel='Continent'>\n40-\n30\n20\n10 -\n0\nAsia\nAfrica\nEurope\nOceania\nAmerica\n. America\nSimple\n0\nPython 3 (ipykernel) | Idle\nMem: 278.08 / 4096.00 MB\nMode: Edit\nX\nLn 4, Col 10 lec07-demo.i2024-09-19111:37:10\n\nLec 07 - DS100 Fa24- Visualizat >\nlab? - JupyterLab\n\u00d7\n+\n>\n\u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n(O\n...\nlec07-demo.ipynb\n+\n*\n8\nT\nab T\na +\nC\nDownload Markdown v\n1\ngit\nOpen in ...\nPython 3 (ipykernel)\nO\n[12]:\n# pandas native plotting\nwb[\"Continent\"] . value_counts() . plot(kind = \"bar\")\nplt.ylabel (\"counts\")\nplt.title(\"Distribution of countries in different continents\");\nDistribution of countries in different continents\n40\n30\ncounts\n20\n10\n0\nAsia\nAfrica\nEurope\nOceania\nN. America\n5. America\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle Mem: 278.08 / 4096.00 MB\nMode: Command\nLn 1, Col 1\nlec07-demo.i2024-09-19111:37:29\n",
        "Retrieved Audio": "X label, and then you're seeing that now I have the plot with ** axis label, Y axis label, and also the title for the plot. This is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward.\nLabel them properly so that it is automatically labeled. For the X axis, I can go ahead and label it. For the Y axis. I could say that PLT dot Y label be equal to.\nThis is going to be our kind of first attempt in Data 100, kind of to see a plot, see if a plot communicates all the ideas are not noticed that it has a title. The first way that you make sense of a plot is to read the title. And then you have to also take a look at the axis labels and make sure that you're understanding what's plotted on the X axis, what's plotted on the Y axis.",
        "Retrieved Notes": "th\");\n```\n##### Overplotting \nAlthough the plots above communicate the general relationship between the two plotted variables, they both suffer a major limitation \u00e2\u0080\u0093 **overplotting**. Overplotting occurs when scatter points with similar values are stacked on top of one another, making it difficult to see the number of scatter points actually plotted in the visualization. Notice how in the upper righthand region of the plots, we cannot easily tell just how many points have been plotted. This makes our visu\n your visualization.\nLet's start by considering the gross national income variable in our plot above. Looking at the y values in the scatter plot, we can see that many large y values are all clumped together, compressing the vertical axis. The scale of the horizontal axis is also being distorted by the few large outlying x values on the right. \n<img src=\"images/horizontal.png\" alt='horizontal' width='450'>\nIf we decreased the size of these outliers relative to the bulk of the data, we could reduce the disto\nnder\", \n    size='num votes',\n    title='Biplot', \n    width=800, \n    height=600, \n    size_max=10,\n    opacity = 0.7,\n    color_discrete_map={'Democrat':'blue', 'Republican':'red', \"Independent\": \"green\"},\n    hover_data=['first', 'last', 'state', 'party', 'gender', 'age'])\nfor (call, pc1, pc2) in loadings.head(20).itertuples():\n    fig.add_scatter(x=[0,pc1], y=[0,pc2], name=call, \n                    mode='lines+markers', textposition='top right',\n                    marker= dict(size=10,symbol= \"arrow-b",
        "Retrieved Video": "l still generate, however, we will see extraneous text as well:\nWe also remember to set the axis labels and the title for the plot.\npandas native plotting:\n[ ]: # pandas native plotting\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle Mem: 262.54 / 4096.00 MB\nMode: Command\n(X\nLn 1, Col 1\nlec07-demo. i2024-09-19111:31:24\n\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nStillait\n....\n-\nplt. title(\"Title of the plot\");\n19\n19\nCc\n2024-09-19 11:28:17\n\nwill still generate, however, we will see extraneous text as well:\nWe also remember to set the axis labels and the title for the plot.\nx\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle\nMem: 265.46 / 4096.00 MB\nMode: Command\nLn 1, Col 1\nlec07-demo. 2024-09-19111:33:43\n",
        "Question": "Using .plot() is there a way to turn the names so there flat like horizontal and not vertical ",
        "Timestamp": 1613,
        "TA Response": "Hi, the usual default is horizontal, but sometimes text overlaps between the bars, so we can set the labels to be diagonal to help with spacing.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In `matplotlib`, functions like `plt.xlabel()`, `plt.ylabel()`, and `plt.title()` are used to modify the current plot after it has been created. This is because `matplotlib` maintains a state machine environment where these functions apply to the most recently created plot. When you call `plt.plotting_func(...)`, it creates a plot, and subsequent calls to `plt.xlabel()`, `plt.ylabel()`, and `plt.title()` modify that plot by adding labels and a title. This design allows for flexibility in modifying plots after their initial creation.",
        "Recent Audio": "way that we're invoking it is a slightly different. The template for us this time with seaborne is that we pass a data frame and then we pass the label for the columns that we want to plot on the X axis and on the Y axis. So we work with labels here. Remember I was telling you that we will work a lot with the labels and not necessarily with integer positions. This is one of those reasons that it's easier to. And what we're plotting using this plot function, how do we import seaborne? We basically say import seaborne as SMS. And that's the usual or usual alias that we use for Seaboard. So the SMS dot plotting function, passing the entire data frame, passing the columns that you want to plot. And that's exactly what we'll be doing. How do we deal with labeling axes and then put a title? We know that it's basically under the hood of math blood lip plot. That is being drawn technically. So what we can do is we can do use the same control, use PLT dot X label, PLT dot Y label, PLT dot title in order to put labels and put title and move on. OK, so let's take a look at what it looks like for us to do exactly the same bar plot kind of plotting that we were doing, but this time doing it with seaborne. So what I'll do is I'll say that SNSI already imported it at the top.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\n% data100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\nO\n7\n...\nlec07-demo.ipynb\nX\n+\n*\nT\nab T\n1\na +\nC\nDownload Markdown v\ngit\nOpen in ...\nPython 3 (ipykernel) O\nEuI\nOce\nN. Ame\nS. Ame\nContinent\nEquivalently, we could use the countplot method of the Seaborn library to create our bar plot.\n[ ] :\n# Seaborn countplot\nAbove, we said that bar plots should only be used to visualize the distribution of a qualitative (categorical) variable. Why is that? Consider what\nhappens when we try to use sns. countplot to visualize a quantitative variable, gross national income per capita.\n[ ]:\nwb['Gross national income per capita, Atlas method: $: 2016' ]\n[ ]:\nsns. countplot(data=wb, x='Gross national income per capita, Atlas method: $: 2016')\nplt.title(\"GNI distribution for different countries\");\nWhat happened? A bar plot (either plt. bar or sns. countplot ) will create a separate bar for each unique value of a variable. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\nHistogram\nBox plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:41:24\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\n>\n\u00ba% data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n7\nE\n...\nlec07-demo.ipynb\n+\n*\nT\nabo T\na + x 0\nC\nDownload\nCode\nV\n1\ngit\nOpen in ...\nPython 3 (ipykernel)\n-\nE\nEuI\nOce\n2\nS. Ame\nContinent\nEquivalently, we could use the countplot method of the Seaborn library to create our bar plot.\n[ ]:\n# Seaborn countplot\nsns.\nAbove, we said that bar plots should only be used to visualize the distribution of a qualitative (categorical) variable. Why is that? Consider what\nhappens when we try to use sns. countplot to visualize a quantitative variable, gross national income per capita.\n[ ]:\nwb['Gross national income per capita, Atlas method: $: 2016' ]\nsns. countplot(data=wb, x='Gross national income per capita, Atlas method: $: 2016')\nplt.title(\"GNI distribution for different countries\");\nWhat happened? A bar plot (either plt. bar or sns. countplot ) will create a separate bar for each unique value of a variable. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\n.\nHistogram\n\u00b7 Box plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n$_\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Edit\n(X\nLn 2, Col 5 lec07-demo.i2024-09-19111:41:29\n",
        "Retrieved Audio": "We can call X label, Y label title, send all of those values to the plotting. We can exactly what you saw was directly called PLT dot bar. Plot the stuff that we want and we want to make sure that the order of the values that we're passing is exactly X 1st and then Y second. Or alternatively you could say that what if I forget the order of passing the values?\nX label, and then you're seeing that now I have the plot with ** axis label, Y axis label, and also the title for the plot. This is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward.\nThat is being drawn technically. So what we can do is we can do use the same control, use PLT dot X label, PLT dot Y label, PLT dot title in order to put labels and put title and move on. OK, so let's take a look at what it looks like for us to do exactly the same bar plot kind of plotting that we were doing, but this time doing it with seaborne. So what I'll do is I'll say that SNSI already imported it at the top.",
        "Retrieved Notes": "odes no additional information about the categories themselves. This is not always true; color may signify meaningful detail in other visualizations. We'll explore this more in-depth during the next lecture.\nBy now, you'll have noticed that each of these plotting libraries have a very different syntax. As with `pandas`, we'll teach you the important methods in `matplotlib` and `seaborn`, but you'll learn more through documentation.\n1. [Matplotlib Documentation](https://matplotlib.org/stable/index.html)\n2. [\nenerate a scatter plot. Notice that, unlike our examples of plotting single-variable distributions, now we specify sequences of values to be plotted along the x-axis *and* the y-axis. \n```{python}\n#| vscode: {languageId: python}\nplt.scatter(wb[\"per capita: % growth: 2016\"], \\\n            wb['Adult literacy rate: Female: % ages 15 and older: 2005-14'])\nplt.xlabel(\"% growth per capita\")\nplt.ylabel(\"Female adult literacy rate\")\nplt.title(\"Female adult literacy against % growth\");\n```\nIn `seaborn`, we call the \nfunction `sns.scatterplot`. We use the `x` and `y` parameters to indicate the values to be plotted along the x and y axes, respectively. By using the `hue` parameter, we can specify a third variable to be used for coloring each scatter point.\n```{python}\n#| vscode: {languageId: python}\nsns.scatterplot(data = wb, x = \"per capita: % growth: 2016\", \\\n               y = \"Adult literacy rate: Female: % ages 15 and older: 2005-14\", \n               hue = \"Continent\")\nplt.title(\"Female adult literacy against % grow",
        "Retrieved Video": "as before:\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nplt. title(\"Title of the plot\");\n22\n2024-09-19 11:41:00\n\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nStillait\n....\n-\nplt. title(\"Title of the plot\");\n19\n19\nCc\n2024-09-19 11:28:17\n\nbefore:\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nplt. title(\"Title of the plot\");\n22\n...\n22\nS\n2024-09-19 11:41:10\n",
        "Question": "why is it the case that we don't pass arguments like \"xlabel\"/\"ylabel\" into the plt.plotting_func(...)? How does plt.xlabel() know to label the existing plot?",
        "Timestamp": 1854,
        "TA Response": "When we call plt.plotting_func(), we generate a plot for that cell. If we called plt.plotting_func() again, it replaces the previous plotting output, so at the end, there is only one plot that is shown (even if there were two calls to plt.plotting_func()). plt.xlabel() will just put a label to the plot that will be shown.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The `fig, ax = plt.subplots()` notation is useful when you want more control over the layout of your plots, especially when creating multiple subplots in a single figure. This approach allows you to customize each subplot individually using methods like `ax.plot()`, `ax.set_title()`, and others. On the other hand, `plt.plot(x, y)` is a simpler approach suitable for creating a single plot quickly without the need for additional customization or when you don't need to manage multiple subplots. Use `plt.subplots()` when you need to handle multiple plots or require more detailed customization of your plot's appearance.",
        "Recent Audio": "I had just only a few. Different quantitative values that I could actually have, nice bars, then I could probably use that. So that's kind of the caveat here that we will try to be aware of. So we saw this count plot, It was nice. We saw that for a quantitative distribution, it might not be helpful. And now we want to see what is a helpful way to visualize the distribution of a quantitative variable. So we're going to talk about in the next part. Boxplot, violin plot, and histograms. It's in histograms a lot, but here we're going to basically see what information we can gather from histograms and how can we summarize information in histograms in today's lecture. So let's start with fox blood and violin plot. Simple syntax. You call SNS dot boxblot or you call SNS dot violent plot, and you will get the boxplot and violent plot. What you're seeing is that generally they communicate the same set of the same set of information. What we're seeing is that the box flood is generally showing you the trend of the distribution of your data. It shows me that, OK, the middle 50% of our data is within that box. And then we're going to talk about different elements that are visualized in the box plot and kind of make sense of what is visualized there. Violin plot is very similar, but it also has the additional channel that this width of this violent part is also encoding some information.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\ndocs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_379\nNarges Norouzi\nBox plots and Violin Plots\n...\nO\n[m] >\nabo T\nBox plots and violin plots display distributions using information about quartiles.\n.\nIn a box plot, the width of the box encodes no meaning.\nIn a violin plot, the width of the \"violin\" indicates the density of datapoints at each value.\n100000\n--\n80000\n80000\n60000\n--\n60000-\n40000\n40000\n20000\n20000\n0 -\n0\nGross national income per capita, Atlas method: $: 2016\nGross national income per capita, Atlas method: $: 2016\nsns.boxplot(data=df, y=\"y_variable\");\nsns.violinplot(data=df, y =\"y_variable\");\nDocumentation]\n[Documentation]\n26\nINC\n2024-09-19 11:45:43\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_445\nNarges Norouzi\nBox plots and Violin Plots\n...\nO\nH\nabo T\nBox plots and violin plots display distributions using information about quartiles.\n.\nIn a box plot, the width of the box encodes no meaning.\nIn a violin plot, the width of the \"violin\" indicates the density of datapoints at each value.\n.\n100000\n--\n80000\n80000 -\n60000\n--\n60000\n-\n40000\n40000\n20000\n20000\n0 -\n0\nGross national income per capita, Atlas method: $: 2016\nGross national income per capita, Atlas method: $: 2016\nsns.boxplot(data=df, y=\"y_variable\");\nsns.violinplot(data=df, y =\"y_variable\");\nDocumentation]\n[Documentation]\n26\n2024-09-19 11:46:26\n",
        "Retrieved Audio": "We can call X label, Y label title, send all of those values to the plotting. We can exactly what you saw was directly called PLT dot bar. Plot the stuff that we want and we want to make sure that the order of the values that we're passing is exactly X 1st and then Y second. Or alternatively you could say that what if I forget the order of passing the values?\nX label, and then you're seeing that now I have the plot with ** axis label, Y axis label, and also the title for the plot. This is going to be the trend that we'll be working with. So every time that we have a map function, we call the function. We pass the sequences of values, we set that X axis label, Y axis label, put the title, and then move forward.\nLabel them properly so that it is automatically labeled. For the X axis, I can go ahead and label it. For the Y axis. I could say that PLT dot Y label be equal to.",
        "Retrieved Notes": "th='600'> -->\n```{python}\n#| code-fold: true\n#| vscode: {languageId: python}\n# Residual visualization\nfig, axs = plt.subplots(2, 2, figsize=(10, 10))\nfor i, dataset in enumerate([\"I\", \"II\", \"III\", \"IV\"]):\n    ans = anscombe[dataset]\n    x, y = ans[\"x\"], ans[\"y\"]\n    ahat, bhat = fit_least_squares(x, y)\n    yhat = predict(x, ahat, bhat)\n    axs[i // 2, i % 2].scatter(\n        x, y - yhat, alpha=0.6, color=\"red\"\n    )  # plot the x, y points\n    axs[i // 2, i % 2].plot(\n        x, np.zeros_like(x), color=\"bla\nenerate a scatter plot. Notice that, unlike our examples of plotting single-variable distributions, now we specify sequences of values to be plotted along the x-axis *and* the y-axis. \n```{python}\n#| vscode: {languageId: python}\nplt.scatter(wb[\"per capita: % growth: 2016\"], \\\n            wb['Adult literacy rate: Female: % ages 15 and older: 2005-14'])\nplt.xlabel(\"% growth per capita\")\nplt.ylabel(\"Female adult literacy rate\")\nplt.title(\"Female adult literacy against % growth\");\n```\nIn `seaborn`, we call the \nited. Instead, future examples will focus on other libraries built specifically for visualizing data. The most well-known library here is `matplotlib`.\n### Plotting in Matplotlib\n```{python}\nimport matplotlib.pyplot as plt # matplotlib is typically given the alias plt\ncontinent = wb['Continent'].value_counts()\nplt.bar(continent.index, continent)\nplt.xlabel('Continent')\nplt.ylabel('Count');\n```\nWhile more code is required to achieve the same result, `matplotlib` is often used over `pandas` for its ability to",
        "Retrieved Video": "to\nbe plotted on the y-axis.\nMatplotlib is typically\nimport matplotlib. pyplot as plt\ngiven the alias plt\nplt. plotting_function(x_values, y_values)\nTo add labels and a title:\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nplt. title(\"Title of the plot\");\n19\n2024-09-19 11:37:48\n\nto\nbe plotted on the y-axis.\nMatplotlib is typically\nimport matplotlib. pyplot as plt\ngiven the alias plt\nplt. plotting_function(x_values, y_values)\nTo add labels and a title:\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nplt. title(\"Title of the plot\");\n19\n2024-09-19 11:37:48\n\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")\nStillait\n....\n-\nplt. title(\"Title of the plot\");\n19\n19\nCc\n2024-09-19 11:28:17\n",
        "Question": "i was taught to do fig, ax=plt.subplots(figsize=(\u2026) and then ax.plot(x,y,\u2026) and then ax.set_title() etc.. when should we use that notation vs plt.plot(x,y) ?",
        "Timestamp": 2153,
        "TA Response": "not entirely sure, but ax helps when you are doing multiple subplots",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "I'm here to help with lecture-related questions, but it seems like you're asking about a Spotify playlist. You might want to reach out to the person who originally shared the playlist link or the group managing it to request a renewal.",
        "Recent Audio": "of the distribution of your data. It shows me that, OK, the middle 50% of our data is within that box. And then we're going to talk about different elements that are visualized in the box plot and kind of make sense of what is visualized there. Violin plot is very similar, but it also has the additional channel that this width of this violent part is also encoding some information. It is a density function on top of a boxplot. So it will tell you that what is the probability or what's the proportion of the data points that are exactly at any given point on that Y axis that you're going up, right? Whereas the boxplot basically tells you that there are some points here, but I'm not going to tell you how many of each do you have, right? But I'm just going to tell you that on aggregate, 50% of your data is within the box. So let's move on and talk a little bit about. What is encoded in box plot and violin plot? So essentially box plot is plotting quartiles. What is the quartile core? That stands for four. So quartile means that we have a data set, we're going to sort it and we're going to chunk it into quarters, right? So when we chunk it into quarters, then what we have is that I'm looking at the distribution and I'm going to say that if I look at the lower 25% of my data or what we call.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_445\nNarges Norouzi\nBox plots and Violin Plots\n...\nO\nH\nabo T\nBox plots and violin plots display distributions using information about quartiles.\n.\nIn a box plot, the width of the box encodes no meaning.\nIn a violin plot, the width of the \"violin\" indicates the density of datapoints at each value.\n.\n100000\n--\n80000\n80000 -\n60000\n--\n60000\n-\n40000\n40000\n20000\n20000\n0 -\n0\nGross national income per capita, Atlas method: $: 2016\nGross national income per capita, Atlas method: $: 2016\nsns.boxplot(data=df, y=\"y_variable\");\nsns.violinplot(data=df, y =\"y_variable\");\nDocumentation]\n[Documentation]\n26\n2024-09-19 11:46:26\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_721\nNarges Norouzi\nQuartiles\n...\nO\nF\nab\nFor a quantitative variable:\nFirst or lower quartile: 25th percentile.\nSecond quartile: 50th percentile (median).\n35\ncategory\nIn the middle 50%\nThird or upper quartile: 75th percentile.\n30 -\nOutside of the middle 50%\n25\nThe interval [first quartile, third quartile] contains\n20\nthe \"middle 50%\" of the data.\nCount\n15\n10\nInterquartile range (IQR) measures spread.\nIQR = third quartile - first quartile.\n5\n0\n-10\n-5\n0\n5\n10\nGross domestic product: % growth : 2016\nThe length of this\nregion is the IQR\n27\nNC\nSA\n2024-09-19 11:47:00\n",
        "Retrieved Audio": "Let me reload this.\nPlug it again, it doesn't like me to misspell stuff.\nWe will also try to.",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000",
        "Retrieved Video": "demo.i2024-09-19111:38:17\n\nv\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n\nv\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nG \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API2142103743_0\nNarges Norouzi\n...\nslido\nO\nO\n7\nV\nab\nT\nJoin at\nslido.com\n#6321 285\n2024-09-19 11:10:41\n",
        "Question": "Can you guys renew the spotify playlist so we can add stuff. The link expired \ud83d\ude14",
        "Timestamp": 2228,
        "TA Response": "There have been a few people adding inappropriate songs. But if you give me the songs you would like to add I am happy to add them for you!",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "A Gaussian distribution, also known as a normal distribution, is a probability distribution that is symmetric about its mean, showing that data near the mean are more frequent in occurrence than data far from the mean. It is characterized by its bell-shaped curve and is defined by two parameters: the mean (average) and the standard deviation (which measures the spread of the distribution). The Gaussian kernel, used in kernel density estimation, is based on this distribution and helps estimate the probability density function of a random variable.",
        "Recent Audio": "center between or center 50% between Q1 and Q3. Can be spread it out 1.5 times. Intercourse one point 1.5 times interquartile range below Q1 and 1.5 times interquartile range above Q3. So let's take a look one more time. We would say that if this is my center of the data, this is where 50% of the data is empirically using some kind of a notion of Gaussian distribution. You can basically say that if I want to be sure that my data is from the same distribution and I'm not including all the outliers. I can extend these legs and I can say that I can go for the duration of 1.5 times interquartile range below the Q1 and 1.5 times interquartile range above Q3 and that's a reasonable range. That reasonable range means that I'm sure with 99.97% that my data should be within this specific range between the upper risk here and the lower risk here. Anything below it and anything below that lower whisker and anything above the upper whisker is going to be an outlier. That means that it's very unlikely that those data sets or data points are from the same distribution or the same trend that we see. So I'm not going to go over why 1.5 times interquartile range, but I want, if you're interested, go and take a look at this link. It's basically an empirical way of saying that how can we make sure that we are summarizing the distribution based on the assumption that.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_729\nNarges Norouzi\nBox Plots\n...\nO\nabd\nA\n10 -\nThird quartile (75th percentile)\n5 -\nSecond quartile (median)\nFirst quartile (25th percentile)\n0 4\n-5 -\nGross domestic product: % growth : 2016\n..\n-10 -\nsns. boxplot(data=wb, y=\"Gross domestic product: % growth : 2016\")\n28\nCC\nHY\nNC\nSA\n2024-09-19 11:50:22\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\nC \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_729\nNarges Norouzi\nBox Plots\n...\nO\nabo T\nA\n10 -\nWhisker: upper quartile + 1.5*IQR\nThird quartile (75th percentile)\nQ3\n5-\nSecond quartile (median)\nQ2\nFirst quartile (25th percentile) Q,\n0 -\nWhisker: lower quartile - 1.5*IQR\n-5 -\nGross domestic product: % growth : 2016\n..\n-10 -\nsns. boxplot(data=wb, y=\"Gross domestic product: % growth : 2016\")\n28\nNC\nSA\n2024-09-19 11:50:50\n",
        "Retrieved Audio": "Learn a specific technique that you haven't seen before. It's called kernel density estimation in order to estimate trends in a distribution. And we're going to talk about what distribution is, but we're going to basically see how we can plot kind of a normalized way of histograms to make sense of the distribution of the trends in the data set. In the second-half, which is on Tuesday's lecture, we're going to come back and we're going to talk about.\nSo I'm not going to go over why 1.5 times interquartile range, but I want if you're interested, go and take a look at this link. It's basically an empirical way of saying that how can we make sure that we are summarizing the distribution based on the assumption that the distribution is is a Gaussian distribution and make sure that any data point that we see, any data point that we sample from this distribution is going to be within.\nThis distribution.",
        "Retrieved Notes": "he most common kernel is the **Gaussian kernel**. The Gaussian kernel is equivalent to the Gaussian probability density function (the Normal distribution), centered at the observed value with a standard deviation of (this is known as the **bandwidth** parameter).\n$$K_a(x, x_i) = \\frac{1}{\\sqrt{2\\pi\\alpha^{2}}}e^{-\\frac{(x-x_i)^{2}}{2\\alpha^{2}}}$$\nIn this formula:\n* $x$ (no subscript) represents any value along the x-axis of our plot\n* $x_i$ represents the $i$ -th datapoint in our dataset. It is one of the \n*probability distribution** from which our dataset was drawn. You may have encountered the idea of a probability distribution in your other classes; if not, we'll discuss it at length in the next lecture. For now, you can think of a probability distribution as a description of how likely it is for us to sample a particular value in our dataset. \nA KDE curve estimates the probability density function of a random variable. Consider the example below, where we have used `sns.displot` to plot both a histogram (\nut a probability distribution or show a histogram, there are some common distributions that come up frequently when doing data science. These distributions are specified by some **parameters**, which are constants that specify the shape of the distribution. In terms of notation, the '~' means \"has the probability distribution of\". \nThese common distributions are listed below:\n1. Bernoulli($p$): If $X$ ~ Bernoulli($p$), then $X$ takes on a value 1 with probability $p$, and 0 with probability $1 - p$. Bernoul",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat\nlab? - JupyterLab\nx | +\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112e46d2196_1_207\nNarges Norouzi\n...\nO\nabo T\n6321285\nLECTURE 7\nVisualization I\nVisualizing distributions and KDEs\nData 100/Data 200, Fall 2024 @ UC Berkeley\nNarges Norouzi and Joseph E. Gonzalez\nContent credit: Acknowledgments\n2\nCC\n2\n> :\nS\n2024-09-19 11:10:50\n\nLec 07 - DS100 Fa24- Visualizat\nlab? - JupyterLab\nx | +\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112e46d2196_1_207\nNarges Norouzi\n...\nO\nabo T\n6321285\nLECTURE 7\nVisualization I\nVisualizing distributions and KDEs\nData 100/Data 200, Fall 2024 @ UC Berkeley\nNarges Norouzi and Joseph E. Gonzalez\nContent credit: Acknowledgments\n2\nCC\n2\n> :\nS\n2024-09-19 11:10:50\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_296\nNarges Norouzi\n...\nO\nDistributions\nabo T\nA distribution describes ...\n6321285\nThe set of values that a variable can possibly take.\nThe frequency with which each value occurs.\n... for a single variable\n11\nHY\nNC\n2024-09-19 11:17:34\n",
        "Question": "what is a gaussian distribution",
        "Timestamp": 2540,
        "TA Response": "It's just the normal curve.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "A violin plot is preferred over a box plot when you want to visualize not only the summary statistics of the data, such as quartiles, but also the distribution and density of the data points. The violin plot provides additional information about the probability density of the data at different values, which can reveal peaks and variations within the data that a box plot might not show. If understanding the distribution shape and density is important for your analysis, a violin plot would be more informative.",
        "Recent Audio": "you want to plot and which axis you want to plot it on. So effectively here I'm saying that I want to plot GDP, right? So this is gross domestic product, and I'm saying that I want to plot that along the Y axis because I am only using one dimension. Effectively, if I would say X equal to GDP, it would give me a violent plot that was horizontal. So that's kind of how you can control whether you want to do a boxplot horizontally or vertically. Question. So the question is what's the use case of violent flood versus the box plot? If you really want to care about the distribution of your data points between between quartiles or generally figure out how extended the likes of this distribution are and then better there are like peaks and whatnot in between Q, in between minimum and Q1 and between Q3 and maximum you might want to do. But otherwise Box Flood is going to summarize everything just equally well. Any other questions? Cool. Seems like easy peasy, right? So it's just making sense of every time that you're seeing a box plot, what are you seeing? And every time that you have a variable qualitative, quantitative, you know why we make certain decisions about each individual, one of them say I want to incur multiple different variables. So, so far we've been thinking about only like encoding or showing one column or the distribution of one variable. Say for example, I want to show.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat\nlab? - JupyterLab\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1932\nNarges Norouzi\nSide-by-side Box and Violin Plots\n...\nO\nabo T\nWhat if we wanted to incorporate a qualitative variable as well? For example, compar\ndistribution of a quantitative continuous variable across different qualitative categories.\n30\nNC\nSA\n2024-09-19 11:55:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1932\nNarges Norouzi\nSide-by-side Box and Violin Plots\n...\n0\nabo\nT\nWhat if we wanted to incorporate a qualitative variable as well? For example, compar\ndistribution of a quantitative continuous variable across different qualitative categories.\nsns. boxplot(data=wb, x=\"Continent\", y=\"Gross domestic product: % growth : 2016\");\n10\n5\nGDP growth:\nquantitative continuous\n0\n-5\nGross domestic product: % growth : 2016\n-10 -\nAfrica\nAsia\nEurope N. America Oceania S. America\nContinent\nContinent: qualitative nominal\n30\nHY\nNC\nSA\n2024-09-19 11:55:53\n",
        "Retrieved Audio": "So that's a summary of the box slot. So that's why we need to visualize our quantitative values using a box plot, because this basically summarized summarizes the entire trend. I don't need to know individual values, but I just need to know the distribution of it. A violin plot essentially plots box plot. And on top of that, it shows you the density function on the curves. So if you look closely, what you're seeing here is that I have.\nBoxplot, violin plot, and histograms.\nWhat we're seeing is that the box flood is generally showing you the trend of the distribution of your data. It shows me that, OK, the middle 50% of our data is within that box. And then we're going to talk about different elements that are visualized in the box plot and kind of make sense of what is visualized there. Violin plot is very similar, but it also has the additional channel that this width of this violent part is also encoding some information.",
        "Retrieved Notes": "y each unique value.\nSpecifically, we can say this histogram suffers from **overplotting** as we are unable to interpret the plot and gain any meaningful insight. \nRather than bar plots, to visualize the distribution of a continuous variable, we use one of the following types of plots:\n- Histogram\n- Box plot\n- Violin plot\n### Box Plots and Violin Plots\nBox plots and violin plots are two very similar kinds of visualizations. Both display the distribution of a variable using information about **quartiles**.\nI\nves. Look closely at the center vertical bar of the violin plot below; the three quartiles and \"whiskers\" are still present!\n```{python}\nsns.violinplot(data=wb, y='Gross domestic product: % growth : 2016');\n```\n### Side-by-Side Box and Violin Plots\nPlotting side-by-side box or violin plots allows us to compare distributions across different categories. In other words, they enable us to plot both a qualitative variable and a quantitative continuous variable in one visualization.\nWith `seaborn`, we can easily\nplot` and `violinplot` to compare two distributions.\n:::\nIn our journey of the data science lifecycle, we have begun to explore the vast world of exploratory data analysis. More recently, we learned how to pre-process data using various data manipulation techniques. As we work towards understanding our data, there is one key component missing in our arsenal \u00e2\u0080\u0094 the ability to visualize and discern relationships in existing data.\nThese next two lectures will introduce you to various examples of data visuali",
        "Retrieved Video": "e. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\nHistogram\nBox plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:41:24\n\nWith a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\n.\nHistogram\n\u00b7 Box plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n$_\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Edit\n(X\nLn 2, Col 5 lec07-demo.i2024-09-19111:41:29\n\nWith a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\n.\nHistogram\n\u00b7 Box plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n$_\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Edit\n(X\nLn 2, Col 5 lec07-demo.i2024-09-19111:41:29\n",
        "Question": "When would we use a violin plot over box plot?",
        "Timestamp": 2734,
        "TA Response": "Violin plots show density of data points at each value via the width of the plot, but box plots don't.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The `sns.histplot` function in Seaborn and the `plt.hist` function in Matplotlib can both be used to create histograms, but they may have different default behaviors regarding the number of bins. Seaborn's `sns.histplot` often provides more flexibility and additional features like automatic bin width selection based on the data distribution, which might result in smaller or more numerous bins compared to Matplotlib's `plt.hist`. Additionally, Seaborn is designed to work well with Pandas DataFrames and often includes enhancements for better visual aesthetics and statistical representation, such as density scaling. You can control the number of bins in both functions by specifying the `bins` parameter.",
        "Recent Audio": "a slightly different syntax, mostly kind of math blood lab use hist function, Seaborne uses hist plot function and. What we have again at the normal kind of setup for calling a Mathlet function, pass X values and basically say that OK, now go ahead and encode all of these X values and under viexus we say that we want the density to be plotted as opposed to the count. Because if you don't provide it, it will basically give you that, OK, you wanted to have X values, I'm going to change them into bins, and then I'm going to just give you the count. But here you're saying that I want density so that there is scale in a way that the area is proportional to to the probability of the data point. For the hist plot, we are using exactly the same kind of trend, passing the data frame, passing the column that we want to actually plot. And then we are also saying that. Statistic that we want to plot is going to be is density instead of count, right? So that's kind of the control that you have. I'll leave it to you to go ahead and take a look at the documentation because there are different controls that you have about what you want to plot on the by axis and so on and so forth. You can also predefine the number of bins that you want to have in each one of the categories instead of the function itself.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_434\nNarges Norouzi\nHistograms in Code\n...\nO\nabo T\nIn Matplotlib [Documentation]: plt.hist(x_values, density=True)\nIn Seaborn [Documentation]: sns.histplot(data=df, x=\"x_column\", stat=\"density\")\nle-5 Distribution of gross national income per capita\nDistribution of gross national income per capita\n0.00010\n7-\n6 -\n0.00008\n5\n0.00006\n4\nDensity\nDensity\n3\n0.00004\n2 -\n0.00002\n1\n0\n0\n20000\n40000\n60000\n80000\n0.00000\n0\n20000\n40000\n60000\n80000\nGross national income per capita\nGross national income per capita, Atlas method: $: 2016\nMatplotlib\nSeaborn\n32\nNC\nSA\n2024-09-19 11:59:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7 | -\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_434\nNarges Norouzi\nHistograms in Code\n...\n0\nabo T\nIn Matplotlib [Documentation]: plt.hist(x_values, density=True)\nIn Seaborn [Documentation]: sns. histplot(data=df, x=\"x_column\", stat=\"density\")\nle-5 Distribution of gross national income per capita\nDistribution of gross national income per capita\n0.00010\n7\n6 -\n0.00008\n5\n0.00006\n4\nDensity\nDensity\n3\n0.00004\n2 -\n0.00002\n1 -\n0\n0\n20000\n40000\n60000\n80000\n0.00000\nGross national income per capita\n0\n20000\n40000\n60000\n80000\nGross national income per capita, Atlas method: $: 2016\nMatplotlib\nSeaborn\n32\nNC\nSA\n2024-09-19 11:59:43\n",
        "Retrieved Audio": "It's in histograms a lot, but here we're going to basically see what information we can gather from histograms and how can we summarize information in histograms in today's lecture. So let's start with fox blood and violin plot. Simple syntax. You call SNS dot boxblot or you call SNS dot violent plot, and you will get the boxplot and violent plot. What you're seeing is that generally they communicate the same set of the same set of information.\nBecause if you don't provide it, it will basically give you that, OK, you wanted to have X values, I'm going to change them into bins, and then I'm going to just give you the count. But here you're saying that I want density so that there is scale in a way that the area is proportional to to the probability of the data point. For the hist plot, we are using exactly the same kind of trend, passing the data frame, passing the column that we want to actually plot. And then we are also saying that.\nBecause if you don't provide it, it will basically give you that, OK, you wanted to have X values, I'm going to change them into bins, and then I'm going to just give you the count. But here you're saying that I want density so that there is scale in a way that the area is proportional to to the probability of the data point. For the hist plot, we are using exactly the same kind of trend, passing the data frame, passing the column that we want to actually plot. And then we are also saying that.",
        "Retrieved Notes": "rate\", stat=\"density\", bins=5)\nplt.title(\"5 histogram bins\");\n```\n```{python}\n# With 10 bins, there seem to be two peaks\nsns.histplot(data=wb, x=\"HIV rate\", stat=\"density\", bins=10)\nplt.title(\"10 histogram bins\");\n```\n```{python}\n# And with 20 bins, it becomes hard to say what counts as a \"peak\"!\nsns.histplot(data=wb, x =\"HIV rate\", stat=\"density\", bins=20)\nplt.title(\"20 histogram bins\");\n```\nIn part, it is these ambiguities that motivate us to consider using Kernel Density Estimation (KDE), which we will e\nn function `sns.stripplot`. A strip plot automatically introduces a small amount of random noise to **jitter** the data. Recall that all values in the `\"WON\"` column are either 1 (won) or 0 (lost) \u00e2\u0080\u0093 if we were to directly plot them without jittering, we would see severe overplotting.\n```{python}\n#| code-fold: true\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.stripplot(data=games, x=\"GOAL_DIFF\", y=\"WON\", orient=\"h\", hue='WON', alpha=0.7)\n# By default, sns.stripplot plots 0, then 1. We invert \ny` to normalize the histogram such that the area under the histogram is equal to 1.\n```{python}\n#| vscode: {languageId: python}\nsns.displot(data=wb, \n            x=\"gni\", \n            kind=\"hist\", \n            stat=\"density\") # default: stat=count and density integrates to 1\nplt.title(\"Distribution of gross national income per capita\");\n```\nNow, what if we want to generate a KDE plot? We can set `kind` = to `\"kde\"`! \n```{python}\n#| vscode: {languageId: python}\nsns.displot(data=wb, \n            x=\"gni\", \n   ",
        "Retrieved Video": "ither plt. bar or sns. countplot ) will create a separate bar for each unique value of a variable. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle\nMem: 290.24 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:43:48\n\nither plt. bar or sns. countplot ) will create a separate bar for each unique value of a variable. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\nSimple\n0\n1 @\nPython 3 (ipykernel) | Idle\nMem: 290.24 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:43:48\n\nens when we try to use sns. countplot to visualize a quantitative variable, gross national income per capita.\n[ ]:\nwb['Gross national income per capita, Atlas method: $: 2016' ]\n[ ]:\nsns. countplot(data=wb, x='Gross national income per capita, Atlas method: $: 2016')\nplt.title(\"GNI distribution for different countries\");\nSimple\n0\n$_\n1 @\nPython 3 (ipykernel) | Idle\nMem: 290.23 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:43:38\n",
        "Question": "why does sns.histplot lead to small bins then plt.hist",
        "Timestamp": 2960,
        "TA Response": "The difference might be in the documentation, and they may have different default bin settings.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "Yes, increasing the number of bars (or bins) in a histogram can provide a more detailed view of the data distribution, similar to how using more rectangles in a Riemann sum can give a more accurate approximation of an integral. However, there's a trade-off: too many bins can lead to overfitting, where the histogram captures noise rather than the underlying distribution. It's important to choose a bin size that balances detail with clarity, often using methods like the Freedman-Diaconis rule or Sturges' formula to determine an appropriate number of bins.",
        "Recent Audio": "a slightly different syntax, mostly kind of math blood lab use hist function, Seaborne uses hist plot function and. What we have again at the normal kind of setup for calling a Mathlet function, pass X values and basically say that OK, now go ahead and encode all of these X values and under viexus we say that we want the density to be plotted as opposed to the count. Because if you don't provide it, it will basically give you that, OK, you wanted to have X values, I'm going to change them into bins, and then I'm going to just give you the count. But here you're saying that I want density so that there is scale in a way that the area is proportional to to the probability of the data point. For the hist plot, we are using exactly the same kind of trend, passing the data frame, passing the column that we want to actually plot. And then we are also saying that. Statistic that we want to plot is going to be is density instead of count, right? So that's kind of the control that you have. I'll leave it to you to go ahead and take a look at the documentation because there are different controls that you have about what you want to plot on the by axis and so on and so forth. You can also predefine the number of bins that you want to have in each one of the categories instead of the function itself.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_434\nNarges Norouzi\nHistograms in Code\n...\nO\nabo T\nIn Matplotlib [Documentation]: plt.hist(x_values, density=True)\nIn Seaborn [Documentation]: sns.histplot(data=df, x=\"x_column\", stat=\"density\")\nle-5 Distribution of gross national income per capita\nDistribution of gross national income per capita\n0.00010\n7-\n6 -\n0.00008\n5\n0.00006\n4\nDensity\nDensity\n3\n0.00004\n2 -\n0.00002\n1\n0\n0\n20000\n40000\n60000\n80000\n0.00000\n0\n20000\n40000\n60000\n80000\nGross national income per capita\nGross national income per capita, Atlas method: $: 2016\nMatplotlib\nSeaborn\n32\nNC\nSA\n2024-09-19 11:59:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7 | -\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_434\nNarges Norouzi\nHistograms in Code\n...\n0\nabo T\nIn Matplotlib [Documentation]: plt.hist(x_values, density=True)\nIn Seaborn [Documentation]: sns. histplot(data=df, x=\"x_column\", stat=\"density\")\nle-5 Distribution of gross national income per capita\nDistribution of gross national income per capita\n0.00010\n7\n6 -\n0.00008\n5\n0.00006\n4\nDensity\nDensity\n3\n0.00004\n2 -\n0.00002\n1 -\n0\n0\n20000\n40000\n60000\n80000\n0.00000\nGross national income per capita\n0\n20000\n40000\n60000\n80000\nGross national income per capita, Atlas method: $: 2016\nMatplotlib\nSeaborn\n32\nNC\nSA\n2024-09-19 11:59:43\n",
        "Retrieved Audio": "Each one of those positions for each one of those bars and then the height of the bars, you're seeing that for most cases it's equal to one, right? Which means that that was a value that only appeared once. So that's not the right way of visualizing quantitative values. So this is one of the reasons that we say bar plot is really good for qualitative, qualitative variable distribution, but not necessarily for quantitative ones. But if I had just only a few.\nSo think about histogram as a way of us sorting the entire quantity that the list of quantitative values that we have been them, right? So you can basically see that there is a bin for anything between zero and for example, 17,000 and so on and so forth. And total we have 5 different bins. And then we are calculating or we're plotting this these bars in a way that the area actually encodes the percentage. So for example, in this case.\nDifferent quantitative values that I could actually have, nice bars, then I could probably use that. So that's kind of the caveat here that we will try to be aware of. So we saw this count plot, It was nice. We saw that for a quantitative distribution, it might not be helpful. And now we want to see what is a helpful way to visualize the distribution of a quantitative variable. So we're going to talk about in the next part.",
        "Retrieved Notes": "_continuous' width='600'>\n</p>\nIf we sum up the total area of the bars/under the density curve, we should get 100%, or 1.\nWe can show the distribution of $Y$ in the following tables. The table on the left lists all possible samples of $s$ and the number of times they can appear ($Y(s)$). We can use this to calculate the values for the table on the right, a **probability distribution table**. \n<p align=\"center\">\n<img src=\"images/distribution.png\" alt='distribution' width='600'>\n</p>\nRather than fully write o\n We can come up with an **empirical estimate** of $\\frac{2}{3}$, though the true probability might be $\\frac{1}{2}$.\nProbabilities are areas. For discrete random variables, the *area of the red bars* represents the probability that a discrete random variable $X$ falls within those values. For continuous random variables, the *area under the curve* represents the probability that a discrete random variable $Y$ falls within those values.\n<p align=\"center\">\n<img src=\"images/probability_areas.png\" alt='discrete\nintuitively makes sense \u00e2\u0080\u0093 if we have already collected more datapoints with a particular value (resulting in a tall histogram bin), it is more likely that, if we randomly sample another datapoint, we will sample one with a similar value (resulting in a high KDE curve).\nThe area under a probability density function should always integrate to 1, representing the fact that the total probability of a distribution should always sum to 100%. Hence, a KDE curve will always have an area under the curve of 1.\n###",
        "Retrieved Video": "e. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\nHistogram\nBox plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo.i2024-09-19111:41:24\n\nparate bar for each unique value of a variable. With a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\n\u00b7 Histogram\n\u00b7\nBox plot\n\u00b7 Violin plot\nDI-L-\nSimple\n0\n1 0\nPython 3 (ipykernel) | Busy Mem: 286.80 / 4096.00 MB\nMode: Command\nLn 1, Col 1\nlec07-demo.i2024-09-19111:42:41\n\nWith a continuous\nvariable, we may not have a finite number of possible values, which can lead to situations where we would need many, many bars to display each\nunique value.\nTo visualize the distribution of a continuous variable, we use a different type of plot:\n.\nHistogram\n\u00b7 Box plot\n\u00b7 Violin plot\nBox Plots and Violin Plots\nSimple\n0\n$_\n1\nPython 3 (ipykernel) | Idle Mem: 281.46 / 4096.00 MB\nMode: Edit\n(X\nLn 2, Col 5 lec07-demo.i2024-09-19111:41:29\n",
        "Question": "in calculus the integral sum is more accurate if we use more bars, would we get a more accurate .hist if we increase the number of bars present?",
        "Timestamp": 2963,
        "TA Response": "By increasing the number of bars in a histogram, we can see a more specific distribution. Having only a few bars may hide the true distribution.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the overlaid histogram example, the grey bars likely represent the overall distribution of the Gross National Income (GNI) without distinguishing between the northern and southern hemispheres. This provides a baseline or reference for comparing the distributions of the two groups (northern and southern) represented by the blue and orange colors.",
        "Recent Audio": "directly say I want 5 bins, I want 10 bins and so on and so forth. So we could also have overlayed histograms in the same way that we had side by side box plots in order to encode 2 variables. If you have two variables that we want to encode, we could actually use the colour or the hue information in order to do that. So what I plotted here is that I calculated whether a country is in the in the northern hemisphere or southern hemisphere and I basically said that OK, I want to look at the GNI. For the Northern hemisphere countries versus the Southern hemisphere countries. And I want to look at the distribution. It plots 1 histogram with one color. It plots another histogram on top of that. That's why we call it overlaid histogram with two different color with two different colors. You can see that the color attribute is going to come from the hemisphere hemisphere column that I created. So it basically says that OK, I'm going to segment the Mason hemisphere. I'm going to basically have the orange one for northern part and then the blue one for the. And additionally, what it will do is it will create this legend for us. Most of the time if color is involved in any way, we might, we might want to add legends so that we add that additional contextual information about what's flooded in orange and what's flooded in blue. And that's called a legend. So.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_400\nNarges Norouzi\nInterpreting Histograms\ny\n...\n0\nK\nabo\nT\nThe skew of a histogram describes the direction in which its \"tail\" extends.\nA distribution with a long right tail is skewed right.\n.\nA distribution with a long left tail is skewed left.\nA histogram with no clear skew is called symmetric.\n0.00010\n0.10\n0.00008\n0.08\n0.00006\n0.06\nDensity\nDensity\n0.00004\n0.04\n0.00002\n0.02\n0.00000\n0.00\n0\n20000\n40000\n60000\n80000\n40\n50\n60\n70\n80\n90\n100\nGross national income per capita, Atlas method: $: 2016\nAccess to an improved water source: % of population: 2015\n34\nNC\nSA\n2024-09-19 12:01:34\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_400\nNarges Norouzi\nInterpreting Histograms\n...\nO\nab T\nThe skew of a histogram describes the direction in which its \"tail\" extends.\nA distribution with a long right tail is skewed right.\n.\nA distribution with a long left tail is skewed left.\nA histogram with no clear skew is called symmetric.\n0.00010\n0.10\n0.00008\n0.08\n0.00006\n0.06\nDensity\nA long right tail\nDensity\n0.00004\n0.04\n0.00002\n0.02\n0.00000\n0.00\n0\n20000\n40000\n60000\n80000\n40\n50\n60\n70\n80\n90\n100\nGross national income per capita, Atlas method: $: 2016\nAccess to an improved water source: % of population: 2015\n34\nNC\nSA\n2024-09-19 12:01:53\n",
        "Retrieved Audio": "So we could also have overlaid histograms in the same way that we had side by side box plots in order to encode 2 variables. If you have two variables that we want to encode, we could actually use the colour or the hue information in order to do that. So what I plotted here is that I calculated whether a country is in the in the northern hemisphere or southern hemisphere. And I basically said that OK, when I look at the GNI.\nFor the northern hemisphere countries versus the southern hemisphere countries, and I want to look at the distribution. It plots 1 histogram with one color. It plots another histogram on top of that. That's why we call it overlaid histogram with two different cult with with two different colors. You can see that the colour attribute is going to come from the hemisphere hemisphere column that I created.\nSo we could also have overlayed histograms in the same way that we had side by side box plots in order to encode 2 variables. If you have two variables that we want to encode, we could actually use the colour or the hue information in order to do that. So what I plotted here is that I calculated whether a country is in the in the northern hemisphere or southern hemisphere and I basically said that OK, I want to look at the GNI.",
        "Retrieved Notes": "y each unique value.\nSpecifically, we can say this histogram suffers from **overplotting** as we are unable to interpret the plot and gain any meaningful insight. \nRather than bar plots, to visualize the distribution of a continuous variable, we use one of the following types of plots:\n- Histogram\n- Box plot\n- Violin plot\n### Box Plots and Violin Plots\nBox plots and violin plots are two very similar kinds of visualizations. Both display the distribution of a variable using information about **quartiles**.\nI\nth\");\n```\n##### Overplotting \nAlthough the plots above communicate the general relationship between the two plotted variables, they both suffer a major limitation \u00e2\u0080\u0093 **overplotting**. Overplotting occurs when scatter points with similar values are stacked on top of one another, making it difficult to see the number of scatter points actually plotted in the visualization. Notice how in the upper righthand region of the plots, we cannot easily tell just how many points have been plotted. This makes our visu\nr reveals the key visual intuition. While the two columns visually span a 2D space as a line, the data does not deviate at all from that singular line. This means that one of the weight columns is redundant! Even given the option to cover the whole 2D space, the data below does not. It might as well not have this dimension, which is why we still do not consider the data below to span more than 1 dimension.\n<center><img src = \"images/dataset3.png\" width=\"400vw\"></center>\nWhat happens when there are outliers?",
        "Retrieved Video": "mine color.\nNorthern\n5\nsns.histplot(data=wb, hue=\"Hemisphere\",\nX=\"Gross national income ... \")\n4\n3\nDensity\n2\nAlways include a legend when color is used to\nencode information!\n1 -\n0\n0\n20000\n40000\n60000\n80000\nGross national income per capita, Atlas method: $: 2016\n33\nNC\n2024-09-19 12:01:19\n\nmine color.\nNorthern\n5\nsns.histplot(data=wb, hue=\"Hemisphere\",\nX=\"Gross national income ... \")\n4\n3\nDensity\n2\nAlways include a legend when color is used to\nencode information!\n1 -\n0\n0\n20000\n40000\n60000\n80000\nGross national income per capita, Atlas method: $: 2016\n33\nNC\n2024-09-19 12:01:19\n\nine color.\nNorthern\n5\nsns.histplot(data=wb, hue=\"Hemisphere\",\nX=\"Gross national income ... \")\n4\n3\nDensity\n2\nAlways include a legend when color is used to\nencode information!\n1 -\n0\n0\n20000\n40000\n60000\n80000\nGross national income per capita, Atlas method: $: 2016\n33\nNC\nSA\n2024-09-19 12:01:14\n",
        "Question": "in the overlain histogram example: blue is southern and orange is northern, what do the grey bars represent?",
        "Timestamp": 3074,
        "TA Response": "The grey is the overlap between the two.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "A bimodal distribution is a specific type of multimodal distribution. Multimodal distributions are those with more than one peak, so a bimodal distribution, having exactly two peaks, fits this definition. Therefore, all bimodal distributions are multimodal, but not all multimodal distributions are bimodal, as multimodal can refer to distributions with more than two peaks.",
        "Recent Audio": "at the trend, look at the histogram and make sure that our data is. Is not left dispute or right is skewed in a sense and our data is kind of normally distributed so that we can work. But it is slightly better. We're going to go into the details of what kind of issues that they can create and how to fix these issues in the next lecture and also in the modeling lectures to come. The additional information that we can gather is Moat mode is basically showing you what are the peaks in your distribution or what are the peaks in your histogram. We can have one peak, we call it unimodel. We can have two peaks, we call it bi model. We can have more than one peak, but we don't go and say. Model and whatnot, we would just call it multi model data sets. So this kind of mode information is going to be exactly what we might want to gather and we might want to summarize in our data. But we're going to see why that's that's important and why we need to summarize it a little bit more to make sure that we understand the mode of our distribution, understanding whether it's unimodal or by model in future lectures and also in modeling lectures particularly. So let's take a 2 minute break, and then after the break I'm going to come back and talk a little bit about how to summarize trends in histograms using kernel density estimates.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\nInterlude\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g3027ada7455_0_0\nM\nNarges Norouzi\nCO\n7 :\nab T\nSky\nSunny side of pyramid\nShady side of pyramid\nOUR RELATIONSHIP ENTERED\nITS DECLINE AT THIS POINT.\nTHAT'S WHEN YOU\nSTARTED GRAPHING\nEVERYTHING.\n3-\nCOINCIDENCE!\nInterlude\nBOX & WHISKER PLOT\nBOX & BEARD PLOT\n>x\nG-RAPH\nHY\nNC\n2024-09-19 12:03:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx | +\nInterlude\n>\nC \u00ba: docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g3027ada7455_0_0\nNarges Norouzi\n[m] >\n...\nC\nab\nif how much door\npainted.\"\nSky\nSunny side of pyramid\nShady side of pyramid\nOUR RELATIONSHIP ENTERED\nITS DECLINE AT THIS POINT.\nTHAT'S WHEN YOU\nSTARTED GRAPHING\nEVERYTHING.\nCOINCIDENCE!\nInterlude\nBOX & WHISKER PLOT\nD\nBOX & BEARD PLOT\n>x\nG-RAPH\nHY\nINC\nSA\n2024-09-19 12:03:43\n",
        "Retrieved Audio": "But it is slightly better. We're going to go into the details of what kind of issues that they can create and how to fix these issues in the next lecture and also in the modeling lectures to come. The additional information that we can gather is Moat mode is basically showing you what are the peaks in your distribution or what are the peaks in your histogram. We can have one peak, we call it unimodel. We can have two peaks, we call it bimodal. We can have more than one pick, but we don't go and.\nModel and whatnot, we would just call it multi model data sets. So this kind of mode information is going to be exactly what we might want to gather and we might want to summarize in our data. But we're going to see why that's that's important and why we need to summarize it a little bit more to make sure that we understand the mode of our distribution, understanding whether it's unimodal or by model in future lectures and also in modeling lectures particularly.\nBut it is slightly better. We're going to go into the details of what kind of issues that they can create and how to fix these issues in the next lecture and also in the modeling lectures to come. The additional information that we can gather is Moat mode is basically showing you what are the peaks in your distribution or what are the peaks in your histogram. We can have one peak, we call it unimodel. We can have two peaks, we call it bi model. We can have more than one peak, but we don't go and say.",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Define a random variable in terms of its distribution\n* Compute the expectation and variance of a random variable\n* Gain familiarity with the Bernoulli and binomial random variables\n:::\nIn the past few lectures, we've examined the role of complexity in influencing model performance. We've considered model complexity in the context of \nnt that lies an abnormally large distance away from other values. Let's make this more concrete. As you may have observed in the box plot infographic earlier, we define **outliers** to be the data points that fall beyond the whiskers. Specifically, values that are less than the \\[$1^{st}$ Quartile $-$ ($1.5\\times$ IQR)\\], or greater than \\[$3^{rd}$ Quartile $+$ ($1.5\\times$ IQR).\\]\n##### Modes\nIn Data 100, we describe a \"mode\" of a histogram as a peak in the distribution. Often, however, it is difficult to \n variable can also be represented using a histogram. If a variable is **continuous**, meaning it can take on infinitely many values, we can illustrate its distribution using a density curve. \n<p align=\"center\">\n<img src=\"images/discrete_continuous.png\" alt='discrete_continuous' width='700'>\n</p>\nWe often don\u00e2\u0080\u0099t know the (true) distribution and instead compute an empirical distribution. If you flip a coin 3 times and get {H, H, T}, you may ask \u00e2\u0080\u0094\u00e2\u0080\u0094 what is the probability that the coin will land heads?",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat\nlab? - JupyterLab\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1932\nNarges Norouzi\nSide-by-side Box and Violin Plots\n...\nO\nabo T\nWhat if we wanted to incorporate a qualitative variable as well? For example, compar\ndistribution of a quantitative continuous variable across different qualitative categories.\n30\nNC\nSA\n2024-09-19 11:55:38\n\nLec 07 - DS100 Fa24- Visualizat\nlab? - JupyterLab\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1932\nNarges Norouzi\nSide-by-side Box and Violin Plots\n...\nO\nabo T\nWhat if we wanted to incorporate a qualitative variable as well? For example, compar\ndistribution of a quantitative continuous variable across different qualitative categories.\n30\nNC\nSA\n2024-09-19 11:55:38\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_296\nNarges Norouzi\n...\nO\nDistributions\nabo T\nA distribution describes ...\n6321285\nThe set of values that a variable can possibly take.\nThe frequency with which each value occurs.\n... for a single variable\n11\nHY\nNC\n2024-09-19 11:17:34\n",
        "Question": "Is a bimodal distribution also considered multimodal? Or is multimodal >2 modes?",
        "Timestamp": 3205,
        "TA Response": "Multimodal is three or more modes.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The context provided discusses election polls, specifically mentioning the Gallup Poll and its methods to mitigate biases. It also references historical polling errors, such as the Literary Digest's failure in 1936, and contrasts it with George Gallup's more accurate prediction. If you are asking about current polls, the context does not provide information on any recent polls.",
        "Recent Audio": "you to think about kernel density estimate and why we need to do that. As like, for example, I have two things on a table. I have two data points, right? And I want to summarize the trends in my data point. Or I have like multiple different bars and I want to summarize it, but I don't want to show the entire data set. Or data points that I have to the users so that they make sense of what's happening. What I can do is I can put a fabric on top of all of these data points and then show them the trend or the shape of that fabric. So depending on the thickness of that fabric, they might even only see the tallest one. Or they might see if the fabric is a little bit lighter in texture. They might also see some of the details of the other peaks or other data points that I have in my trend. So I want you to think about kernel. Estimation as a way that we're trying to put kind of a fabric on top of our our like bars in a histogram and make sense of how can we normalize or how can we give a general visual about what's happening in the trend of our data set. Why is it important in the 1st place? So let me show you why it's important So if I go ahead here and basically say that. These are for the previous part. All right, if.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\n>\ndata 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel Tabs Settings Help\n...\n0\n7\nlec07-demo.ipynb\nX\n+\n*\nT\nabo T\n8 + x 00 > C Download Code\nv 1 git\n\u00b7 Open in ...\nPython 3 (ipykernel)\nsns.histplot(data=wb, x =\"HIV rate\", stat=\"density\", bins=20)\nplt.title(\"20 histogram bins\");\nAs this example illustrates, it is sometimes more useful to understand the general structure of our data, rather than focus on individual observations.\nKernel density estimation helps with this goal.\nKernel Density Estimation\nKernel density estimation (KDE) allows us to \"smooth\" a distribution to display general trends and eliminate noisy, distracting detail.\n[ ]:\n# The smooth curve overlaid on the histogram is a KDE\nsns.displot(data=wb, x=\"HIV rate\", kde=True, stat=\"density\")\nplt.title(\"Histogram and overlaid KDE on HIV rate distribution\");\nTo illustrate the process of constructing a KDE curve, we'll use a fake dataset of just five datapoints, contained in the list points .\n[ ]:\npoints = [2.2, 2.8, 3.7, 5.3, 5.7]\n[ ]: plt.hist(points, bins=range(0, 10, 2), ec='w', density=True);\nLet's define some kernels. We will explain these formulas momentarily. We'll also define some helper functions for visualization purposes.\n[ ]: def gaussian(x, z, a):\n# Gaussian kernel\nreturn (1/np.sqrt(2*np.pi*a ** 2)) * np.exp((-(x- z) ** 2 / (2 * a ** 2)))\ndef boxcar_basic(x, z, a):\n# Boxcar kernel\nSimple\n0\n1\nPython 3 (ipykernel) | Idle\nMem: 289.77 / 4096.00 MB\nMode: Edit\n(X\nLn 2, Col 41\nlec07-demo.i2024-09-19112:06:55\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\n>\n% data100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit\nView\nRun\nKernel Tabs Settings Help\n...\n0\nlec07-demo.ipy\nRun Selected Cell\nShift+Enter\n*\nabo T\n+\nRun Selected Cell and Insert Below\nAlt+Enter\nOpen in ...\nPython 3 (ipykernel)\nRun Selected Cell and Do not Advance\nCtrl+Enter\nsns\nplt\nRun Selected Text or Current Line in Console\nAs\nRun All Above Selected Cell\nthe general structure of our data, rather than focus on individual observations.\nKer\nRun Selected Cell and All Below\nRender All Markdown Cells\nKE\nRun All Cells\nRestart Kernel and Run All Cells ...\nKernel density estimation (KDE) allows us to \"smooth\" a distribution to display general trends and eliminate noisy, distracting detail.\n[19]:\n# The smooth curve overlaid on the histogram is a KDE\nsns.displot(data=wb, x=\"HIV rate\", kde=True, stat=\"density\")\nplt. title(\"Histogram and overlaid KDE on HIV rate distribution\");\nValueError\nTraceback (most recent call last)\nCell In[19], line 2\n1 # The smooth curve overlaid on the histogram is a KDE\n-- > 2 sns.displot(data=wb, x=\"HIV rate\", kde=True, stat=\"density\")\n3 plt.title(\"Histogram and overlaid KDE on HIV rate distribution\");\nFile /srv/conda/envs/notebook/lib/python3.11/site-packages/seaborn/distributions.py : 2125, in displot(data, x, y, hue, row, col, weigh\nts, kind, rug, rug_kws, log_scale, legend, palette, hue_order, hue_norm, color, col_wrap, row_order, col_order, height, aspect, facet\nkws, ** kwargs)\n2111 def displot(\n2112\ndata=None,\n*,\n2113\n# Vector variables\n( ... )\n2122\n** kwargs,\n2123 ) :\nSimple\n0\n1\nPython 3 (ipykernel) | Idle\nMem: 289.79 / 4096.00 MB\nMode: Command\n(X\nLn 3, Col 65\nlec07-demo.i2024-09-19112:07:00\n",
        "Retrieved Audio": "Question.\nOK.\nSo.",
        "Retrieved Notes": "**\"No\"**, then the surveyor knows the **individual didn't cheat**. We assume the individual is comfortable revealing this information. \nGenerally, we can assume that the coin lands heads 50% of the time, masking the remaining 50% of the \"No\" answers. We can therefore **double** the proportion of \"No\" answers to estimate the **true** fraction of \"No\" answers.\n**Election Polls**\nToday, the *Gallup Poll* is one of the leading polls for election results. The many sources of biases -- who responds to polls? Do v\noters tell the truth? How can we predict turnout? -- still remain, but the *Gallup Poll* uses several tactics to mitigate them. Within their sampling frame of \"civilian, non-institutionalized population\u00e2\u0080\u009d of adults in telephone households in continental U.S., they use random digit dialing to include both listed/unlisted phone numbers and to avoid selection bias. Additionally, they use a within-household selection process to randomly select households with one or more adults. If no one answers, re-call mul\ny had a dismal response rate (about 24\\%); who knows how the other non-respondents would have polled? The *Digest* folded just 18 months after this disaster.\nAt the same time, George Gallup, a rising statistician, also made predictions about the 1936 elections. Despite having a smaller sample size of \u00e2\u0080\u009conly\u00e2\u0080\u009d 50,000 (this is still more than necessary; more when we cover the Central Limit Theorem), his estimate that 56\\% of voters would choose Roosevelt was much closer to the actual result (61\\%). Gallup",
        "Retrieved Video": "Narges Norouzi\n2024-09-19 11:29:10\n\nNarges Norouzi\n2024-09-19 11:29:10\n\nfeelings\n34\n46%\nDating life\n22\nJoin at\nPersonal problems\n13\nslido.com\nReligious beliefs\n11\n#6321 285\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n2024-09-19 11:21:14\n",
        "Question": "No polls yet ?",
        "Timestamp": 3379,
        "TA Response": "thats what im saying",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The context provided does not indicate whether there will be another poll. The discussion seems to focus on the methodology and history of polling, particularly the Gallup Poll, and does not mention any upcoming polls.",
        "Recent Audio": "density estimate and why we need to do that. As like, for example, I have two things on a table. I have two data points, right? And I want to summarize the trends in my data point. Or I have like multiple different bars and I want to summarize it, but I don't want to show the entire data set. Or data points that I have to the users so that they make sense of what's happening. What I can do is I can put a fabric on top of all of these data points and then show them the trend or the shape of that fabric. So depending on the thickness of that fabric, they might even only see the tallest one. Or they might see if the fabric is a little bit lighter in texture. They might also see some of the details of the other peaks or other data points that I have in my trend. So I want you to think about kernel. Estimation as a way that we're trying to put kind of a fabric on top of our our like bars in a histogram and make sense of how can we normalize or how can we give a general visual about what's happening in the trend of our data set. Why is it important in the 1st place? So let me show you why it's important So if I go ahead here and basically say that. These are for the previous part. All right, if. Run all above selected cell.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel\nTabs Settings Help\n..\nO\n7\nlec07-demo.ipynb\n+\nab T\na +\nC\nDownload\nCode\n@ git\nOpen in ...\nPython 3 (ipykernel)\nO\n[41]:\n# Rename the very Long column name for convenience\nwb = wb. rename(columns={'Antiretroviral therapy coverage: % of people living with HIV: 2015' : \"HIV rate\"} )\n\u011a\n# With 5 bins, it seems that there is only one peak\nsns.histplot(data=wb, x=\"HIV rate\", stat=\"density\", bins=5)\nplt.title(\"5 histogram bins\");\n5 histogram bins\n0.0200\n0.0175\n0.0150\n0.0125\n0.0100\nDensity\n0.0075\n0.0050\n0.0025\n0.0000\n0\n20\n40\n60\n80\nUN rato\nSimple\n0\n$.\n1\nPython 3 (ipykernel) | Idle Mem: 315.95 / 4096.00 MB\nMode: Command\nLn 3, Col 65\nlec07-demo. i2024-09-19112:07:14\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n% data 100.datahub.berkeley.edu/user/norouzi/lab?\nNarges Norouzi\nFile\nEdit View Run Kernel\nTabs Settings Help\n...\nO\n7\nlec07-demo.ipynb\n+\nab T\n+ x\nC\nDownload\nCode\nv 1 git\n0\n[41]:\n# Rename the very Long column name for convenience\nwb = wb. rename(columns={'Antiretroviral therapy coverage: % of people living with HIV: 2015' : \"HIV rate\"})\n# With 5 bins, it seems that there is only one peak\nsns. histplot(data=wb, x=\"HIV rate\", stat=\"density\", bins=5)\nplt.title(\"5 histogram bins\");\n5 histogram bins\n0.0200\n0.0175\n0.0150\n0.0125\n0.0100\nDensity\n0.0075\n0.0050\n0.0025\n0.0000\n0\n20\n40\n60\n80\nHIV rato\nSimple\n0\n$\nPython 3 (ipykernel) | Idle\nMem: 315.94 / 4096.00 MB\nMode: Command\nLn 3, Col 65\nlec07-demo.i2024-09-19112:07:19\n-\n",
        "Retrieved Audio": "Question.\nOK.\nAnd then this slide, whether this is a distribution or not?",
        "Retrieved Notes": "oters tell the truth? How can we predict turnout? -- still remain, but the *Gallup Poll* uses several tactics to mitigate them. Within their sampling frame of \"civilian, non-institutionalized population\u00e2\u0080\u009d of adults in telephone households in continental U.S., they use random digit dialing to include both listed/unlisted phone numbers and to avoid selection bias. Additionally, they use a within-household selection process to randomly select households with one or more adults. If no one answers, re-call mul\n**\"No\"**, then the surveyor knows the **individual didn't cheat**. We assume the individual is comfortable revealing this information. \nGenerally, we can assume that the coin lands heads 50% of the time, masking the remaining 50% of the \"No\" answers. We can therefore **double** the proportion of \"No\" answers to estimate the **true** fraction of \"No\" answers.\n**Election Polls**\nToday, the *Gallup Poll* is one of the leading polls for election results. The many sources of biases -- who responds to polls? Do v\ny had a dismal response rate (about 24\\%); who knows how the other non-respondents would have polled? The *Digest* folded just 18 months after this disaster.\nAt the same time, George Gallup, a rising statistician, also made predictions about the 1936 elections. Despite having a smaller sample size of \u00e2\u0080\u009conly\u00e2\u0080\u009d 50,000 (this is still more than necessary; more when we cover the Central Limit Theorem), his estimate that 56\\% of voters would choose Roosevelt was much closer to the actual result (61\\%). Gallup",
        "Retrieved Video": "feelings\n34\n46%\nDating life\n22\nJoin at\nPersonal problems\n13\nslido.com\nReligious beliefs\n11\n#6321 285\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n2024-09-19 11:21:14\n\nories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n\nories!\nFamily\n44\n.\nBut, this is not a distribution because\nEmotions and\nfeelings\n34\nindividuals can be in more than one\nDating life\n22\ncategory (see the fine print).\nPersonal problems\n13\nReligious beliefs\n11\nPolitical beliefs\n9\nNone of these\n28\nNote: Respondents were allowed to select multiple options.\nRespondents who did not give an answer are not shown.\nSource: Survey conducted March 7-April 10, 2018.\n\"Teens' Social Media Habits and Experiences\"\nPEW RESEARCH CENTER\n13\nCC 036\nNC\n2024-09-19 11:21:19\n",
        "Question": "is there going to be another poll?",
        "Timestamp": 3403,
        "TA Response": "there have been 2 polls already this lecture. One more is coming",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The kernel in kernel density estimation (KDE) is a function used to approximate the probability distribution of a dataset. It is placed at each data point and represents the likelihood of observing values around that point. The Gaussian kernel, a common choice, is shaped like a bell curve and is centered at each data point with a specified bandwidth that determines its spread. To construct the KDE, all kernels are summed together and normalized so that the total area under the resulting curve equals 1, providing a smooth estimate of the data's distribution.",
        "Recent Audio": "So that's what we want from probability. You can go ahead and calculate that the area under the curve is equal to 1, right? And it makes sense kind of for us to model this exact data point with HIV rate equal to 20 using this spellcare function because it's more likely for you to get something that you think. Is your Grand Prix 'cause you went out in the in the world and you collected the data and as you go to 21 to 22 or 30, then the probability of you observing those samples is going to drop, right? So that's basically what we're basically modeling with this kernel function. But exactly what we want is to model the entire data set, not only a single data point. So what we'll do is we'll basically say that let me put the kernel on top of all of the. Individual data points that I have, right? Because each one of them should be modeled with a probability function. And let me sum up all of those probability function functions in order to build a probability distribution for the entire data set that I have. But the caveat that when you're looking at the entire probability distribution of your data set, you need to make sure that the area under the care of over the entire distribution should be equal to 1, as opposed to here, the probability. The area under the care for this carnal for a single data point is equal to 1, so.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\nC \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_825\nNarges Norouzi\n...\n0\nKernel Density Estimation: Process\nabo T\nIdea: Approximate the probability distribution that generated the data.\n6321285\nPlace a kernel at each data point.\n.\nNormalize kernels so that total area = 1.\nSum all kernels together.\nA kernel is a function that tries to capture the randomness of our sampled data.\n0.08\n0.07\n0.06\n0.05\n0.04\nDensity\n0.03\n0.02\n0.01\n0.00\n0\n5\n10\n15\n20\n25\n30\n35\n40\nHIV rate\n39\nHTY\nNC\n2024-09-19 12:09:43\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nC \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_825\nNarges Norouzi\n:\nKernel Density Estimation: Process\nabo\nT\nIdea: Approximate the probability distribution that generated the data.\n6321285\nPlace a kernel at each data point.\n.\nNormalize kernels so that total area = 1.\nSum all kernels together.\nA kernel is a function that tries to capture the randomness of our sampled data.\n0.08\n0.07\n0.06\n0.05\n0.04\nDensity\n0.03\n0.02\n0.01\n0.00\n0\n5\n10\n15\n20\n25\n30\n35\n40\nHIV rate\n39\nHY\nNC\n2024-09-19 12:09:48\n",
        "Retrieved Audio": "So that was a lot of complicated, but let me tell you how we build a probabilistic notion into visualizing a distribution. So the core part of the kernel density estimation or how we're going to make this estimation is based on a kernel function. What is a kernel function? The kernel function says that I'm a probability function, and this probability function represents that. What is the likelihood that?\nOr data points that I have to the users so that they make sense of what's happening. What I can do is I can put a fabric on top of all of these data points and then show them the trend or the shape of that fabric. So depending on the thickness of that fabric, they might even only see the tallest one. Or they might see if the fabric is a little bit lighter in texture. They might also see some of the details of the other peaks or other data points that I have in my trend. So I want you to think about kernel.\nIs your ground first 'cause you went out in the in the world and you collected the data and as you go to 21 to 22 or 30, then the probability of you observing those samples is going to drop, right? So that's basically what we're basically modeling with this kernel function. But exactly what we want is to model the entire data set, not only a single data point. So what we'll do is we'll basically say that let me put the kernel on top of all of the.",
        "Retrieved Notes": "he most common kernel is the **Gaussian kernel**. The Gaussian kernel is equivalent to the Gaussian probability density function (the Normal distribution), centered at the observed value with a standard deviation of (this is known as the **bandwidth** parameter).\n$$K_a(x, x_i) = \\frac{1}{\\sqrt{2\\pi\\alpha^{2}}}e^{-\\frac{(x-x_i)^{2}}{2\\alpha^{2}}}$$\nIn this formula:\n* $x$ (no subscript) represents any value along the x-axis of our plot\n* $x_i$ represents the $i$ -th datapoint in our dataset. It is one of the \ne server, the kernel will \u00e2\u0080\u009cdie\u00e2\u0080\u009d. This is an indication that there is a mistake in your code that you need to fix.\n\n### [](https://dsc10.com/debugging/#how-do-i-quickly-run-all-the-cells-in-a-notebook)How do I quickly run all the cells in a notebook?\n\nGo to the Cell menu in the top toolbar, then \u00e2\u0080\u009cRun All.\u00e2\u0080\u009d You can also select a certain cell and run all cells before this point, or run all cells after this point. You should run all the cells in your notebook before submitting to confirm that you pa\nea of 1\nAbove, we said that *each* kernel has an area of 1. Earlier, we also said that our goal is to construct a KDE curve using these kernels with a *total* area of 1. If we were to directly sum the kernels as they are, we would produce a KDE curve with an integrated area of (5 kernels) $\\times$ (area of 1 each) = 5. To avoid this, we will **normalize** each of our kernels. This involves multiplying each kernel by $\\frac{1}{\\#\\:\\text{datapoints}}$. \nIn the cell below, we multiply each of our 5 kernels by ",
        "Retrieved Video": "pykernel) | Idle Mem: 261.36 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo i2024-09-19111:28:36\n\npykernel) | Idle Mem: 261.36 / 4096.00 MB\nMode: Command\nLn 1, Col 1 lec07-demo i2024-09-19111:28:36\n\n3 (ipykernel) | Idle Mem: 286.80 / 4096.00 MB\nMode: Command\n[X\nLn 1, Col 1\nlec07-demo.i2024-09-19111:42:31\n",
        "Question": "how does the kernel work? ",
        "Timestamp": 3740,
        "TA Response": "We place a kernel on each datapoint. We then normalize the kernels so that the area sum to one, and we get an approximation of the probability distribution.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "No, the probability distribution for each individual data point does not always have to be a bell curve. In the context of kernel density estimation (KDE), a bell curve (or Gaussian kernel) is often used because it provides a smooth and continuous estimate of the probability distribution. However, other kernel shapes can be used depending on the specific characteristics of the data and the desired properties of the estimate. The choice of kernel affects the smoothness and shape of the resulting density estimate.",
        "Recent Audio": "OK, if I go in the vial and sample it is one over I, I'm getting 1 / n probability that I'm going to get this sample in a data frame of N samples. So that's basically what you're doing, right? And then 1 / n is the maximum probability that you'll get. So that's why the area not the maximum probability or? Share of a given data point that you have. So that's why it makes sense for the area under the cares for each individual point point to be one over north. So I'm going to scale it. Scaling down here is going to give me all of these kernels, which then I can go ahead and sum them up together and then get this kernel density estimate. So that's the entire process. So without looking at the data, I give you 5 data points if you plot kernel density estimation and you plot it with the. That your bandwidth is equal to 1, which is going to be the shape of that bell curve, which is kind of controlling how narrow or how wide that bell cab is going to be. This is going to be the trend that you're getting, which kind of makes sense. What you're expecting here is that you had two peaks here, and then this data point contributes more to these first two samples. And these two samples are kind of more clustered together. So that's where one mode comes here and another higher mode comes before it.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n->\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1003\nNarges Norouzi\nO\n7\nT\n:\nStep 2 - Normalize Kernels\nIn Step 3, We will be summing each of these kernels to produce a probability distribution.\n6321285\nWe want the result to be a valid probability distribution that has area 1.\n.\nWe have 5 different kernels, each with an area 1.\nSo, we normalize by multiplying each kernel by 1/s.\n0.5\n0.5\n0.4\n0.4\n0.3\n0.3\n0.2\n0.2\n0.1\n0.1 -\n0.0\n-2\n0.0\n0\n2\n4\n6\n8\n10\n-2\n0\n2\n4\n6\n8\n10\nEach kernel has area 1.\nEach normalized kernel has density 1/5.\n41\nHY\nNC\n2024-09-19 12:16:17\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\nC\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1011\nNarges Norouz\n0\n7\n:\nStep 3 - Sum the Normalized Kernels\nT\nAt each point in the distribution, add up the values of all kernels. This gives us a smooth curve\n6321285\nwith area 1 - an approximation of a probability distribution!\n0.5\n0.5\n0.4\n0.4\n0.3\n0.3\n0.2\n0.2\n0.1\n0.1\n0.0\n-2\n0\n2\n0.0\n4\n6\n8\n10\n-2\n2\n4\n6\n8\n10\nSum these five normalized curves together.\nThe final KDE curve.\n42\nTY\nNC\n2024-09-19 12:16:26\n",
        "Retrieved Audio": "Individual data points that I have, right? Because each one of them should be modeled with a probability function. And let me sum up all of those probability function functions in order to build a probability distribution for the entire data set that I have. But the caveat that when you're looking at the entire probability distribution of your data set, you need to make sure that the area under the care of over the entire distribution should be equal to 1, as opposed to here, the probability.\nThis a probability function on top of each one of the data points, and then I'll sum up all of those probability functions and scale them in order to make sense of what's the general trend. What's the probability that my data point is going to be sampled? If I go ahead and sample again, I'm going to sample a data point from the exact same distribution.\nSo again, because I want to model each individual data point, but I can do is I can go ahead and say that that nice spell curve, that bell curve shape, which is the Gaussian kernel, I'm going to put it on each individual data point that I have. So here is kind of a random toy example with five different data points that I created. We can plot something like this, which has indicators for different data points using something that's called rock plot. So we're going to see rock plot.",
        "Retrieved Notes": " variable can also be represented using a histogram. If a variable is **continuous**, meaning it can take on infinitely many values, we can illustrate its distribution using a density curve. \n<p align=\"center\">\n<img src=\"images/discrete_continuous.png\" alt='discrete_continuous' width='700'>\n</p>\nWe often don\u00e2\u0080\u0099t know the (true) distribution and instead compute an empirical distribution. If you flip a coin 3 times and get {H, H, T}, you may ask \u00e2\u0080\u0094\u00e2\u0080\u0094 what is the probability that the coin will land heads?\n_continuous' width='600'>\n</p>\nIf we sum up the total area of the bars/under the density curve, we should get 100%, or 1.\nWe can show the distribution of $Y$ in the following tables. The table on the left lists all possible samples of $s$ and the number of times they can appear ($Y(s)$). We can use this to calculate the values for the table on the right, a **probability distribution table**. \n<p align=\"center\">\n<img src=\"images/distribution.png\" alt='distribution' width='600'>\n</p>\nRather than fully write o\n However, what if we happened, by random chance, to draw a sample with a different mean or spread than that of the population? We might get a skewed view of how the population behaves (consider the extreme case where we happen to sample the exact same value $n$ times!). \n<p align=\"center\">\n<img src=\"images/CLTdiff.png\" alt='clt' width='400'>\n</p>\nFor example, notice the difference in variation between these two distributions that are different in sample size. The distribution with a bigger sample size ($n=8",
        "Retrieved Video": "her words: How is the variable distributed across all of its possible values?\nThis means that percentages should sum to 100% (if using proportions) and counts should\nsum to the total number of datapoints (if using raw counts).\nLet's see some examples.\n11\nCC\nHY\nNC\nSA\n2024-09-19 11:18:55\n\nher words: How is the variable distributed across all of its possible values?\nThis means that percentages should sum to 100% (if using proportions) and counts should\nsum to the total number of datapoints (if using raw counts).\nLet's see some examples.\n11\nCC\nHY\nNC\nSA\n2024-09-19 11:18:55\n\nwords: How is the variable distributed across all of its possible values?\nThis means that percentages should sum to 100% (if using proportions) and counts should\nsum to the total number of datapoints (if using raw counts).\nLet's see some examples.\n11\nCC\nO\nHY\nNC\nSA\n2024-09-19 11:19:38\n",
        "Question": "Will the probability distribution for each individual datapoint always be a bell curve? If yes why? ",
        "Timestamp": 3990,
        "TA Response": "No, the probability distribution for each individual datapoint can also have a non-normal distribution (eg uniform, binomial).",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The `bw_method` parameter in the `sns.kdeplot` function specifies the bandwidth of the kernel density estimate (KDE). A bandwidth of 0.65 means that the smoothing applied to the KDE is based on this value, which affects how smooth or spiky the resulting curve will be. A smaller bandwidth results in a more spiky curve, capturing more of the local variations in the data, while a larger bandwidth produces a smoother curve that may overlook some of these variations. The choice of 0.65 is arbitrary and was selected to achieve a visually appealing balance between smoothness and detail in the plot.",
        "Recent Audio": "5 or 6 and now I'm trying to put a fabric on top of them. And that fabric is going to tell me that, OK, you have a peak here or two points that are stacked on top of each other in frequency around 2 and then or three points. And then you have two points that are stacked on top of each other around 6. And that's the trend. So the final result that I'll get. Is something like this. You can plot this kernel density estimate plot using KDE plot. So that's the syntax that was the math behind that. How how do we arrive at it? And this is the kind of the plotting function that we have. So we call seaborne KDE plot. We say that OK, my data set on my data frame is called points. And here I'm saying that my bandwidth is equal to .65. This is like really arbitrary value that I just chose. For this plot to really look good, which basically says that OK, if you have a bandwidth of one, this is going to be the shape of your bell curve. And if you decrease the bandwidth, then basically what you're going to have is that the bandwidth or the standard division is going to get a smaller. So you're going to have a spike here, which is what's happening in this case. On top of the KDE plot. You can call all of these plotting functions on top of each other under the hood.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n->\nG\ndocs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2452bd494f8_0_1\nVarges Norouz!\n0\n...\nResult\nT\n.\nA summary of the distribution using KDE.\nsns . kdeplot (points, bw_method=0.65)\n6321285\nsns. histplot(points,\nstat=\"density\",\nbins=2);\n0.35\n0.5\n0.30\n0.4\n0.25\n0.3-\n0.20\n0.2-\n0.15\nDensity\n0.1\n0.10\n0.05\n0.0\n-2\n0\n2\n4\n6\n8\n10\n0.00\nO\n2\n4\n6\n8\nEach line represents a datapoint in the dataset\nThe density at each point corresponds to the KDE\n(e.g. one country's HIV rate).\ncalculated based on kernels placed on all data points\n43\n2024-09-19 12:18:50\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2452bd494f8_0_1\nNarges Norouz!\n:\nResult\nT\n\u00b7\nA summary of the distribution using KDE.\nsns . kdeplot (points, bw_method=0.65)\n6321285\nsns.histplot(points,\nstat=\"density\",\nbins=2);\n0.35\n0.5\n0.30 -\n0.4\n0.25\n0.3-\n0.20\n0.2-\n0.15\nDensity\n0.1\n0.10\n0.05\n0.0\n-2\n0\n2\n4\n6\n8\n10\n0.00\n0\n2\n4\n6\n8\nEach line represents a datapoint in the dataset\nThe density at each point corresponds to the KDE\n(e.g. one country's HIV rate).\ncalculated based on kernels placed on all data points\n43\nCC 036\nNC\nSA\n2024-09-19 12:18:55\n",
        "Retrieved Audio": "Frank, So what you're seeing in this kernel is that this kernel is a probability function. All of the values is starting from zero all the way to that 40 that I show. They're all positive value, right? So that's what we want from probability. You can go ahead and calculate that the area under the curve is equal to 1, right? And it makes sense kind of for us to model this exact data point with HIV rate equal to 20 using this spellcare function because it's more likely for you to get something that you think.\nIs something like this. You can plot this kernel density estimate plot using KDE plot. So that's the syntax that was the math behind that. How how do we arrive at it? And this is the kind of the plotting function that we have. So we call seaborne KDE plot. We say that OK, my data set on my data frame is called points. And here I'm saying that my bandwidth is equal to .65. This is like really arbitrary value that I just chose.\nIs something like this. You can plot this kernel density estimate plot using KDE plot. So that's the syntax that was the math behind that. How how do we arrive at it? And this is the kind of the plotting function that we have. So we call seaborne KDE plot. We say that OK, my data set on my data frame is called points. And here I'm saying that my bandwidth is equal to .65. This is like really arbitrary value that I just chose.",
        "Retrieved Notes": " than $2.2$; it could also be lower than $2.2$. We make the assumption that any future sampled datapoints will likely be similar in value to the data we've already drawn. This means that our *kernel* \u00e2\u0080\u0093 our description of the probability of randomly sampling any new value \u00e2\u0080\u0093 will be greatest at the datapoint we've already drawn but still have non-zero probability above and below it. The area under any kernel should integrate to 1, representing the total probability of drawing a new datapoint.\nA **bandwi\nss national income per capita, Atlas method: $: 2016':'gni'})\nwb.head()\n```\n```{python}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.displot(data = wb, x = 'HIV rate', \\\n                       kde = True, stat = \"density\")\nplt.title(\"Distribution of HIV rates\");\n```\nNotice that the smooth KDE curve is higher when the histogram bins are taller. You can think of the height of the KDE curve as representing how \"probable\" it is that we randomly sample a datapoint with the corresponding value. This \nmodel to the transformed variables\n* \"Undo\" our transformations to identify the underlying relationship between the original variables\nIn past examples, we used the bulge diagram to help us decide what transformations may be useful. The S-shaped curve we saw above, however, looks nothing like any relationship we've seen in the past. We'll need to think carefully about what transformations will linearize this curve.\n#### 1. Odds\nLet's consider our eventual goal: determining if we should predict a Class of 0 ",
        "Retrieved Video": "\n0.05\n0.04\nDensity\n0.03\n0.02\n0.01\n0.00\n0\n5\n10\n15\n20\n25\n30\n35\n40\nHIV rate\n39\nHTY\nNC\n2024-09-19 12:09:43\n\n10-5) = 78.3%\n2 -\nof all datapoints in the dataset.\nDensity\n1\n0\n0\n20000\n40000\n60000\n80000\nGross national income per capita\n31\nHY\nNC\n2024-09-19 11:56:50\n\neach unique value. This leads to\n1.5\ntoo many bars for continuous data!\ncount\n1.0 -\n0.5 -\n0\nGross national income per capita, Atlas method: $: 2016\n24\nINC\n2024-09-19 11:45:14\n",
        "Question": "why is bw_method = 0.65 and what does this mean",
        "Timestamp": 4101,
        "TA Response": "It refers to the bandwidth of the kernel or the smoothness of the curve. 0.65 is a moderately smooth curve.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "KDE (Kernel Density Estimation) might be tested on exams by asking students to explain the steps involved in creating a KDE plot, such as placing kernels on data points, scaling them, and summing them up. Students might also be asked to interpret or manipulate the KDE formula, which involves understanding the role of the kernel function, bandwidth, and normalization. Additionally, questions could involve comparing KDE with other distribution visualization methods like histograms or ECDFs. Understanding the mathematical concepts behind KDE, such as the impact of bandwidth on the smoothness of the curve, could also be part of the exam.",
        "Recent Audio": "to the steps that we took in order to create the KDE plot. Remember that we had three different steps, so I'm going to put that in one equation and show you what those three steps were. It sounds a little bit complicated, but it is not. So the first step for us was to put the kernel on top of each one of those locations. Right. When I say putting a kernel on top of each one of those locations, that means that we would say that I want a function that is on the X axis. It can take different X values, but it is centered around XI. It is centered around each one of the sample data points that you have because we're putting each one of these kernels on top of each individual data point, so. K alpha X and XI basically is the kernel function. Alpha is the bandwidth of that kernel function. X is a value that it can take. It can be any value on the X axis, XI as various the centre of that curve. So you're basically thinking about putting the curve on each one of the data points. Then what we did was effectively scaling it down. Remember this was scaling it down by a factor of 1 / n if you have N data points. And then the other factor here is that you're going to sum up over all of the possible data points that you had if you have N different data points.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nX\n+\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1173\nNarges Norouzi\n...\n1\nab,\nSummary of KDE\n6321285\n0.5\n2\n3\nK\u0131(x, 2)\nK\u0131(x, 6)\n0.4\nn\n1\n9\nfa(x) =\n1\nS Ka(\", \"i)\n03\n-\n0.2\nn\n0.1\ni=1\n0.0\n-2\n0\n2\n4\n8\n10\nA general \"KDE formula\" function is given above.\nKa(x, Xi) is the kernel function centered on the observation i.\n-\nO\nEach kernel individually has area 1.\nO\nK represents our kernel function of choice. We'll talk about the math of these\nfunctions soon.\n46\nHY\nINC\n2024-09-19 12:23:29\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n+\nX\nC \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1189\nNarges Norouzi\n...\n0\nSummary of KDE\nH\nab\nT\n6321285\n05\n2\n3\nK\u0131(x, 2)\nK\u0131(x, 6\n0.4\nfa (x)\n1\nn\n1\n03\n=\nKa(x, xi)\n0.2\nn\n01\ni == 1\n0.0\n-2\n2\n4\n6\n8\n10\nA general \"KDE formula\" function is given above.\n1\nKa(x, Xi) is the kernel centered on the observation i.\nO\nEach kernel individually has area 1.\nO\nx represents any number on the number line. It is the input to our function.\n2\nn is the number of observed data points that we have.\n0\nWe multiply by 1/n to normalize the kernels so that the total area of the KDE is still 1.\n3\nEach Xi (X1, X2, ..., Xn) represents an observed data point. We sum the kernels for each\ndatapoint to create the final KDE curve.\na is the bandwidth or smoothing parameter.\n47\n2024-09-19 12:24:07\n",
        "Retrieved Audio": "Question.\nThe distribution plot, you can have the ECDF plot as well. So on the other side, let's go back to the steps that we took in order to create the KDE plot. Remember that we had three different steps, so I'm going to put that in one equation and show you what those three steps were. It sounds a little bit complicated, but it is not. So the first step for us was to put the kernel on top of each one of those locations.\nThe distribution plot, you can have the ECDF plot as well. So on the other side, let's go back to the steps that we took in order to create the KDE plot. Remember that we had three different steps, so I'm going to put that in one equation and show you what those three steps were. It sounds a little bit complicated, but it is not. So the first step for us was to put the kernel on top of each one of those locations.",
        "Retrieved Notes": "ck that you are submitting the right part.\n-   Homeworks and projects have both public (visible) and hidden autograder tests. The public tests are mainly sanity checks. For example, a sanity check might verify that the answer you entered is a number as expected, and not a word. The hidden tests generally check for correctness, and are invisible to students while they are completing the assignment.\n-   The primary form of support students will have for homeworks and projects are **office hours** and **Ed**.\n\ngoogle.com/document/d/e/2PACX-1vQm6iUDd-S2reyCNVHNgHKQTr7AqBQTbTEVew2POSvSAQLdpSPJb1OlYWsQ5wuFkVf1yHSVGXcta4Tv/pub)**, curating common exam-related questions we\u00e2\u0080\u0099ve seen on Ed over the past couple semesters, and corresponding staff responses. Feel free to make use of this resource when reviewing past exam questions.\n\n## Course Website\n\nWe will be posting all lecture materials on the course syllabus. In addition, they will also be listed in the following publicly visible [GitHub repository](https://github.\n\n> -   **Midterm** on **Wednesday, October 23** 7-9 PM PST.\n> -   **Final** on **Wednesday, December 18** 8-11 AM PST.\n\n**All exams must be taken in-person.** There will be no alternate exams offered.\n\n### Graduate Final Project\n\nAll students enrolled in the graduate version of the course (CS C200A or Stat C200C, i.e. Data 200; Data 200S) will be graded according to the Graduate grading scheme, which includes a team-based **Graduate Final Project** distributed in the second half of the semester. More detail",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat\nlab? - JupyterLab\nx | +\nX\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g112e46d2196_1_207\nNarges Norouzi\n...\nO\nabo T\n6321285\nLECTURE 7\nVisualization I\nVisualizing distributions and KDEs\nData 100/Data 200, Fall 2024 @ UC Berkeley\nNarges Norouzi and Joseph E. Gonzalez\nContent credit: Acknowledgments\n2\nCC\n2\n> :\nS\n2024-09-19 11:10:50\n\nWe'll talk about the math of these\nfunctions soon.\n46\nHY\nINC\n2024-09-19 12:23:29\n\nWe'll talk about the math of these\nfunctions soon.\n46\nHY\nINC\n2024-09-19 12:23:29\n",
        "Question": "How would KDE be tested on exams?",
        "Timestamp": 4420,
        "TA Response": "Yes, it's in scope.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "You don't need to memorize all the plotting functions and their arguments for the midterm. The focus should be on understanding the general template for using plotting libraries like Matplotlib and Seaborn, as they follow a similar structure. It's more important to know how to choose the appropriate plot for different types of data and how to effectively use visualizations to convey information. Understanding the concepts and being able to apply them is more valuable than memorizing specific function details.",
        "Recent Audio": "around XI. It is centered around each one of the sample data points that you have because we're putting each one of these kernels on top of each individual data point, so. K alpha X and XI basically is the kernel function. Alpha is the bandwidth of that kernel function. X is a value that it can take. It can be any value on the X axis, XI as various the centre of that curve. So you're basically thinking about putting the curve on each one of the data points. Then what we did was effectively scaling it down. Remember this was scaling it down by a factor of 1 / n if you have N data points. And then the other factor here is that you're going to sum up over all of the possible data points that you had if you have N different data points. To put the kernel on top of each individual one of them, that's where your eye comes from. That's why we're, that's where your XI comes from. So put a kernel on top of each one of them and scale it down, sum it up and at the end you have a function. And what is this function? This is a function of ** can take any values and then it, this function is parameterized by alpha because depending on the choice of alpha, then the type of the kernel density. Estimate. The KDE function that you're going to get at the end is going to be different.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n+\nX\nC \u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1189\nNarges Norouzi\n...\n0\nSummary of KDE\nH\nab\nT\n6321285\n05\n2\n3\nK\u0131(x, 2)\nK\u0131(x, 6\n0.4\nfa (x)\n1\nn\n1\n03\n=\nKa(x, xi)\n0.2\nn\n01\ni == 1\n0.0\n-2\n2\n4\n6\n8\n10\nA general \"KDE formula\" function is given above.\n1\nKa(x, Xi) is the kernel centered on the observation i.\nO\nEach kernel individually has area 1.\nO\nx represents any number on the number line. It is the input to our function.\n2\nn is the number of observed data points that we have.\n0\nWe multiply by 1/n to normalize the kernels so that the total area of the KDE is still 1.\n3\nEach Xi (X1, X2, ..., Xn) represents an observed data point. We sum the kernels for each\ndatapoint to create the final KDE curve.\na is the bandwidth or smoothing parameter.\n47\n2024-09-19 12:24:07\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1358\nNarges Norouzi\n...\nE\nO\nKernels\nabo T\nA kernel (for our purposes) is a valid density function,\n6321285\nmeaning:\nIt must be non-negative for all inputs.\nIt must integrate to 1(area under curve = 1).\n48\nNC\nSA\n2024-09-19 12:24:41\n",
        "Retrieved Audio": "Of the bar plot. Then you can basically use everything that we're teaching you. So count plot.\nMake effective decision in terms of how much time do you want to spend it and how much how much care you should put into the details of the plot that you're creating. So in that sense, these two lectures are divided between the lecture one or today's lecture is just generally talking about different kinds of plots, looking into different types of variables, and then figuring out what is the appropriate type of plot that we can use for those visualizations.\nImporting them in In some of the notebooks, we're going to talk about math, plot, Lib, and seaborne, and the good thing about them is that each one of them follow a specific template for different flooding functions. It's just that the name of the function that plots different types of plots is going to be different, but the template for how we invoke them is going to be exactly the same or mostly the same. The template for.",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Define a random variable in terms of its distribution\n* Compute the expectation and variance of a random variable\n* Gain familiarity with the Bernoulli and binomial random variables\n:::\nIn the past few lectures, we've examined the role of complexity in influencing model performance. We've considered model complexity in the context of \nd we strongly recommend spending time covering the prerequisite material yourself. We will assume that you have prior knowledge of these requirements and that these resources are simply to refresh your memory of concepts that you have previously learned. Please reach out to staff if you have any questions or concerns about this.\n\n**Calculus**: In terms of calculus, you will need to know a few things, most of which are covered within the space of the first homework and lab. Specifically, you will need to kno\nzations and their underlying theory. In doing so, we'll motivate their importance in real-world examples with the use of plotting libraries.\n## Visualizations in Data 8 and Data 100 (so far)\nYou've likely encountered several forms of data visualizations in your studies. You may remember two such examples from Data 8: line plots, scatter plots, and histograms. Each of these served a unique purpose. For example, line plots displayed how numerical quantities changed over time, while histograms were useful in u",
        "Retrieved Video": "choice. We'll talk about the math of these\nfunctions soon.\n46\nNC\nSA\n2024-09-19 12:23:14\n\nchoice. We'll talk about the math of these\nfunctions soon.\n46\nNC\nSA\n2024-09-19 12:23:14\n\nta 100:\nChoosing the \"right\" plot for\nStylizing plots appropriately\n.\nIntroducing plots for different variable\n. .\nSmoothing and transforming visual data\ntypes\nProviding context through labeling and\nGenerating these plots through code\ncolor\n9\nHY\nINC\n2024-09-19 11:16:36\n",
        "Question": "Do we have to memorize all of these plotting functions along with their arguments in terms of preparing for midterm?",
        "Timestamp": 4442,
        "TA Response": "These will be on the reference sheet provided for exams.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "Increasing alpha in kernel density estimation (KDE) affects the bandwidth of the Gaussian kernel, which is analogous to the width of each bin in a histogram. A larger alpha results in a wider kernel, which smooths out the distribution by averaging over a larger range of data points. This reduces the impact of noise and small fluctuations, leading to a smoother curve. However, it can also obscure important distributional features like multimodality.",
        "Recent Audio": "probability sharply because the denominator is large, right? So that's how you can make sense of why alpha controls the bandwidth. And because you're dropping sharply, is going to be making a very kind of. Makes a very kind of centered peak. The effect of bandwidth, we can see it here. We could say that OK, if I have a distribution and my distribution. If I look at it from the histogram perspective is like this and I use different bandwidth, you're seeing that with alpha equal to point point .1 it is going to be very spiky because I'm putting a spiky stuff on top of the data points and I'm averaging all of them. So those are spikes are not going to merge together and form a nice kind of curvy shape. If I increase alpha to equal to 1, I will start losing some of those noise that I saw in the previous case. There is still some noise exists in my data. If I increase alpha to be equal to two, you're seeing that my curve is getting a smoother and a smoother in this case as well. So the choice of alpha is really your choice, but you just know that based on the alpha you're changing. Remember that fabric thing? You're changing the density of that fabric. So if your alpha is going to be a very high alpha, you're putting a very thick fabric on top of your distribution. So only the single pick is going to be captured.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1367\nNarges Norouzi\n...\nO\nEffect of Bandwidth on KDEs\nT\n6321285\nKDE of tips with Gaussian kernel and a = 0.1\n0.10\nKDE of tips with Gaussian kernel and a = 1\nBandwidth is analogous to the\n0.14\nwidth of each bin in a histogram.\n0.12\n0.08\nAs a increases, the KDE\n0.10\n0.06\nbecomes more smooth.\n0.08\nLarge a KDE is simpler to\n0.06\n0.04\nunderstand, but gets rid of\n0.04\n0.02\npotentially important\n0.02\n0.00\ndistributional information\n0.00\n0\n10\n20\n30\n40\n50\n0\n10\n20\n30\n40\n50\nKDE of tips with Gaussian kernel and a = 2\nKDE of tips with Gaussian kernel and a = 5\n(e.g. multimodality).\n0.10\n0.10\n0.08\n0.08\n50\n0.06\n0.06\n40\n0.04\n0.04\n30\n0.02\n0.02\n20\nCount\n10\n0.00\n0\n10\n20\n30\n40\n50\n0.00\n10\n20\n30\n40\n50\n0\n10\n20\n30\n40\n50\ntotal_bill\n49\nHY\nNC\nSA\n2024-09-19 12:26:36\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\n\u00d7\n+\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1367\nNarges Norouzi\n...\nEffect of Bandwidth on KDEs\nab\nT\n6321285\nKDE of tips with Gaussian kernel and a = 0.1\nKDE of tips with Gaussian kernel and a = 1\n0.10\nBandwidth is analogous to the\n0.14\nwidth of each bin in a histogram.\n0.12\n0.08\nAs a increases, the KDE\n0.10\n0 06\nbecomes more smooth.\n0.08\n0.04\nLarge a KDE is simpler to\n0.06\nunderstand, but gets rid of\n0.04\n0.02\npotentially important\n0.02\n0.00\ndistributional information\n0.00\n10\n20\n30\n40\n50\n0\n10\n20\n30\n40\n50\nKDE of tips with Gaussian kernel and a = 5\n(e.g. multimodality).\n0.10\nKDE of tips with Gaussian kernel and a = 2\n0.10\n0.08\n0.08\n50\n0.06\n0.06\n40\n0.04\n0.04\n30\nCount\n0.02\n20\n0.02\n10\n0.00\n0\n10\n20\n30\n40\n50\n0.00\n10\n20\n30\n40\n50\n0\n10\n20\n30\n40\n50\ntotal_bill\n49\n2024-09-19 12:26:41\n",
        "Retrieved Audio": "Increase alpha to be equal to two. You're saying that my curve is getting a smoother and a smoother in this case as well. So the choice of alpha is really your choice, but you just know that based on the alpha you're changing. Remember that fabric thing? You're changing the density of that fabric. So if you're your alpha is going to be a very high alpha, you're putting a very thick fabric on top of your distribution. So only the single pick is going to be captured if you keep like lightening or or choosing.\nThere is still some noise exists in my data. If I increase alpha to be equal to two, you're seeing that my curve is getting a smoother and a smoother in this case as well. So the choice of alpha is really your choice, but you just know that based on the alpha you're changing. Remember that fabric thing? You're changing the density of that fabric. So if your alpha is going to be a very high alpha, you're putting a very thick fabric on top of your distribution. So only the single pick is going to be captured.\nAnd I use different bandwidths. You're seeing that with alpha equal to point point .1 it is going to be very spiky because I'm putting a spiky stuff on top of the data points and I'm averaging all of them. So those spikes are not going to merge together and form a nice kind of curvy shape. If I increase alpha to equal to 1, I will start losing some of those noise that I saw in the previous case, But there is still some noise existing my data if I.",
        "Retrieved Notes": "**smooth** function \u00e2\u0080\u0093 it is differentiable at all points, making it easy to minimize using numerical methods. The MAE, in contrast, is not differentiable at each of its \"kinks.\" We'll explore how the smoothness of the cost function can impact our ability to apply numerical optimization in a few weeks.\nHow do outliers affect each cost function? Imagine we replace the largest value in the dataset with 1000. The mean of the data increases substantially, while the median is nearly unaffected.\n```{python}\n#| \n that is wider and shorter \u00e2\u0080\u0093 this leads to a smoother KDE when the kernels are summed together.\n    * A small value of $\\alpha$ will produce a narrower, taller kernel, and, with it, a noisier KDE.\nThe details of this (admittedly intimidating) formula are less important than understanding its role in kernel density estimation \u00e2\u0080\u0093 this equation gives us the shape of each kernel.\n| Gaussian Kernel, $\\alpha$ = 0.1 | Gaussian Kernel, $\\alpha$ = 1 | \n| --- | --- |\n| <img src=\"images/gaussian_0.1.png\" alt='gau\nreater in value than our previous guess \u00e2\u0080\u0093 that is, we want to shift our guess to the right. You can think of this as following the slope \"downhill\" to the function's minimum value.\n<div align=\"middle\">\n  <table style=\"width:100%\">\n    <tr align=\"center\">\n      <td><img src=\"images/neg_step.png\" alt='neg_step' width='600'>\n      </td>\n    </tr>\n  </table>\n</div>\nIf we've overshot $\\hat{\\theta}$ by guessing too high of a value, we'll want our next guess to be lower in value \u00e2\u0080\u0093 we want to shift our guess ",
        "Retrieved Video": "ta 100:\nChoosing the \"right\" plot for\nStylizing plots appropriately\n.\nIntroducing plots for different variable\n. .\nSmoothing and transforming visual data\ntypes\nProviding context through labeling and\nGenerating these plots through code\ncolor\n9\nHY\nINC\n2024-09-19 11:16:36\n\nta 100:\nChoosing the \"right\" plot for\nStylizing plots appropriately\n.\nIntroducing plots for different variable\n. .\nSmoothing and transforming visual data\ntypes\nProviding context through labeling and\nGenerating these plots through code\ncolor\n9\nHY\nINC\n2024-09-19 11:16:36\n\nWe'll talk about the math of these\nfunctions soon.\n46\nHY\nINC\n2024-09-19 12:23:29\n",
        "Question": "why does increasing alpha make it smoother ",
        "Timestamp": 4625,
        "TA Response": "Alpha refers to the bandwidth parameter and is also the standard deviation.",
        "Lecture": 7
    },
    {
        "Conversation History": "\t",
        "GPT Response": "Yes, the discussion about kernel density estimation (KDE) and different kernels like the Gaussian and Boxcar kernels is related to the broader topic of estimating probability distributions, which can be connected to Maximum Likelihood Estimation (MLE). MLE is a method used to estimate the parameters of a statistical model, and KDE is a non-parametric way to estimate the probability density function of a random variable. While KDE itself is not directly an MLE method, both are techniques used to understand and model data distributions.",
        "Recent Audio": "a sense of all of those smaller peaks or smaller trends. So that's kind of a choice when you're making in order to make sure that do you understand enough about your distribution? Do you understand what is the mood of your distribution and the skewness of the distribution and so on and so forth. There are other types of kernels such as Boxcar kernel. It's not going to be used in practice, but you would basically. We see that it's still parameterized by alpha and it still has the center on X is and the shape is going to be something like this area under the box is always equal to one. It's centered at XI, for example. In this case, it's equal to four. And then it takes in a value for the height or for the density so that the area under the curve is equal to 1. And if we apply boxcar instead of the Gaussian, a Gaussian kernel for the kernel lensity estimation. This is the kernel density estimation that we're going to see with a different kernel. But in practice, most of the time we'll use Gaussian kernel. So we'll always see all of those like curvy shapes or nice carbs that you're seeing that you were seeing in the demo today. So this is the last thing. Just as a practice, if you haven't had a chance to respond to any of the slightest, go ahead and tell us which one of these are. A kernel density estimate plot.",
        "Recent Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n>\nG\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.g2555b8b1865_0_1378\nNarges Norouzi\n...\n0\nOther Kernels: Boxcar\nT\nAs an example of another kernel, consider the boxcar kernel.\n6321285\nKDE of toy data with Gaussian kernel and a = 1\nIt assigns uniform density to points within a \"window\" of\n05\nthe observation, and 0 elsewhere.\n0.4\nResembles a histogram ... sort of.\n0.3\nI, Ix-xil\u2264\uc744\n0.2\nKa(x, xi) =\n=\n10, else\n0.1\n.\nNot of any practical use in Data 100! Presented as a\n0.0\n-2\n2\n4\n6\n8\n10\nsimple theoretical alternative.\nKDE of toy data with Boxcar kernel and a = 1\n0.5\n0.5\n0.4\n0.4\n0.3\nA boxcar kernel\n0.3\ncentered on xi = 4 with\n0.2\n0.2\n0.1\na=2.\n0.1\n0.0\n0.0\nIN\n0\n2\n4\n6\n8\n-2\n0\n8\n10\n50\n'S\nHY\nNC\n2024-09-19 12:28:31\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx +\n->\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_API759836349_0\nNarges Norouzi\n...\n: Active poll\nSynchronous\nabo\nT\n0 83\nWhich of the following are\nvalid kernel density plots?\n\u00b7 A\nCombined Gaussian Kernels\nCombined Boxcar Kernels\nA\n01\nCombined Gaussian Kemels\nB\nCombined Boxcar Kernels\n0.30\n0.6\n0.25\n.\nB\n05\n0.20\n0.15\nKemnel Value\nKernel Value\n0.10\n02\n0.05\n0.00\n2\n\u00b7 C\nCombined Boxcar Kernels\nCombined Triangular Kernels\nCombined Boxcar Kernels\nCombined Thangular Kernels\nJoin at\nC\n020\nD\n015\n0.10\n0.2\nslido.com\n\u00b7 D\nKennel Value\nKemel Value\n0.05\n9.00\n-4\n4\n-4\n-\n2\n#6321 285\n2024-09-19 12:28:55\n",
        "Retrieved Audio": "And then this slide, whether this is a distribution or not?\nI'm not sure what's going on.\nQuestion.",
        "Retrieved Notes": "ood model?\nTo illustrate this process, we derived the optimal model parameters under simple linear regression (SLR) with mean squared error (MSE) as the cost function. A summary of the SLR modeling process is shown below:\n<div align=\"middle\">\n<img src=\"images/slr_modeling.png\" alt='modeling' width='600'>\n</div>\nIn this lecture, we'll dive deeper into step 4 - evaluating model performance - using SLR as an example. Additionally, we'll also explore the modeling process with new models, continue familiarizing \n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Define a random variable in terms of its distribution\n* Compute the expectation and variance of a random variable\n* Gain familiarity with the Bernoulli and binomial random variables\n:::\nIn the past few lectures, we've examined the role of complexity in influencing model performance. We've considered model complexity in the context of \n that this is under the assumption that all data is drawn independently from the same logistic regression model with parameter $\\theta$. In fact, many of the model + loss combinations we've seen can be motivated using MLE (e.g., OLS, Ridge Regression, etc.). In probability and ML classes, you'll get the chance to explore MLE further.  \n::: {.callout-note}\n## Learning Outcomes\n- Dissect Singular Value Decomposition (SVD) and use it to calculate principal components\n- Develop a deeper understanding of how to ",
        "Retrieved Video": "Lec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n\nLec 07 - DS100 Fa24- Visualizat X\nlab? - JupyterLab\nx\n+\n>\n\u00ba5 docs.google.com/presentation/d/1uuUWNOYIV5ECrBYt_Koe95hFpD2gD3AMbWwyA1414KA/edit#slide=id.SLIDES_AP1971506376_0\nM\nNarges Norouzi\nC\n...\n:= Active poll\nSynchronous\n4\nab\nT\n428 8\n0\nDoes this chart show a\ndistribution?\nYes O\nSHARE OF AMERICAN ADULTS\n95%\nIN EACH INCOME TIER\nUpper\n19%\nNo\n5%\nJoin at\nMiddle\n52%\nslido.com\nLower\n29%\n#6321 285\n2024-09-19 11:22:41\n\ndemo.i2024-09-19111:38:17\n",
        "Question": "Is this related to MLE? ",
        "Timestamp": 4718,
        "TA Response": "We will cover this later in the course.",
        "Lecture": 7
    }
]