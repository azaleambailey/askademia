[
    {
        "Conversation History": "\t",
        "GPT Response": "The lecture slides and code for Lecture 19 can be found at the following link: [Lecture 19 Resources](https://ds100.org/fa24/lecture/lec19/).",
        "Recent Audio": "Yes. So welcome back to Data 100. I hope you enjoyed the beginning. We are gonna pick up where we left off last time. Join the slide out. I started looking at some of your feedback. Please do fill the feedback form. I sometimes go too fast, sometimes go too slow, which checks out. So today I'm gonna try to go appropriately fast and slow when necessary. And part of that is we're gonna go a little bit faster in the beginning so we can get some of the more technical stuff at the end with some more time. All right, so brief recap. In last lecture we started playing random variables, we started talking about distributions, we talked about P of X and then we spent a fair amount of time on these operators. Very important, the expectation defined as this and the variance defined as that. We then started talking about some of the important properties of these operators. So linearity of expectation right here and then variance isn't quite linear, but how to deal with, you know, AX plus B? Here's what I remember. The little, little letters are constants and these are random variables the the capital letters. So quick recap and we'll get to practice these some more today.",
        "Recent Video": "[Summary] Expectation and Variance for Linear Functions of Random Variables\nLet X be\nE[X] =_ xP(X=x)\nHey Gonzalez Dhe, h.\na random variable with\ndistribution P(X = x).\nVar(X) = E [(X-E[X])2]\n(definition)\n= E[X2] - (E[X])2\n(easier computation)\nLet a and b be\nE[aX+b]=aLE[X]+b\nscalar values.\nVar(aX+b) = a2Var(X)\nLet Y be\nE[X+Y] =E[X]+[Y]\nanother random variable.\nVar(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\nZero if X, Y independent.\n4\n2024-10-29 11:11:37\n\n[Summary] Expectation and Variance for Linear Functions of Random Variables\nLet X be\nE[X] =_ xP(X=x)\nHey Gonzalez Me, N.\na random variable with\ndistribution P(X = x).\nVar(X) = E [(X-E[X])2]\n(definition)\n= E[X2] - (E[X])2\n(easier computation)\nLet a and b be\nE[aX+b]=aE[X]+b\nscalar values.\nVar(aX+b) = a2Var(X)\n-\nLet Y be\nE[X+Y] =E[X]+[Y]\nanother random variable.\nVar(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\nZero if X, Y independent.\n4\n2024-10-29 11:11:42\n",
        "Retrieved Audio": "Yes. So welcome back to Data 100. I hope you enjoyed the beginning. We are gonna pick up where we left off last time. Join the slide out. I started looking at some of your feedback. Please do fill the feedback form. I sometimes go too fast, sometimes go too slow, which checks out. So today I'm gonna try to go appropriately fast and slow when necessary.\nSo quick recap and we'll get to practice these some more today.\nAnd part of that is we're gonna go a little bit faster in the beginning so we can get some of the more technical stuff at the end with some more time. All right, so brief recap.",
        "Retrieved Notes": "Optional Supplementary Textbook](https://ds100.org/fa24/resources/#optional-supplementary-textbook)\n-   [Exam Resources](https://ds100.org/fa24/resources/#exam-resources)\n-   [Course Website](https://ds100.org/fa24/resources/#course-website)\n-   [Coding and Mathematics Resources](https://ds100.org/fa24/resources/#coding-and-mathematics-resources)\n    -   [Pandas](https://ds100.org/fa24/resources/#pandas)\n    -   [SQL](https://ds100.org/fa24/resources/#sql)\n    -   [Regex](https://ds100.org/fa24/resources/#r\ns/#data-science-education)\n-   [Local Setup (Old)](https://ds100.org/fa24/resources/#local-setup-old)\n\n## Reference Sheet\n\nHere is the Spring 2024 Final [Reference Sheet](https://ds100.org/fa24/resources/assets/exams/sp24/ds100-sp24-final-ref.pdf).\n\n## Supplementary Course Notes\n\nAlongside each lecture are supplementary [Course Notes](https://ds100.org/course-notes/).\n\nLecture notes will be updated on a weekly basis, prior to the lecture. If you spot any errors or would like to suggest any changes, please e\n   -   [Discussion](https://ds100.org/fa24/syllabus/#discussion)\n    -   [Homework and Projects](https://ds100.org/fa24/syllabus/#homework-and-projects)\n    -   [Lab](https://ds100.org/fa24/syllabus/#lab)\n    -   [Exams](https://ds100.org/fa24/syllabus/#exams)\n    -   [Graduate Final Project](https://ds100.org/fa24/syllabus/#graduate-final-project)\n-   [Office Hours and Communication](https://ds100.org/fa24/syllabus/#office-hours-and-communication)\n-   [Policies](https://ds100.org/fa24/syllabus/#policies)\n ",
        "Retrieved Video": "LECTURE 18\nEstimators, Bias, and Variance\nExploring the different sources of error in the predictions that our models make.\nData 100/Data 200, Fall 2024 @ UC Berkeley\nNarges Norouzi and Joseph E. Gonzalez\nContent credit: Acknowledgments\n2\n2024-10-29 11:10:36\n\nslido\nHey Gonzalez Bhe, h.\nJoin at\nslido.com\n#2214 265\n2024-10-29 11:10:25\n\n[Summary] Expectation and Variance for Linear Functions of Random Variables\nLet X be\nE[X] =_ xP(X=x)\nHey Gonzales Phe,h.\na random variable with\ndistribution P(X = x).\nVar(X) = E [(X-E[X])2]\n(definition)\n= E[X2] - (E[X])2\n(easier computation)\n4\n2024-10-29 11:10:54\n",
        "Question": "For those looking for the lecture slides and/or code, here they are: https://ds100.org/fa24/lecture/lec19/",
        "Timestamp": 89,
        "TA Response": "The lecture slides and code are here: https://ds100.org/fa24/lecture/lec18/",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "The expression \\( P(Y=y) = \\binom{n}{y} p^y (1-p)^{n-y} \\) is the probability mass function (PMF) of a binomial random variable, which describes the probability of observing exactly \\( y \\) successes in \\( n \\) independent Bernoulli trials, each with success probability \\( p \\). This formula is called the binomial distribution because it provides the probabilities for all possible values of \\( y \\) (from 0 to \\( n \\)), thus characterizing the entire distribution of the random variable \\( Y \\). While it gives the probability of a specific outcome \\( y \\), it is part of the broader distribution that describes all potential outcomes and their probabilities.",
        "Recent Audio": "Y is the number of ones of N independent Bernoulli trials. O we can write Y. Here's the density function for Y which is kind of complicated based on binomial coefficients. What's the expectation? Take some work to work through the the actual expectation using the definition. There's an easy way to do it. We can say why is this sum of some random variables? We can use our properties from before, so what's the expectation of? Why? The expectation. Why? Is the sum of the expectations of these random variables. These are Bernoulli, Bernoulli P random variables. We know the expectation of a Bernoulli single Bernoulli random variable is P and we have north of them, so we have n * P. We derive the expectation. No need to use this complicated equation. It's complicated. We used the definition here we use math on random variables. Cover the variance. We're going to use another important thing here. They're independent. What can we say about the sum of the variance of random variables? OK. Take the variance of Y is the sum of the variances. We have to deal with covariance terms if they're not independent, but they are. So it's just the sum of the variances we have end of them as before N and the variance Oh no, sorry, the variance and and the variance of a single one of them was P * 1 -, P. OK, so use our properties and we can now derive properties of more interesting random variables questions.",
        "Recent Video": "Properties of Binomial Random Variables\nLet Y be a Binomial(n, p) random variable.\nYis the number (i.e ., count) of 1s in n independent Bernoulli(p) trials.\n.\nDistribution of Y given by the binomial formula.\nP(Y=y)=(\")p\u00a5(1-p)\"-y\nn\nWe can write: Y => Xi\nA count is a sum of 0's and 1's.\ni=1\n.\nXi is the indicator of success on trial i. Xi = 1 if trial i is a success, else 0.\n.\nAll Xis are i.i.d. (independent and identically distributed) and Bernoulli(p).\nExpectation: E[Y]=>[X] =np\ni=1\nVariance: Because all Xis are independent, Cov(Xi, X;)= 0; Var(Y)=>Var(X;) =np(1-p)\n10\n2024-10-29 11:18:49\n\nProperties of Binomial Random Variables\nLet Y be a Binomial(n, p) random variable.\nHey Gonzalez De ...\nY is the number (i.e ., count) of 1s in n independent Bernoulli(p) trials.\nDistribution of Y given by the binomial formula.\n1\n70\nn\nWe can write: Y => Xi\nA count is a sum of 0's and 1's.\ni=1\n.\nXi is the indicator of success on trial i. Xi = 1 if trial i is a success, else 0.\n.\nAll Xis are i.i.d. (independent and identically distributed) and Bernoulli(p).\nExpectation:\nE[Y]=>EE[X] =np\ni=1\nVariance: Because all Xis are independent, Cov(X1, X) = 0; Var(Y)=>Var(X;) =np(1-p)\ni=1\n10\n2024-10-29 11:18:54\n",
        "Retrieved Audio": "O we can write Y. Here's the density function for Y which is kind of complicated based on binomial coefficients. What's the expectation? Take some work to work through the the actual expectation using the definition. There's an easy way to do it. We can say why is this sum of some random variables?\nHas two parameters and NP. This is the number of 1, so Y is the number of ones of N independent Bernoulli trials.\nThe Bernoulli We often write a distribution. Say X is distributed according to Bernoulli. We'd write it like this again. P here is my parameter, and that's a thing I pick where I learn or I estimate.",
        "Retrieved Notes": "\n- When $y = 1$, this reads $P(Y=y) = p$\n- When $y = 0$, this reads $P(Y=y) = (1-p)$\nIn our example, a Bernoulli random variable is analogous to a single data point (e.g., one instance of a basketball team winning or losing a game). All together, our `games` data consists of many IID Bernoulli($p$) random variables. To find the likelihood of independent events in succession, simply multiply their likelihoods.\n$$\\prod_{i=1}^{n} p^{y_i} (1-p)^{1-y_i}$$\nAs with the coin example, we want to find the parameter $\nc=\"images/yz_distribution.png\" alt='distribution' width='=500'>\n</p>\nHowever, $Y = X_1$ has a larger variance.\n<p align=\"center\">\n<img src=\"images/yz.png\" alt='distribution' width='200'>\n</p>\n### Example: Bernoulli Random Variable\nTo get some practice with the formulas discussed so far, let's derive the expectation and variance for a Bernoulli($p$) random variable. If $X$ ~ Bernoulli($p$),\n$\\mathbb{E}[X] = 1 \\cdot p + 0 \\cdot (1 - p) = p$\nTo compute the variance, we will use the computational formula. We fi\nrst find that:\n$\\mathbb{E}[X^2] = 1^2 \\cdot p + 0^2 \\cdot (1 - p) = p$\nFrom there, let's calculate our variance: \n$\\text{Var}(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = p - p^2 = p(1-p)$\n### Example: Binomial Random Variable\nLet $Y$ ~ Binomial($n$, $p$). We can think of $Y$ as being the sum of $n$ i.i.d. Bernoulli($p$) random variables. Mathematically, this translates to \n$$Y = \\sum_{i=1}^n X_i$$\nwhere $X_i$ is the indicator of a success on trial $i$. \nUsing linearity of expectation,\n$$\\mathbb{E}[Y] = \\sum_{i",
        "Retrieved Video": "Properties of Binomial Random Variables\nLet Y be a Binomial(n, p) random variable.\nY is the number (i.e ., count) of 1s in n independent Bernoulli(p) trials.\n.\nDistribution of Y given by the binomial formula.\nP(Y= y) =\nn\ny\npu(1-p)\"-y\nWe can write: Y = X\nA count is a sum of 0's and 1's.\ni=1\nXi is the indicator of success on trial i. Xi = 1 if trial i is a success, else 0.\nAll Xis are i.i.d. (independent and identically distributed) and Bernoulli(p).\n10\n2024-10-29 11:17:37\n\nProperties of Binomial Random Variables\nLet Y be a Binomial(n, p) random variable.\nY is the number (i.e ., count) of 1s in n independent Bernoulli(p) trials.\n.\nDistribution of Y given by the binomial formula.\nP(Y=3) = (2)D\"(1-p)\"- y\n10\n2024-10-29 11:17:27\n\nProperties of Binomial Random Variables\nLet Y be a Binomial(n, p) random variable.\nHey Gonzalez Phe.h.\nYis the number (i.e ., count) of 1s in n independent Bernoulli(p) trials.\nDistribution of Y given by the binomial formula.\nP(Y= 3)=(2)D\"(1-p)2-4\n10\n2024-10-29 11:17:08\n",
        "Question": "Why is P(Y=y) given by the binomial formula the distribution of Y and not the probability of y.",
        "Timestamp": 524,
        "TA Response": "P(Y=y) gives the distribution, because we can plug in any possible value y that random variable Y can take and then solve for the probability of that y. So we get a probability when we choose a specific value for y, like P(Y=2) is a probability. Edit: You are technically correct that the formula represents the probability of y, we just call it a distribution because we can use that formula to compute the probability for any possible y.",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In slide 13, we multiply by 0.25 because it represents the variance of a Bernoulli random variable with \\( p = 0.5 \\). The variance of a Bernoulli random variable is calculated as \\( p(1-p) \\), which in this case is \\( 0.5 \\times (1 - 0.5) = 0.25 \\). This value is used to compute the variance of the payout strategies involving Bernoulli random variables.",
        "Recent Audio": "we've. Our our payouts and then the expectation that each of these X is just .5, right. So we got a payout of 10 and 10. So 10 we got a .5 S $0.50 for each of our 2020 plays. So 20 flips or $10 payout. Then here we got a 50% chance of getting $20 and a zero, you know, 50% chance of getting nothing. So our expectation is 10. So the expectation they're all good. But variants, so are variants do the same kinds of analysis here, right? So these coefficients are now squared. We know the variance is .5 * 1 -, .5 or .25 for each of the X is. So we can work out the variance for each of these variants of 50, there's a much lower variance of five. This has a much higher variance of 100, right? So the less spread. So we're more confident that this one's going to give us something close to to 10. Right. Which could be less, I mean we the high variability here, you could get 20 on this one, right? So it's kind of your risk preferences. Me, I choose this one. Walk with some money. OK, can compute standard deviation. Take the square root, and again if you go to the notebook, you can try doing the simulation. It's pretty straightforward. It's a good chance to practice using some of the random number generators, so take a look at the notebook after lecture. So there isn't a book. We'll skip that.",
        "Recent Video": "Which Would You Pick?\nVar(X1+X2) = Var(X1)+ Var(X2) +2\nVar(aX+b) = a2Var(X)\nSuppose you win cash based on the number of heads\nyou get in a series of 20 coin flips.\nLet X1 , X2, ..., X20 be 20 IID Bernoulli(0.5) random variables.\nSince X/ s are independent:\nCov(Xi. X\u00a1) = 0 for all i, j.\nWhich payout\nstrategy would\nSince Xr is Bernoulli(p = 0.5): E[X] =p=0.5, Var(Xi) =p(1-p)=0.25.\nyou choose?\nA. YA = $10.X1 + $10.X2\nB. Ya= $ (Ex.)\nC. Yc = $20.X1\nExpectation\nE[YA]=10(0.5)+10(0.5)=10\nE[YB] =0.5+ ... +0.5=10\nE[Yc] =20(0.5) =10\nVariance\nVar(YA)= 102(0.25) + 102(0.25)\nVar(YB) = 0.25 + ... + 0.25\nVar(Yc) =202(0.25)\n=50\n=20(0.25)\n>=100\n%=5\nStd. Deviation\nSD(YA) = 7.07\nSD(YB) =2.24\nSD(Yc) =10\n13\n2024-10-29 11:24:20\n\nBrief Recap\nCommon Distributions\nSample Mean Properties\nPopulation vs Sample Statistics\nSample Mean\nTraining and Prediction as Estimation\nProperties\nThe Bias-Variance Tradeoff\nLecture 18, Data 100 Fall 2024\n15\n2024-10-29 11:24:44\n",
        "Retrieved Audio": "We derive the expectation. No need to use this complicated equation. It's complicated.\nRight. So this equation right here, this equation right here becomes this P -, P ^2 which can be rewritten as P * 1 -, P.\nBut variants, so are variants do the same kinds of analysis here, right? So these coefficients are now squared. We know the variance is .5 * 1 -, .5 or .25 for each of the X is. So we can work out the variance for each of these variants of 50, there's a much lower variance of five. This has a much higher variance of 100, right? So the less spread. So we're more confident that this one's going to give us something close to to 10.",
        "Retrieved Notes": "reater in value than our previous guess \u00e2\u0080\u0093 that is, we want to shift our guess to the right. You can think of this as following the slope \"downhill\" to the function's minimum value.\n<div align=\"middle\">\n  <table style=\"width:100%\">\n    <tr align=\"center\">\n      <td><img src=\"images/neg_step.png\" alt='neg_step' width='600'>\n      </td>\n    </tr>\n  </table>\n</div>\nIf we've overshot $\\hat{\\theta}$ by guessing too high of a value, we'll want our next guess to be lower in value \u00e2\u0080\u0093 we want to shift our guess \n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Define a random variable in terms of its distribution\n* Compute the expectation and variance of a random variable\n* Gain familiarity with the Bernoulli and binomial random variables\n:::\nIn the past few lectures, we've examined the role of complexity in influencing model performance. We've considered model complexity in the context of \nesent relationships in our data by manipulating the scale or axes. The visualization below improperly portrays two seemingly independent relationships on the same plot. The authors have clearly changed the scale of the y-axis to mislead their audience.\n<img src=\"images/wrong_scale_viz.png\" alt='wrong_scale_viz' width='350'> \nNotice how the downwards-facing line segment contains values in the millions, while the upwards-trending segment only contains values near three hundred thousand. These lines should not",
        "Retrieved Video": "0-29 11:18:20\n\n] =0.5+ ... +0.5=10\nE[Yc]=20(0.5)=10\nVariance\nStd. Deviation\n13\n2024-10-29 11:23:18\n\n0-29 11:14:20\n",
        "Question": "Why did we multiply by 0.25 in slide 13?",
        "Timestamp": 868,
        "TA Response": "We computed the variance of a single coin flip to be 0.25 using the formula for Bernoulli variance that we derived on the previous slide. Then to compute the variance for 20 flips under each of the 3 strategies, we use the Variance rules given earlier: Var(aX + b) = (a^2)*Var(X), and Var(X + Y) = Var(X) + Var(Y) + Cov(X,Y). (Cov is 0 here because the flips are independent). If you apply these rules to the 3 strategies, you should find that you get the calculations given on the slide.",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the context of i.i.d. (independent and identically distributed) random variables, the independence aspect implies that any two different variables \\(X_i\\) and \\(X_j\\) are independent. For independent random variables, the covariance is zero, i.e., \\(\\text{Cov}(X_i, X_j) = 0\\). This is because the covariance between two independent variables is defined as \\(\\text{Cov}(X_i, X_j) = \\mathbb{E}[X_i X_j] - \\mathbb{E}[X_i]\\mathbb{E}[X_j]\\), and for independent variables, \\(\\mathbb{E}[X_i X_j] = \\mathbb{E}[X_i]\\mathbb{E}[X_j]\\), leading to a covariance of zero.",
        "Recent Audio": "if you kind of think there's a true mean for the height of people in in this class, but I only have a sample and each of those people are sort of drawn from some distribution who's, you know, the mean of that distribution is the true mean, right? So if I knew the true mean. Then the expectation of my sample mean should actually be the true mean. Which is a good thing. Talk about that in one moment. So at variance, so it's a variance of my sample mean. Well, remember I'm going to take, I have this one over north here. So I got to square it one over north squared times the variance of the sum. I drew these IID identically independently distributed. Independently distributed so I can make this 0. The covariance is 0, so now it's just the sum of the variances. This is north of these sigmas, so I'll assume that the each of the X is has a population. I didn't write there here population standard deviation of Sigma, right? I don't know that in practice. But I can guess it now maybe. So I look at the variance here my variance, my sample. It should be if I knew the population Sigma Sigma squared over. N so if I knew the population variance, the variance of my sample is Sigma squared over N. What does that mean? There's some inherent variability in the population. There's the students in this class, but as I make my sample bigger.",
        "Recent Video": "Sample Mean\nConsider an i.i.d. sample X1 , X2, ..., Xn drawn from a population with mean u and SD\nDefine the sample mean:\nn\nX ,=; Ex\ni=1\nExpectation:\nVariance/Standard Deviation:\nVar(x) == aver( x) === ([ Var(X)\n= = (np) = H\n=1(no2)= 12\nHID -Cov(X.X)=0\n16\n2024-10-29 11:25:51\n\nSample Mean\nConsider an i.i.d. sample X1 , X2, .... X. drawn from a population with mean u and SD\nHey Gonzalez Phe.h.\nDefine the sample mean:\nn\nX, =; Ex\ni=1\nExpectation:\nVariance/Standard Deviation:\nE[X] =- >E[X]\ni=1\nVar(x)= / var( x)=( Var(X)\n== (nu) =\"\nMID - Cov(X. X) =0\n16\n2024-10-29 11:26:15\n",
        "Retrieved Audio": "If they are independent, we have this nice property, then it is 0. That's great. So we get, you know, something that looks like expectations, but they're not. We have to account for the covariance. All right, one more property we did not get to cover last time that we'll use today. So review it. Is it the if X&Y are independent random variables, then the expectation of the product of those variables is the product of the expectation.\nIndependent or not the covariance of those two variables?\nThe covariance is 0, so now it's just the sum of the variances. This is north of these sigmas, so I'll assume that the each of the X is has a population. I didn't write there here population standard deviation of Sigma, right? I don't know that in practice.",
        "Retrieved Notes": "and $r(X, Y) = 0$. Note, however, that the converse is not always true: $X$ and $Y$ could have $\\text{Cov}(X, Y) = r(X, Y) = 0$ but not be independent. \n### Equal vs. Identically Distributed vs. i.i.d\nSuppose that we have two random variables $X$ and $Y$:\n* $X$ and $Y$ are **equal** if $X(s) = Y(s)$ for every sample $s$. Regardless of the exact sample drawn, $X$ is always equal to $Y$.\n* $X$ and $Y$ are **identically distributed** if the distribution of $X$ is equal to the distribution of $Y$. We say \u00e2\u0080\u009c$X\n$ and $Y$ are equal in distribution.\u00e2\u0080\u009d That is, $X$ and $Y$ take on the same set of possible values, and each of these possible values is taken with the same probability. On any specific sample $s$, identically distributed variables do *not* necessarily share the same value. If $X = Y$, then $X$ and $Y$ are identically distributed; however, the converse is not true (ex: $Y = 7 - X$, $X$ is a die)\n* $X$ and $Y$ are **independent and identically distributed (i.i.d)** if \n    1. The variables are identically\n Since the $X_i$'s are independent, $\\text{Cov}(X_i, X_j) = 0$ for all pairs $i, j$. Additionally, Since $X_i$ is Bernoulli(0.5), we know that $\\mathbb{E}[X] = p = 0.5$ and $\\text{Var}(X) = p(1-p) = 0.25$. We can calculate the following for each scenario: \n|   | A. $Y_A = 10 * X_1 + 10 * X_2$ | B. $Y_B = \\sum_{i=1}^{20} X_i$ | C. $Y_C = 20 * X_1$ | \n| --- | --- | --- | --- |\n| Expectation | $\\mathbb{E}[Y_A] = 10 (0.5) + 10(0.5) = 10$ | $\\mathbb{E}[Y_B] = 0.5 + ... + 0.5 = 10$ | $\\mathbb{E}[Y_C] = 20(0.5) = ",
        "Retrieved Video": "l Xis are independent, Cov(X1, X) = 0; Var(Y)=>Var(X;) =np(1-p)\ni=1\n10\n2024-10-29 11:18:54\n\n are independent, Cov(Xi, X;)= 0; Var(Y)=>Var(X;) =np(1-p)\n10\n2024-10-29 11:18:49\n\nSample Mean\nConsider an i.i.d. sample X1 , X2, ..., Xn drawn from a population with mean u and SD\nDefine the sample mean:\nn\nX ,=; Ex\ni=1\nExpectation:\nVariance/Standard Deviation:\nVar(x) == aver( x) === ([ Var(X)\n= = (np) = H\n=1(no2)= 12\nHID -Cov(X.X)=0\n16\n2024-10-29 11:25:51\n",
        "Question": "Why does iid mean Cov(Xi,Xj)=0?",
        "Timestamp": 1008,
        "TA Response": "iid means independent and identically distributed, so here we are using that independence to say that covariance between these two variables is 0.",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "Expectation, in the context of probability and statistics, is the weighted average of all possible values of a random variable, where the weights are the probabilities of each value occurring. It is a number, not a random variable, and serves as a generalization of the average. The expectation represents the center of gravity of the probability distribution histogram and is the long-run average of simulated values if the variable is simulated many times. For example, in a coin toss where heads is 1 and tails is 0, the expectation is 0.5, which is the average value over many tosses.",
        "Recent Audio": "of cool. Coin flips, whatever you want, doesn't have to be a Gaussian, but this thing here, this sample mean will become more and more Gaussian shaped and more and more pointed, which is nice, kind of converging to some. Some true value and this is from the central limit theorem. Which we won't prove again in this class either. So in day-to-day we talked about it and invoked it. Here you got to see the derivation using expectation and variance of these two key properties. In STAT 140, you'll get to understand this actually fairly technical idea a little bit more more detail. What you should take away from this is you know that we get this concentration because I get bigger and bigger samples, these standard deviation of my estimator of my mean. Reduces by one over north or the variance reduces by one over north? Questions. Keep going. Let me build this slide in. Alright, so you've said this already now, so we have this distribution. As my end gets bigger, my sample mean will start to look more and more Gaussian and more and more peaked, which is nice. And we peaked right around the mean, which is a good thing to be. And this is called an unbiased estimator. That is the expectation, the sample mean of my, the mean of my sample that is unbiased. Estimate of the mean of the distribution. If the true mean is MU, the expectation of the thing I just computed is the true mean.",
        "Recent Video": "Using the Sample Mean to Estimate the Population Mean\nOur goal is often to estimate some characteristic of a population.\nHey Gonzalez Pheyh.\nExample: average height of Cal undergraduates.\nn = 800\nWe typically can collect a single sample. It has just one average.\n.\nSince that sample was random, it could have come out differently.\nn = 200\nWe should consider the average value and spread of all possible\nsample means, and how it scales with the sample size n.\nE[X,]\nSD(X) = n\nFor every sample size, the expected value of\nthe sample mean is the population mean.\nWe call the sample mean an\nunbiased estimator of the population mean.\n(more on this in a bit)\n17\n2024-10-29 11:31:18\n\nUsing the Sample Mean to Estimate the Population Mean\nOur goal is often to estimate some characteristic of a population.\nHey Gonzalez Pheyh.\nExample: average height of Cal undergraduates.\nn = 800\nWe typically can collect a single sample. It has just one average.\n.\nSince that sample was random, it could have come out differently.\nn = 200\nWe should consider the average value and spread of all possible\nsample means, and how it scales with the sample size n.\n0\nE[X,]\nSD(X) =\nIn\nFor every sample size, the expected value of\nthe sample mean is the population mean.\nWe call the sample mean an\nunbiased estimator of the population mean.\n(more on this in a bit)\n17\n2024-10-29 11:31:22\n",
        "Retrieved Audio": "The expectation. Why?\nMy expectation.\nSo we can do this analysis of the expectation.",
        "Retrieved Notes": "$\nThe latter is more commonly used as we are usually just given the distribution, not all possible samples.\nWe want to emphasize that the expectation is a *number*, not a random variable. Expectation is a generalization of the average, and it has the same units as the random variable. It is also the center of gravity of the probability distribution histogram, meaning if we simulate the variable many times, it is the long-run average of the simulated values.\n#### Example 1: Coin Toss\nGoing back to our coin t\nention on the expectation and variance of a random variable.\n### Expectation\nThe **expectation** of a random variable $X$ is the **weighted average** of the values of $X$, where the weights are the probabilities of each value occurring. There are two equivalent ways to compute the expectation: \n1. Apply the weights one *sample* at a time: $$\\mathbb{E}[X] = \\sum_{\\text{all possible } s} X(s) P(s)$$.\n2. Apply the weights one possible *value* at a time: $$\\mathbb{E}[X] = \\sum_{\\text{all possible } x} x P(X=x)$\noss example, we define a random variable $X$ as: \n$$X = \\begin{cases} \n      1, \\text{if the coin lands heads} \\\\\n      0, \\text{if the coin lands tails} \n   \\end{cases}$$\n   \nWe can calculate its expectation $\\mathbb{E}[X]$ using the second method of applying the weights one possible value at a time: \n$$\\begin{align}\n \\mathbb{E}[X] &= \\sum_{x} x P(X=x) \\\\\n &= 1 * 0.5 + 0 * 0.5 \\\\\n &= 0.5\n\\end{align}$$\nNote that $\\mathbb{E}[X] = 0.5$ is not a possible value of $X$; it's an average. **The expectation of X do",
        "Retrieved Video": "One more important property of Expectation:\nLet X and Y be independent random variables:\nE [XY] = E [X] E [Y]\n5\n2024-10-29 11:12:30\n\nOne more important property of Expectation:\nLet X and Y be independent random variables:\nHey Gonzalez Phe.N.\nE [XY] = EE [X] [[Y]\nProof:\nE[XY]=>>ryP(X=x,Y=y)\nc y.\n=>>ryP(X=x)P(Y=y)\ny\n=>xP(X=x)_yP(Y=y)\n=(CIP(X=x) (CUP (Y=3)\ny\n= E [X] E[Y]\n5\n2024-10-29 11:13:08\n\nOne more important property of Expectation:\nLet X and Y be independent random variables:\nHey Gonzalez Pe,h.\nE [XY] =E [X] E[Y]\nProof:\nE[XY]=>>ryP(X=x,Y=y)\nDefinition\n\"=>>ryP(X=x)P(Y=y)\nIndependence\n-{[TP(X=x)CUP (Y=3)\ny\n= (CzP(X=x)\nEyP(Y =y)\nAlgebra\n= E [X]E[Y]\nDefinition\n5\n2024-10-29 11:13:51\n",
        "Question": "can you explain again really quick what expectation is",
        "Timestamp": 1268,
        "TA Response": "Expectation is the \"expected value\" of some random variable. It can be thought of as the weighted average value that some random variable takes. For instance, if you roll a 6-sided die, the \"expected value\" is 3.5, as that is the average of its equally probable values, 1,2,3,4,5,6. Another way to think about it is that if you rolled the die an infinite number of times, the average of all of the rolls will come out to 3.5. The formula given for calculating expectation is essentially just a weighted average of all possible values that an RV can take (weighted by the probability of each value).",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the context of the lecture, the green and purple lines represent different models that have been fitted to different samples drawn from the population. The variability in these lines illustrates how different samples can lead to different model estimates. The terms \\(\\hat{y}_0\\) and \\(\\hat{y}_1\\) refer to the predictions made by these models at a specific point \\(x\\). This demonstrates the concept of model variance, where different samples can lead to different predictions even if they are based on the same underlying process.",
        "Recent Audio": "get depending on which sample I take from the population. My goal now is to understand that variability and the bias between these samples and the truth. OK. Curry said this. So when I make a prediction at a point I'm going to evaluate my function, I'm going to get a random variable for that estimate for that location. Right. So now what I'm going to do is try to use the tools of bias invariants or expectation variance to actually derive this relationship for the squared loss because it's pretty neat. And this will try to explain what we showed in previous lectures. That is we increase our complexity variance went up, training air went down, bias decreased on our data. Yeah, but our validation is starting to go up. Did feel like there's a trade off. You're getting better and better fits for data and getting worse and worse predictions on the world. We're going to show that there are these two pieces, model variance and model bias squared that make up this test error. All right, so we're going to build this plot. So suppose my test point is here. The red line is truth. These are my data points. I have a new X and testing at the green curve is my prediction build on the right here. And then Y is what I actually observe when I go to see that that that particular data point. So my error my residual is going to be different between Y hat and Y.",
        "Recent Video": "Prediction Error\nRecall the plot from earlier:\nHey Gonzalez Phe.N.\n1.5\n-g(x)\n. Y\n1\n-y_hat_0\nWe will zoom in on\n0.5\na single x\n0\n-0.5\n-1\n-2\n-1\n0\n1\n2\n40\n2024-10-29 11:51:03\n\nPrediction Error\nRecall the plot from earlier:\nHey Gonzalez Pe ..\nY=g(x) +\u20ac\n1.5\n-g(x)\n. Y\n1\n-y_hat_0\ng(x)\nY-\u00dd(x)-\nWe will zoom in on\n0.\na single x\n(residual)\n.\n0\n....\n-0.5\nT\n-1\n-2\n-1\n0\n1\n2\n40\n40\n2024-10-29 11:51:18\n",
        "Retrieved Audio": "Maybe this blue dots are the population, those are all the students that were drawn from this truth. And then each of these green or purple dots are different samples. So I got 1 sample and another sample.\nRight, She's dots are samples. These lines would be fit to some model on those samples. So this variability in the choice of models I get depending on which sample I take from the population.\nRemember, remember, in our story, we see a sample using the data points of some complex process. Could be this, this green line. Sorry. We fit our sample. This, this process here. Oh, no, OK, don't have it built in. All right, so this is what I see. And On this date I go, you know what? Here's the curve. I fit it nearly perfectly. This green line here, here is the model's best fit.",
        "Retrieved Notes": "slope for the model by using only a single random sample of 20 cars.\n<!-- #### PurpleAir (chose to skip this section because it's too complex for the amount of pedagogical value it adds)\nTo show an example of this hypothesis testing process, we'll work with air quality measurement data. There are 2 common sources of air quality information: Air Quality System (AQS) and [PurpleAir sensors](https://www2.purpleair.com/). AQS is seen as the gold standard because it is high quality, well-calibrated, and publicly\np $g$. We do this by constructing the model $\\hat{Y}(x)$ to estimate $g$. \n$$\\text{True relationship: } g(x)$$\n$$\\text{Observed relationship: }Y = g(x) + \\epsilon$$\n$$\\text{Prediction: }\\hat{Y}(x)$$\n<p align=\"center\">\n<img src=\"images/y_hat.png\" alt='y_hat' width='600'>\n</p>\nWhen building models, it is also important to note that our choice of features will also significantly impact our estimation. In the plot below, you can see how the different models (green and purple) can lead to different estimates.\n<p\nhe image below, $g$ is denoted by the red line.\nAs data scientists, however, we have no way of directly \"seeing\" the underlying relationship $g$. The best we can do is collect observed data out in the real world to try to understand this relationship. Unfortunately, the data collection process will always have some inherent error (think of the randomness you might encounter when taking measurements in a scientific experiment). We say that each observation comes with some random error or **noise** term, $\\ep",
        "Retrieved Video": "The Population Model and the Samples\nHey Gonzalez Phe ....\nY = g(x) +E\n\u0176(x) =f\u00f4(x)\nSample Data\n1.5\n-g(x)\nY\ng(x)\n1\n. Y\n1\n-y_hat_0\ny_hat_1\n0.5\n0\n0\n-0.5\n-0.5\n-1\n-2 -1.5 -1 -0.5 0 0.5 1 1.5 2\n-1\n-2\n-1\n1\n2\n2024-10-29 11:49:23\n\nThe Population Model and the Samples\nHey Gonzalez The.h.\nY = g(x) +\u20ac\n\u0176(x)=f\u00f4(x)\nSample Data\n1.5\nY\n-g(x)\n1\n. Y\n1\n-y_hat_0\ny_hat_1\n0.5\n0.5\n0\n0\n-0.5\n-0.5\n-1\n-2 -1.5 -1 -0.5 0 0.5 1 1.5 2\n-1\n-2\n-1\n1\n2\n2024-10-29 11:49:61\n\nThe Population Model and the Samples\nHey Gonzalez Phe ....\nY = g(x) +\u20ac\nSample Data\n\u0176(x)=f\u00f4(x)\nWe fit (train) a model based on our\n1.5\nY\nsample of (x, y) pairs.\n-g(x)\n1\ny_hat_0\nOur model estimates the true relationship:\n=y_hat_1\nY= g(x) +\u20ac\n0.5\nAt every x, our prediction for Y is:\n0\n\u00dd(x) = f\u00f4(x)\n-0.5\n-1\n-2\n-1\n1\n2\n2024-10-29 11:50:15\n",
        "Question": "What do the green line and purple line mean in slide the population model and the samples. Idk their difference why there is hat0 and hat1",
        "Timestamp": 2470,
        "TA Response": "The green and purple lines represent 2 different model fits to the data. Recall the notation of Y_hat to represent our \"predicted\" y's\u2014 that's what Y_hat_0 and Y_hat_1 represent here. The important thing to note here is that the 2 models were created from 2 different samples of the population data, resulting in 2 very different model predictions. This is meant to display the variability between different model fits, based on which sample is chosen.",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the context of the lecture, \\( g(x) \\) represents the true underlying relationship between the input \\( x \\) and the output, which is often unknown. On the other hand, \\( Y \\) is the observed data, which includes both the true relationship \\( g(x) \\) and some random noise \\( \\epsilon \\). We use \\( g(x) \\) in the model bias calculation because model bias is concerned with how well our model's expected predictions \\( E[\\hat{Y}(x)] \\) approximate the true relationship \\( g(x) \\), rather than the noisy observations \\( Y \\). This helps us understand the systematic error introduced by the model itself, independent of the random noise in the data.",
        "Recent Audio": "data made a big difference. So more data is valuable. Manages variance the model bias. Again, this is the gap between G and our model. And expectation, This is not a random variable, right? This is constant. This is also you know. Not a random variable again. How to interpret bias? We often don't think about the sign of bias, but just in this form. When I've written it like this, if I look at the bias, if it is positive, then we're underestimating the value of our data on average. If it's negative or overestimating, and if it's zero, we have an unbiased estimator and we often strive to get to that 0 unbiased and then try to manage variance and other techniques. But you'll see that variance in BIOS often are at odds. What kind of bias would regularization introduce? Quick intuitions. Good good check. Here's my plot. Here's my data. I have really aggressive regularization. What will my model look like? Flyline zeros break 0 everywhere, so I have I'm underestimating my data, right? Of course it could be my data looks like this regressive regularization again here. Overestimating my data OK. So my model is not changing a lot, it's always 0. No matter what sample I take, I'm still going to get 0 model. But it's biased low variance. Questions up to this point before we do more math. Questions on Slido how slider looking? OK, I'm going too slowly. When we're underfitting, what can we do? We've often over regularized.",
        "Recent Video": "3. Model Bias\nDefine the model bias as the difference between the\nexpected predicted value and the true g(x).\nmodel bias = g(z) - E [} (z)]\n\u0176(x)\nPrediction for the\nindividual at x\nA random variable\nAverage\nModel bias is computed for the expected prediction\nmodel\n(averaged over all possible training datasets).\n10\n----\ntrue g(x)\nReasons: Underfitting.\n5\nOver regularized\nNot optimizing loss adequately\n0\nInsufficient model complexity\nRemedies:\n-5\nTune regularization and optimization\n-10\nIncrease model complexity (but don't overfit!)\n-2\n-1\n0\n1\n2\nx\n50\n2024-10-29 11:57:27\n\n3. Model Bias\nDefine the model bias as the difference between the\nexpected predicted value and the true g(x).\nHey Gonzalez Be ...\nmodel bias = g(x) -E |f(x)\n\u0176(x)\nPrediction for the\nindividual at x\nA random variable\nAverage\nModel bias is computed for the expected prediction\nmodel\n(averaged over all possible training datasets).\n10\n----\ntrue g(x)\nReasons: Underfitting.\n5\nOver regularized\nNot optimizing loss adequately\n0\nInsufficient model complexity\nRemedies:\n-5\nTune regularization and optimization\n-10\nIncrease model complexity (but don't overfit!)\n-2\n-1\n0\n1\n2\n50\n2024-10-29 11:57:37\n",
        "Retrieved Audio": "Another possible way, G is fixed Y is random variable. So we have some observational variance that I told you before Sigma that accounts for this variation.\nManages variance the model bias. Again, this is the gap between G and our model.\nI'm going to introduce a modeling assumption about how that random variable comes to be. It's an important one. There is some truth, some true underlying underlying relationship G this relationship between the X and the Yi Don't know this.",
        "Retrieved Notes": "g(x) - \\hat{Y}(x) ~ = ~ \\left(g(x) - E\\left[\\hat{Y}(x)\\right] \\right) + \\left(E\\left[\\hat{Y}(x)\\right] - \\hat{Y}(x)\\right) \n$$\nThe first term on the right hand side is the model bias at $x$. The second term is $-D_{\\hat{Y}(x)}$. So\n$$\ng(x) - \\hat{Y}(x) ~ = ~ \\text{model bias} - D_{\\hat{Y}(x)}\n$$\n### Step 3\nRemember that the model bias at $x$ is a constant, not a random variable. Think of it as your favorite number, say 10. Then \n$$\n\\begin{align*}\nE\\left[ \\left(g(x) - \\hat{Y}(x)\\right)^2 \\right] ~ &= ~ \\text\np $g$. We do this by constructing the model $\\hat{Y}(x)$ to estimate $g$. \n$$\\text{True relationship: } g(x)$$\n$$\\text{Observed relationship: }Y = g(x) + \\epsilon$$\n$$\\text{Prediction: }\\hat{Y}(x)$$\n<p align=\"center\">\n<img src=\"images/y_hat.png\" alt='y_hat' width='600'>\n</p>\nWhen building models, it is also important to note that our choice of features will also significantly impact our estimation. In the plot below, you can see how the different models (green and purple) can lead to different estimates.\n<p\nr model on the noises.\n#### Model Bias\nFinally, the second term is $\\left(g(x)-E\\left[\\hat{Y}(x)\\right]\\right)^2$. What is this? The term $E\\left[\\hat{Y}(x)\\right] - g(x)$ is called the **model bias**.\nRemember that $g(x)$ is the fixed underlying truth and $\\hat{Y}(x)$ is our fitted model, which is random. Model bias therefore measures how far off $g(x)$ and $\\hat{Y}(x)$ are on average over all possible samples.\n$$\\text{model bias} = E\\left[\\hat{Y}(x) - g(x)\\right] = E\\left[\\hat{Y}(x)\\right] - g(x)$$\nThe mo",
        "Retrieved Video": "3. Model Bias\nDefine the model bias as the difference between the\nexpected predicted value and the true g(x).\n\u0176(x)\nPrediction for the\nmodel bias = g(2) - IE [} (2)]\nindividual at x\nA random variable\nAverage\nModel bias is computed for the expected prediction\nmodel\n(averaged over all possible training datasets).\n10\n----\ntrue g(x)\n5\n0\n-5\n-10\n-2\n-1\n0\n1\n2\nx\n49\n2024-10-29 11:55:27\n\nThe Population Model and the Samples\nY = g(x) +\u20ac\nSample Data\n\u0176(x)=f\u00f4(x)\nWe fit (train) a model based on our\n1.5\nY\nsample of (x, y) pairs.\n1\n-y_hat_0\n(x)6.\nOur model estimates the true relationship:\ny_hat_1\nY= g(x) +\u20ac\n0.5\nAt every x, our prediction for Y is:\n0\n\u0176(x) =f\u00f4(x)\n-0.5\n-2\n-1\n1\n2\n2024-10-29 11:50:11\n\nThe Population Model and the Samples\nHey Gonzalez The.h.\nY = g(x) +\u20ac\n\u0176(x)=f\u00f4(x)\nSample Data\n1.5\nY\n-g(x)\n1\n. Y\n1\n-y_hat_0\ny_hat_1\n0.5\n0.5\n0\n0\n-0.5\n-0.5\n-1\n-2 -1.5 -1 -0.5 0 0.5 1 1.5 2\n-1\n-2\n-1\n1\n2\n2024-10-29 11:49:61\n",
        "Question": "Could you explain the difference between g(x) and Y again? Why do we use g(c) in model bias instead of Y? ",
        "Timestamp": 2855,
        "TA Response": "g(x) represents the \"true\" underlying function that best fits the population data. However, most of the time, the true underlying function does not fit the data exactly, and there is some additional irreducible noise/error term. This is represented by epsilon. Y, on the other hand, represents the exact population data. In other words, Y = g(x) + epsilon, as given on the slide. We use g(x) to calculate model bias instead of Y, so as to not conflate the model bias with the irreducible error. If we used Y instead of g(x), like so: Y - E[Y_hat(x)], we would get model bias + or - the irreducible error.",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "Regularization is a technique used in machine learning to reduce model complexity by imposing constraints on the magnitudes of the model parameters. This is achieved by adding a penalty term to the cost function, which discourages large parameter values. The penalty term is controlled by a hyperparameter, often denoted as $\\lambda$, which needs to be determined prior to training the model, typically through cross-validation. Regularization helps prevent overfitting by introducing bias, which can lead to a model that generalizes better to unseen data.",
        "Recent Audio": "then try to manage variance and other techniques. But you'll see that variance in BIOS often are at odds. What kind of bias would regularization introduce? Quick intuitions. Good good check. Here's my plot. Here's my data. I have really aggressive regularization. What will my model look like? Flyline zeros break 0 everywhere, so I have I'm underestimating my data, right? Of course it could be my data looks like this regressive regularization again here. Overestimating my data OK. So my model is not changing a lot, it's always 0. No matter what sample I take, I'm still going to get 0 model. But it's biased low variance. Questions up to this point before we do more math. Questions on Slido how slider looking? OK, I'm going too slowly. When we're underfitting, what can we do? We've often over regularized. Not sufficiently optimized their loss and maybe we didn't tune our our gradient descent and we didn't minimize the the function. So we're still stuck at something close to 0 maybe. Or as we've learned recently, we can make models much more complex, adding more features, adding nonlinearities and so on. And this is what a lot of modern AI has done is really push model complexity and finding other mechanisms to deal with the consequences of all that model complexity. And what are the consequences of all that model complexity? Fairness. Some more variability in our models. OK, so let's do the math finally. So we have a residual, we have our G, the truth.",
        "Recent Video": "Components of Prediction Error\nHey Gonzalez Pe ...\nY= g(x) +\u20ac\nY-\u0176(x).\n(residual)\n\u0176(x)\n.\n..\n51\n2024-10-29 11:58:25\n\nComponents of Prediction Error\nY= g(x) +\u20ac\n\u20ac\n.\ng(x)=E[Y]\ng(x)-\u0176(x)\n\u0176(x)\n..\n53\n2024-10-29 11:58:30\n",
        "Retrieved Audio": "What kind of bias would regularization introduce?\nWhen we're underfitting, what can we do? We've often over regularized.\nI have really aggressive regularization. What will my model look like?",
        "Retrieved Notes": "lution is the global minimum $\\hat{\\theta} = \\hat\\theta_{No Reg.}$. <!-- We showed that the global optimum is achieved when the L2 norm ball radius $Q \\rightarrow \\infty$. -->\nWe call $\\lambda$ the **regularization penalty hyperparameter**; it needs to be determined *prior* to training the model, so we must find the best value via cross-validation.\nThe process of finding the optimal $\\hat{\\theta}$ to minimize our new objective function is called **L1 regularization**. It is also sometimes known by the acron\ne of $\\hat{\\mathbb{Y}}$. If we restrict how large each parameter $\\theta_i$ can be, we restrict how much feature $\\phi_i$ contributes to the model. This has the effect of *reducing* model complexity.\nIn **regularization**, we restrict model complexity by putting a limit on the *magnitudes* of the model parameters $\\theta_i$. \nWhat do these limits look like? Suppose we specify that the sum of all absolute parameter values can be no greater than some number $Q$. In other words:\n$$\\sum_{i=1}^p |\\theta_i| \\leq \nented by the term $\\lambda \\sum_{i=1}^p |\\theta_i|$\nThe $\\lambda$ factor controls the degree of regularization. Roughly speaking, $\\lambda$ is related to our $Q$ constraint from before by the rule $\\lambda \\approx \\frac{1}{Q}$. To understand why, let's consider two extreme examples. Recall that our goal is to minimize the cost function: $\\frac{1}{n}||\\mathbb{Y} - \\mathbb{X}\\theta||_2^2 + \\lambda || \\theta ||_1$.\n- Assume $\\lambda \\rightarrow \\infty$. Then, $\\lambda || \\theta ||_1$ dominates the cost functio",
        "Retrieved Video": "hat kind of bias would regularization introduce?\n-2\n-1\n0\n1\n2\nx\n49\n2024-10-29 11:56:30\n\nhat kind of bias would regularization introduce?\n-2\n-1\n0 x\n1\n2\n49\n2024-10-29 11:56:26\n\nnbiased.\n-5\n-10\nWhat kind of bias would regularization introduce?\n-2\n-1\n0\n1\n2\n49\n2024-10-29 11:57:03\n",
        "Question": "What is regularization? ",
        "Timestamp": 2891,
        "TA Response": "Regularization is a technique in machine learning that helps prevent a model from fitting too closely to the training data, a problem known as overfitting. By adding a penalty for more complex models during the training process, regularization ensures the model remains simple and improves its ability to make predictions on new, unseen data. For details on what that looks like specifically see the course notes here on Cross Validation and Regularization: https://ds100.org/course-notes/cv_regularization/cv_reg.html",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "On slide 57, the transition from \\( E[B^2] \\) to \\( 2a E[C] \\) is part of the expansion of the expression for model risk, which involves breaking down the squared terms and cross terms. The expression \\( E[B^2] \\) is part of the decomposition of the variance term, while \\( 2a E[C] \\) is one of the cross terms that arises when expanding the square of the sum \\((a + B + C)^2\\). The cross terms are derived from the linearity of expectation and the independence assumptions, where \\( a \\) is a constant and \\( C \\) is a random variable.",
        "Recent Audio": "just made this epsilon to begin with. But anyways, so C is epsilon. Big step there. I think that's all I changed so C is now epsilon. This is a good sign right now, right? You like that? What's this going to be? Let's see expectation epsilon. Zero. We assume that. OK, that's going to be helpful. This we have to think about. Let's look at this one. B. This whole thing here doesn't depend on epsilon, and epsilon are independent. Right, there's no this is a new epsilon for my new Y. These might have their own epsilons in that process, but they're independent because the epsilons are independent. Noise. OK, because they're independent. That new property entries the beginning of lecture means I can break this into this. Now we're cooking, right? Where we said the expectation of epsilon is 0. We assume that. That's our modeling assumption. Unbiased noise. If we weren't sure, we'd have a problem at this point, but it is. That means this and this go to 0. So we can go into this whole set of terms. It's convenient. What's left? This piece right here. We can expand B. It's this piece right here. Let's do that. We just plugged in B. What is this expectation right here? Microsoft. What is his expectation? This is a constant, so I can pull this expectation through the parenthesis here. This expectation put this expectation over here. I get the expectation of Y hat minus the expectation of Y hat. What's that?",
        "Recent Video": "Examining the Cross Terms\nSimplify notation so we can easily expand the square:\nHey Gonzalez Phe.JE\nY - \u00dd (z) = (g(z) - IE \u00dd (r) + (IE [}(2)] - \u00dd(z)\n+ \u20ac\na\nB\nC\nNote that B and C are random variables and the bias term a is a constant.\ncross terms = 2a E [B] + 2a E [C] + 2 E [BC]\nE [ E] =0\n=2a E [B]+ 2a E [\u20ac] + 2E [Be]\nSubstitution\n= 2a E [B] + 2a EX( + 2 E [B] EYE\nB and \u20ac are independent\n= 2a E [B] +20+0+2E[B] +0'\nE[e] =0\n2018 [10 Y(2)] -8(2)] =0\n58\n2024-10-29 12:08:44\n\nExamining the Cross Terms\nSimplify notation so we can easily expand the square:\nHey Gonzalez Be ...\nY - \u00dd(x)= (g(x) - E \u00dd(z) + (E |\u00dd (2)] - \u00dd (x) + \u20ac\na\nB\nNote that B and C are random variables and the bias term a is a constant.\ncross terms = 2a E [B] + 2a E [C] + 2E [BC]\n= 2a E [B]+ 2a EE [\u20ac] + 2 EE [Be]\nSubstitution\n= 2a LE [B] + 2a E [\u20ac] + 2 EE [ B] E [\u20ac]\nB and \u20ac are independent\n=2a E [B] + 2a*0+2EE[B]*0\nE[e] =0\n= 2 E [E [{(2)] - \u00dd (2)] = 0\nLinearity of expectation\n59\n2024-10-29 12:08:54\n",
        "Retrieved Audio": "We just plugged in B. What is this expectation right here?\nWe take the square of all this and I believe that is a ^2 + b ^2 + C ^2 + 2 AB +2 AC +2 BC, right? But we had some expectations to deal with. We use linearity of expectation and we broke that into the sum of expectations of a ^2, b ^2, C ^2. I pulled the 2A out. It would have been expectation of two A * B, but you know, 2 as a constant, so I pulled that out.\nStep one I substituted in C, which in retrospect I should not have done so I should have just made this epsilon to begin with. But anyways, so C is epsilon. Big step there. I think that's all I changed so C is now epsilon.",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Define a random variable in terms of its distribution\n* Compute the expectation and variance of a random variable\n* Gain familiarity with the Bernoulli and binomial random variables\n:::\nIn the past few lectures, we've examined the role of complexity in influencing model performance. We've considered model complexity in the context of \n$\nWith this reformulated modeling goal, we can now revisit the Bias-Variance Tradeoff from two lectures ago (shown below): \n<p align=\"center\">\n<img src=\"images/bvt_old.png\" width='600'>\n</p>\nIn today's lecture, we'll explore a more mathematical version of the graph you see above by introducing the terms model risk, observation variance, model bias, and model variance. Eventually, we'll work our way up to an updated version of the Bias-Variance Tradeoff graph that you see below \n<p align=\"center\">\n<img src=\"\nood model?\nTo illustrate this process, we derived the optimal model parameters under simple linear regression (SLR) with mean squared error (MSE) as the cost function. A summary of the SLR modeling process is shown below:\n<div align=\"middle\">\n<img src=\"images/slr_modeling.png\" alt='modeling' width='600'>\n</div>\nIn this lecture, we'll dive deeper into step 4 - evaluating model performance - using SLR as an example. Additionally, we'll also explore the modeling process with new models, continue familiarizing ",
        "Retrieved Video": "Basic Algebra and Linearity of Expectation\nSimplify notation so we can easily expand the square:\n= (\u201e(z) - E { (a) +(IE [\u00dd (z)] - \u2103(ar)\n770\n+ \u20ac\na\nB\nNote that B and C are random variables and the bias term a is a constant.\nmodel risk = E\n(Y-\u00dd(2)2|= [(a+B+C)2]\nL\n= E [a2] + E [B2] + E [C2]\n+ 2a [ [B] + 2a E [C] + 2 EE [BC]\n57\n2024-10-29 12:05:37\n\nBasic Algebra and Linearity of Expectation\nSimplify notation so we can easily expand the square:\nHey Gonzalez Phe.h.L\nY - \u00dd(2) = (g(x) - IE \u00dd (2) + (IE [\u00dd()] - \u00dd(z)\n+ \u20ac\na\nB\nNote that B and C are random variables and the bias term a is a constant.\n2\nmodel risk = E\n= IE [2] + [E [B2] + [E [C2]\n+ 2a LE [B] + 2a [ [C] + 2 E [BC]\n57\n2024-10-29 12:05:56\n\nExamining the Cross Terms\nSimplify notation so we can easily expand the square:\n= ((z) - E { (a) +(E [ (z)] - \u00dd(a)\n+ \u20ac\na\nB\nC\nNote that B and C are random variables and the bias term a is a constant.\ncross terms = 2a E [B] + 2a E [C] + 2 E [BC]\n=2a LE [B]+ 2a E [\u20ac]+2E[Be]\nSubstitution\n= 2a E [B] + 2a EE [\u20ac] + 2E [ B] E [\u20ac]\nB and \u20ac are independent\n2a E [B]+2a*0+2E[B]*0\n2013 18 Y(2) -Y(2) =0\n58\n2024-10-29 12:08:20\n",
        "Question": "On slide 57, how did we go from E(B^2) to a E (C) ? ",
        "Timestamp": 3546,
        "TA Response": "I believe you may be mistaken\u2014 notice that the start of that line is a + and not an =, indicating that the terms in that line are being added to the line above, not equated to them. Does that answer your question, or were you referring to a different part?",
        "Lecture": 18
    },
    {
        "Conversation History": "\t",
        "GPT Response": "In the context of the lecture, B and C are both random variables, but they represent different components in the model. B is typically associated with the bias or systematic error, while C (or epsilon) represents the random error or noise in the observations. The distinction is important because the modeling assumptions treat epsilon as having an expectation of zero, which simplifies the analysis by eliminating certain terms. Plugging in B as epsilon would not be appropriate because they serve different roles in the model's error decomposition.",
        "Recent Audio": "expectation of epsilon is 0. We assume that. That's our modeling assumption. Unbiased noise. If we weren't sure, we'd have a problem at this point, but it is. That means this and this go to 0. So we can go into this whole set of terms. It's convenient. What's left? This piece right here. We can expand B. It's this piece right here. Let's do that. We just plugged in B. What is this expectation right here? Microsoft. What is his expectation? This is a constant, so I can pull this expectation through the parenthesis here. This expectation put this expectation over here. I get the expectation of Y hat minus the expectation of Y hat. What's that? Alright, give it away. It's bummer. That's zero right times 2. A All right, so we've shown all the cross terms are 0. We did make assumptions, right? We assume this that's important and this those are remodeling assumptions. Let's just get rid of all these cross terms and it's a pretty reasonable set of assumptions. Now what do we got? We're left with the interesting terms right here. So let's break these down some more. Constants are gone. The interesting terms. Do you have expectation of a ^2 plus expectation of b ^2? Expectation of C? Remember, these are random variables. This is not. We'll do some substitution here. This is the expectation of a ^2, right? This is the expectation of b ^2. Check expectation of b ^2. Yep, good. And the expectation of C ^2.",
        "Recent Video": "Basic Algebra and Linearity of Expectation\nY - \u00dd(x) = (g(x) - E [\u00dd(2)]) + (E [}(2)] - }]\nto\na\nB\nNote that B and C are random variables and the bias term a is a constant.\n[(Y -Y(x)2]= E [(a+B+C)2]=E[g2]+E[2]+ [C]\n=(a)- B [(D) + (BY()] -8(0) |+02\n61\n2024-10-29 12:10:16\n\nBasic Algebra and Linearity of Expectation\nY - \u00dd (x) = (g(r) - E [Y(z)]) + (E [}(r)] - }]\nto\na\nB\nNote that B and C are random variables and the bias term a is a constant.\nE[(Y -Y(x)2]=E [(a+B+C)2]=B[2]+ [B2]+ [2]\n=E (2)-[8(a)]+[ (2)]- (2)}+B[ 2]\n= (2)- B [Y()\" += (= [Y()] - 8() |+02\n61\n2024-10-29 12:10:30\n",
        "Retrieved Audio": "But here remember this depends on Theta hat on my sample and the C term is boring, it's just epsilon. I don't know why I made it. C could just set epsilon. Anyways C is epsilon OK, also a random variable, so capital C.\nWe just plugged in B. What is this expectation right here?\nDo you have expectation of a ^2 plus expectation of b ^2? Expectation of C? Remember, these are random variables. This is not. We'll do some substitution here.",
        "Retrieved Notes": "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Define a random variable in terms of its distribution\n* Compute the expectation and variance of a random variable\n* Gain familiarity with the Bernoulli and binomial random variables\n:::\nIn the past few lectures, we've examined the role of complexity in influencing model performance. We've considered model complexity in the context of \nsilon$ (read: \"epsilon\"). This error is assumed to be a random variable with expectation $\\mathbb{E}(\\epsilon)=0$, variance $\\text{Var}(\\epsilon) = \\sigma^2$, and be i.i.d. across each observation. The existence of this random noise means that our observations, $Y(x)$, are *random variables*.\n<p align=\"center\">\n<img src=\"images/data.png\" alt='data' width='700'>\n</p>\nWe can only observe our random sample of data, represented by the blue points above. From this sample, we want to estimate the true relationshi\npsilon$:\n$$\n\\begin{align*}\n\\text{Var}(\\epsilon) &= E[\\epsilon^2] + \\left(E[\\epsilon]\\right)^2\\\\\n&= E[\\epsilon^2] + 0^2\\\\\n&= \\sigma^2.\n\\end{align*}\n$$\nThis term describes how variable the random error $\\epsilon$ (and $Y$) is for each observation. This is called the **observation variance**. It exists due to the randomness in our observations $Y$. It is a form of *chance error* we talked about in the Sampling lecture.\n$$\\text{observation variance} = \\text{Var}(\\epsilon) = \\sigma^2.$$\nThe observation variance ",
        "Retrieved Video": "Basic Algebra and Linearity of Expectation\nSimplify notation so we can easily expand the square:\nHey Gonzalez Phe.h.L\nY - \u00dd(2) = (g(x) - IE \u00dd (2) + (IE [\u00dd()] - \u00dd(z)\n+ \u20ac\na\nB\nNote that B and C are random variables and the bias term a is a constant.\n2\nmodel risk = E\n= IE [2] + [E [B2] + [E [C2]\n+ 2a LE [B] + 2a [ [C] + 2 E [BC]\n57\n2024-10-29 12:05:56\n\nBasic Algebra and Linearity of Expectation\nSimplify notation so we can easily expand the square:\nHey Gonzalez Pek\nY - \u0176(x) = (g(x) - IE \u0176(z) + (E |\u00dd (2)] - \u00dd(x) + \u20ac\na\nB\nc\nNote that B and C are random variables and the bias term a is a constant.\nmodel risk = E\n[x-{(=)2] =[(a+B+C)2]\n= E [a2] + [E [B2] + ]E [C2]\nInteresting terms ...\nCross terms ...\n+ 2a LE [B] + 2a LE [C] + 2 EE [BC]\n60\n2024-10-29 12:09:51\n\nExamining the Cross Terms\nSimplify notation so we can easily expand the square:\nHey Gonzalez Phe.NUL\nY - \u0176 (x) = (g(x) - E \u00dd(2) + (IE [}(x)] - \u00dd(2) + \u20ac\na\nB\nNote that B and C are random variables and the bias term a is a constant.\ncross terms = 2a E [B] + 2a E [C] + 2 E [BC]\n= 2a LE [B]+ 2a EE [\u20ac] + 2 EE [Be]\nSubstitution\n= 2a EE [B]+ 2a E [\u20ac] + 2EE [B] E [\u20ac] B and c are independent\n2a E [B]+2a*0+2E[B]*0\n2013 [18 Y(2)] -8(2)] =0\n58\n2024-10-29 12:07:61\n",
        "Question": "Sorry I might\u2019ve missed it, but why didn\u2019t we also plug in B as epsilon if both B and c are random variables? ",
        "Timestamp": 3617,
        "TA Response": "Note that we are using B and C to represent 2 different terms of our equation at the top of the slide. We can plug epsilon into C because we assigned C to the epsilon term! We assigned B to a different term, specifically E[Y_hat(x)] - Y_hat(x), so we must handle it separately.",
        "Lecture": 18
    }
]